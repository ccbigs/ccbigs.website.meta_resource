# 现代操作系统_上



# 第一章 引 论

现代计算机系统由一个或多个处理器、主存、磁盘、打印机、键盘、鼠标、显示器、网络接口以及各种其他输入/输出设备组成。一般而言,现代计算机系统是ー个复杂的系统。如果每位应用程序员都不得不掌握系统的所有细节,那就不可能再编写代码了。而且,管理这些部件并加以优化使用,是一件挑战性极强的工作。所以,计算机安装了一层软件,称为操作系统,它的任务是为用户程序提供一个更好、更简单、更清晰的计算机模型,并管理刚オ提到的所有设备。本书的主题就是操作系统。

多数读者都会对诸如Windows、Linux.FreeBSD或OSX等某个操作系统有些体验,但表面现象是会骗人的。用户与之交互的程序,基于文本的通常称为shell,而基于图标的则称为图形用户界面（GraphicalUserInterface,GUI）,它们实际上并不是操作系统的一部分,尽管这些程序使用操作系统来完成工作。

图1-1给出了这里所讨论的主要部件的ー个简化视图。图的底部是硬件。硬件包括芯片、电路板、磁盘、键盘、显示器以及类似的设备。在硬件的顶部是软件。多数计算机有两种运行模式:内核态和用户态。软件中最基础的部分是操作系统,它运行在内核态（也称为管态、核心态）。在这个模式中,操作系统具有对所有硬件的完全访问权,可以执行机器能够运行的任何指令。软件的其余部分运行在用户态下。在用户态下,只使用了机器指令中的ー个子集。特别地,那些会影响机器的控制或可进行i/o（输入/输出）操作的指令,在用户态中的程序里是禁止的。在本书中,我们会不断地讨论内核态和用户态之间的差别,这些差别在操作系统的运作中扮演着极其重要的角色。

用户接口程序（shell或者GUI）处于用户态程序中的最低层次,允许用户运行其他程序,诸如Web浏览器、电子邮件阅读器或音乐播放器等。这些程序也大量使用操作系统。

![image-20240914174247502](现代操作系统_上.assets/image-20240914174247502.png)

操作系统所在的位置如图1-1所示。它运行在裸机之上,为所有其他软件提供基础的运行环境。操作系统和普通软件（用户态）之间的主要区别是,如果用户不喜欢某个特定的电子邮件阅读器,他可以自由选择另ー个,或者自己写ー个,但是不能自行写ー个属于操作系统一部分的时钟中断处理程序。这个程序由硬件保护,防止用户试图对其进行修改。

然而,有时在嵌入式系统（该系统没有内核态）或解释系统（如基于Java的操作系统,它采用解释方式而非硬件方式区分组件）中,上述区别是模糊的。

另外,在许多系统中,ー些在用户态下运行的程序协助操作系统完成特权功能。例如,经常有一个程序供用户修改其口令之用。但是这个程序不是操作系统的一部分,也不在内核态下运行,不过它明显地帯有敏感的功能,并且必须以某种方式给予保护。在某些系统中,这种想法被推向了极致,ー些传统上被认为是操作系统的部分（诸如文件系统）在用户空间中运行。在这类系统中,很难划分出一条明显的界限。在内核态中运行的当然是操作系统的一部分,但是ー些在内核外运行的程序也有争议地被认为是操作系统的一部分,或者至少与操作系统密切相关。

操作系统与用户（即应用）程序的差异并不仅仅在于它们所处的地位。特别地,操作系统更加大型、复杂和长寿。Linux或Windows操作系统的源代码有500万行甚至更高的数量级。要理解这个数量的含义,请考虑具有500万行的ー套书,每页50行,每卷1000页（比本书厚）。为了以书的大小列出ー个操作系统,需要有100卷书—基本上需要一整个书架来摆放。请设想一下有个维护操作系统的工作,第一天老板带你到装有代码的书架旁,说:“去读吧ズ而这仅仅是运行在内核中的部分代码。当包括重要的共享库时,Windows将有超过7000万行代码,或者说要用10~20个书架,而且这还不包括一些基础的应用（如WindowsExplorer、WindowsMediaPlayer等）。

至于为什么操作系统的寿命较长,读者现在应该清楚了—操作系统是很难编写的。一旦编写完成,操作系统的所有者当然不愿意把它扔掉,再写ー个。相反,操作系统会在长时间内进行演化。基本上可以把Windows95/98/Me看成是一个操作系统,而WindowsNT/2000/XP/Vista/Windows7则是另外一个操作系统。对于用户而言,它们看上去很像,因为微软公司努力使Windows2000/XP八大ta/WEdows7与被替代系统（如Windows98）的用户界面看起来十分相似。无论如何,微软公司要舍弃Windows98是有非常正当的原因的,我们将在第"章涉及Windows细节时具体讨论这ー内容。

除了Windows以外,贯穿本书的其他主要例子还有UNIX,以及它的变体和克隆版。UNIX当然也演化了多年,如SystemV版、Solaris以及FreeBSD等都是来源于UNIX的原始版∣不过尽管Linux非常像依照UNIX模式仿制而成,并且与UNIX高度兼容,但是Linux具有全新的代码基础。本书将采用来自UNIX中的示例,并在第10章中具体讨论Linux。

本章将简要叙述操作系统的若干重要部分,内容包括其含义、历史、分类、ー些基本概念及其结构。在后面的章节中,我们将具体讨论这些重要内容。

## 1.1 什么是操作系统

很难给出操作系统的准确定义。操作系统是ー种运行在内核态的软件—尽管这个说法并不总是符合事实。部分原因是操作系统有两个基本上独立的任务,即为应用程序员（实际上是应用程序）提供ー个资源集的清晰抽象,并管理这些硬件资源,而不仅仅是ー堆硬件。另外,还取决于从什么角度看待操作系统。读者多半听说过其中一个或另ー个的功能。下面我们逐项进行讨论。

### 1.1.1 作为扩展机器的操作系统

在机器语言ー级上,多数计算机的体系结构（指令集、存储组织、I/o和总线结构）是很原始的,而且编程是很困难的,尤其是对输入/输出操作而言。为了更细致地考察这一点,我们以大多数电脑使用的更现代的SATA（SerialATA）硬盘为例。曾有一本描述早期版本硬盘接口（程序员为了使用硬盘而需要了解的东西）的书（Anderson,2007）,它的页数超过450页。自2007年起,接口又被修改过很多次,因而比当时更加复杂。显然,没有任何理智的程序员想要在硬件层面上和硬盘打交道。相反,他们使用ー些叫作硬盘驱动（diskdriver）的软件来和硬件交互。这类软件提供了读写硬盘块的接口,而不用深入细节。操作系统包含很多用于控制输入/输出设备的驱动。

但就算是在这个层面,对于大多数应用来说还是太底层了。因此,所有的操作系统都提供使用硬盘的又一层抽象:文件。使用该抽象,程序能创建、读写文件,而不用处理硬件实际工作中那些恼人的细节。

抽象是管理复杂性的ー个关键。好的抽象可以把一个几乎不可能管理的任务划分为两个可管理的部分。其第一部分是有关抽象的定义和实现,第二部分是随时用这些抽象解决问题。几乎每个计算机用户都理解的一个抽象是文件,正如上文所提到的。文件是ー种有效的信息片段,诸如数码照片、保存的电子邮件、歌曲或Web页面等。处理数码照片、电子邮件、歌曲以及Web页面等,要比处理SATA（或者其他）硬盘的细节容易,这些磁盘的具体细节与前面叙述过的软盘ー样。操作系统的任务是创建好的抽象,并实现和管理它所创建的抽象对象。本书中,我们将研究许多关于抽象的内容,因为这是理解操作系统的关键。

上述观点是非常重要的,所以值得用不同的表达方式来再次叙述。即使怀着如此小心翼翼对设计Macintosh机器的工业设计师的尊重,还是不得不说,硬件是丑陋的。真实的处理器、内存条、磁盘和其他装置都是非常复杂的,对于那些为使用某个硬件而不得不编写软件的人们而言,他们使用的是困难、可怕、特殊和不一致的接口。有时这是由于需要兼容旧的硬件,有时是为了节省成本,但是,有时硬件设计师们并没有意识到（或在意）他们给软件设计带来了多大的麻烦。操作系统的ー个主要任务是隐藏硬件,呈现给程序（以及程序员）良好、清晰、优雅、一致的抽象。如图1-2所示,操作系统将丑陋转变为美丽。

![image-20240914174310256](现代操作系统_上.assets/image-20240914174310256.png)

需要指出的是,操作系统的实际客户是应用程序（当然是通过应用程序员）。它们直接与操作系统及其抽象打交道。相反,最终用户与用户接口所提供的抽象打交道,或者是命令行shell或者是图形接口。而用户接口的抽象可以与操作系统提供的抽象类似,但也不总是这样©为了更清晰地说明这ー点,请读者考虑普通的Windows桌面以及面向行的命令提示符。两者都是运行在Windows操作系统上的程序,并使用了Windows提供的抽象,但是它们提供了非常不同的用户接口。类似地,运行Gnome或者KDE的Linux用户与直接在XWindow系统（面向文本）顶部工作的Linux用户看到的是非常不同的界面,但是在这两种情形中,操作系统下面的抽象是相同的。

在本书中,我们将具体讨论提供给应用程序的抽象,不过很少涉及用户界面。尽管用户界面是ー个巨大和重要的课题,但是它们毕竟只和操作系统的外围相关。

### 1.1.2 作为资源管理者的操作系统

把操作系统看作向应询程序提供基本抽象的概念,是ー种自顶向下的观点。按照另ー种自底向上的观点,操作系统则用来管理一个复杂系统的各个部分。现代计算机包含处理器、存储器、时钟、磁戏、鼠标、网络接口、打印机以及许多其他设备。从这个角度看,操作系统的任务是在相互竞争的程序之间有序地控制对处理器、存储器以及其他i/o接口设备的分配。

现代操作系统允许同时在内存中运行多道程序。假设在一台计算机上运行的三个程序试图同时在同一台打印机上输出计算结果,那么开始的几行可能是程序1的输出,接着几行是程序2的输出,然后又是程序3的输出等,最终结果将是ー团糟。采用将打印结果送到磁盘上缓冲区的方法,操作系统可以把潜在的混乱有序化。在ー个程序结束后,操作系统可以将暂存在磁盘上的文件送到打印机输出,同时其他程序可以继续产生更多的输出结果,很明显,这些程序的输出还没有真正送至打印机。

当ー个计算机（或网络）有多个用户时,管理和保护存储器、シ。设备以及其他资源的需求变得强烈起来,因为用户间可能会互相干扰。另外,用户通常不仅共享硬件,还要共享信息（文件、数据库等）。简而言之,操作系统的这种观点认为,操作系统的主要任务是记录哪个程序在使用什么资源,对资源请求进行分配,评估使用代价,并且为不同的程序和用户调解互相冲突的资源请求。

资源管理包括用以下两种不同方式实现多路复用（共享）资源:在时间上复用和在空间上复用。当ー种资源在时间上复用时,不同的程序或用户轮流使用它。先是第一个获得资源的使用,然后下ー个,以此类推。例如,若在系统中只有一个CPU,而多个程序需要在该CPU上运行,操作系统则首先把该CPU分配给某个程序,在它运行了足够长的时间之后,另ー个程序得到CPU,然后是下ー个,如此进行下去,最终,轮到第一个程序再次运行。至于资源是如何实现时间复用的—谁应该是下一个以及运行多长时间等—则是操作系统的任务。还有一个有关时间复用的例子是打印机的共享。当多个打印作业在一台打印机上排队等待打印时,必须决定将轮到打印的是哪个作业。

另ー类复用是空间复用。每个客户都得到资源的一部分,从而取代了客户排队。例如,通常在若干运行程序之间分割内存,这样每ー个运行程序都可同时入驻内存（例如,为了轮流使用CPU）。假设有足够的内存可以存放多个程序,那么在内存中同时存放若干个程序的效率,比把所有内存都分给ー个程序的效率要高得多,特别是,如果一个程序只需要整个内存的ー小部分」结果更是这样。当然,如此的做法会引起公平、保护等问题,这有赖于操作系统解决它们。有关空间复用的其他资源还有磁盘。在许多系统中,一个磁盘同时为许多用户保存文件。分配磁盘空间并记录谁正在使用哪个磁盘块,是操作系统的典型任务。

## 1.2 操作系统的历史

操作系统已经存在许多年了。在下面的小节中,我们将简要地考察操作系统历史上的ー些重要之处。操作系统与其所运行的计算机体系结构的联系非常密切。我们将分析连续几代的计算机,看看它们的操作系统是什么样的。把操作系统的分代映射到计算机的分代上有些粗糙,但是这样做确实有某些作用,否则没有其他好办法能够说清楚操作系统的历史。

下面给出的有关操作系统的发展主要是按照时间线索叙述的,且在时间上是有重叠的。每个发展并不是等到先前ー种发展完成后オ开始。存在着大量的重叠,更不用说还存在有不少虚假的开始和终结时间。请读者把这里的文字叙述看成是ー种指引,而不是盖棺定论。

第一台真正的数字计算机是英国数学家CharlesBabbage（1792—1871）设计的。尽管Babbage花费了他几乎一生的时间和财产,试图建造他的“分析机”,但是他始终未能让机器正常运转,因为它是ー台纯机械的数字计算机,他所在时代的技术不能生产出他所需要的高精度轮子、齿轮和轮牙。毫无疑问,这台分析机没有操作系统。

有一段有趣的历史花絮,Babbage认识到他的分析机需要软件,所以他雇佣了一个名为AdaLovelace的年轻妇女,这是世界上第一个程序员,而她是著名的英国诗人LordByron的女儿。程序设计语言Ada是以她命名的。

### 1.2.1 第一代（1945~1955）:真空管和穿孔卡片

从Babbage失败之后一直到第二次世界大战,数字计算机的建造几乎没有什么进展,第二次世界大战刺激了有关计算机研究工作的爆炸性开展。艾奥瓦州立大学的JohnAtanasoff教授和他的学生CliffordBerry建造了被认为是第一台可工作的数字计算机。该机器使用了300个真空管。大约在同时,KonradZuse在柏林用继电器构建了Z3计算机。1944年,一群科学家（包括AlanTuring）在英格兰布莱切利庄园构建了Colossus并为其编程,HowardAiken在哈佛大学建造了MarkI,宾タ法尼亚大学的WilliamMauchley和他的学生J.PresperEckert建造了ENIAC。这些机器有的是二进制的,有的使用真空管,有的是可编程的,但是都非常原始,甚至需要花费数秒时间才能完成最简单的运算。

在那个年代里,同一个小组的人（通常是工程师们）设计、建造、编程、操作并维护一台机器。所有的程序设计是用纯粹的机器语言编写的,甚至更糟糕,需要通过将上千根电缆接到插件板上连接成电路,以便控制机器的基本功能。没有程序设计语言（甚至汇编语言也没有）,操作系统则从来没有听说过。使用机器的一般方式是,程序员在墙上的机时表上预约一段时间,然后到机房中将他的插件板接到计算机里,在接下来的几小时里,期盼正在运行中的两万多个真空管不会烧坏。那时,所有的计算问题实际上都只是简单的数学运算,如制作正弦、余弦、对数表或者计算炮弹弹道等。

到了20世纪50年代初有了改进,出现了穿孔卡片,这时就可以将程序写在卡片上,然后读入计算机而不用插件板,但其他过程则依然如旧。

### 1.2.2 第二代（1955—1965）:晶体管和批处理系统

20世纪50年代晶体管的发明极大地改变了整个状况。计算机已经很可靠,厂商可以成批地生产并销售计算机给用户,用户可以指望计算机长时间运行,完成一些有用的工作。此时,设计人员、生产人员、操作人员、程序人员和维护人员之间第一次有了明确的分エ。

这些机器,现在被称作大型机（mainframe）,锁在有专用空调的大房间中,由专业操作人员运行。只有少数大公司、重要的政府部门或大学オ接受数百万美元的标价。要运行一个作业（job,即ー个或ー组程序）,程序员首先将程序写在纸上（用FORTRAN语言或汇编语言）,然后穿孔成卡片,再将卡片盒带到输入室,交给操作员,接着就喝咖啡直到输出完成。

计算机运行完当前的任务后,其计算结果从打印机上输出,操作员到打印机上撕下运算结果并送到输出室,程序员稍后就可取到结果。然后,操作员从已送到输入室的卡片盒中读入另ー个任务。如果需要FORTRAN编译器,操作员还要从文件柜把它取来读入计算机。当操作员在机房里走来走去时许多机时被浪费掉了。

由于当时的计算机非常昂贵,人们很自然地要想办法减少机时的浪费。通常采用的解决方法就是批处理系统（batchsystem）o其思想是:在输入室收集全部的作业,然后用一台相对便宜的计算机如IBM1401计算机将它们读到磁带上。IBM1401计算机适用于读卡片、复制磁带和输出打印,但不适用于数值运算。另外用较昂贵的计算机如IBM7094来完成真正的计算。这些情况如图1-3所示。

![image-20240914174328056](现代操作系统_上.assets/image-20240914174328056.png)

> 图1-3一种早期的批处理系统:a）程序员将卡片拿到1401机处・b）1401机将批处理作业读到磁带上,c）操作员将输入带送至7094机Id）7094机进行计算,e）操作员将输出磁带送到1401机∣f）1401机打印输出

在收集了大约ー个小时的批量作业之后,这些卡片被读进磁帯，然后磁带被送到机房里并装到磁带机上。随后,操作员装入ー个特殊的程序（现代操作系统的前身）,它从磁带上读入第一个作业并运行,其输出写到第二盘磁帯上,而不打印。毎个作业结束后,操作系统自动地从磁带上读入下ー个作业并运行。当ー批作业完全结束后,操作员取下输入和输出磁带,将输入磁带换成下ー批作业,并把输出磁带拿到ー台1401机器上进行脱机（不与主计算机联机）打印。

典型的输入作业结构如图1-4所示。ー开始是$JOB卡片,它标识出所需的最大运行时间（以分钟为单位）、计费账号以及程序员的名字。接着是$FORTRAN卡片,通知操作系统从系统磁带上装入FORTRAN语言编译器。之后就是待编译的源程序,然后是$LOAD卡片,通知操作系统装入编译好的目标程序。接着是$RUN卡片,告诉操作系统运行该程序并使用随后的数据。最后,$END卡片标识作业结束。这些基本的控制卡片是现代shell和命令解释器的先驱。

![image-20240914174346874](现代操作系统_上.assets/image-20240914174346874.png)

第二代大型计算机主要用于科学与工程计算,例如,解偏微分方程。这些题目大多用FORTRAN语言和汇编语言编写。典型的操作系统是FMS（FORTRANMonitorSystem,FORTRAN监控系统）和IBSYS（IBM为7094机配备的操作系统）。

### 1.2.3 第三代（1965〜1980）:集成电路和多道程序设计

20世纪60年代初,大多数计算机厂商都有两条不同并且完全不兼容的生产线。一条是面向字的大型科学用计算机,诸如IBM7094,主要用于エ业强度的科学和工程计算。另一条是面向字符的商用计算机,诸如IBM1401,银行和保险公司主要用它从事磁带归档和打印服务。

开发和维护两种完全不同的产品,对厂商来说是昂贵的。另外,许多新的计算机用户ー开始时只需要一台小计算机,后来可能又需要一台较大的计算机,而且希望能够更快地执行原有的程序。

IBM公司试图通过引入System/360来一次性地解决这两个问题。360是一个软件兼容的计算机系列,其低档机与1401相当,高档机则比7094功能强很多。这些计算机只在价格和性能（最大存储器容量、处理器速度、允许的シ。设备数量等）上有差异。由于所有的计算机都有相同的体系结构和指令集,因此,在理论上,为ー种型号机器编写的程序可以在其他所有型号的机器上运行。（但就像传言YogiBerra曾说过的那样:“在理论上，理论和实际是一致的,而实际上,它们并不是。”）既然360被设计成既可用于科学计算,又可用于商业计算,那么一个系列的计算机便可以满足所有用户的要求。在随后的几年里,IBM使用更现代的技术陆续推出了360的后续机型,如著名的370、4300,3080和3090系列。zSeries是这个系列的最新机型,不过它与早期的机型相比变化非常之大。

360是第一个采用（小规模）集成电路（1C）的主流机型,与采用分立晶体管制造的第二代计算机相比,其性能/价格比有很大提高。360很快就获得了成功,其他主要厂商也很快采纳了系列兼容机的思想。这些计算机的后代仍在大型的计算中心里使用。现在,这些计算机的后代经常用来管理大型数据库（如航班订票系统）或作为Web站点的服务器,这些服务器每秒必须处理数千次的请求。

“单ー家族”思想的最大优点同时也是其最大的缺点。原因在于所有的软件（包括操作系统OS/360）原本都打算能够在所有机器上运行。从小的代替1401把卡片复制到磁带上的机器,到用于代替7094进行气象预报及其他繁重计算的大型机;从只能带很少外部设备的机器到有很多外设的机器,从商业领域到科学计算领域等。总之,它要有效地适用于所有这些不同的用途。

IBM无法写出同时满足这些相互冲突需要的软件（其他公司也不行）。其结果是ー个庞大的又极其复杂的操作系统,它比FMS大了约2〜3个数量级规模。其中包含数千名程序员写的数百万行汇编语言代码,也包含成千上万处错误,这就导致IBM不断地发行新的版本试图更正这些错误。每个新版本在修正老错误的同时又引入了新错误,所以随着时间的流逝,错误的数量可能大致保持不变。

OS/360的设计者之一FredBrooks后来写过一本既诙谐又尖锐的书（Brooks,1995）,描述他在开发OS/360过程中的经验。我们不可能在这里复述该书的全部内容,不过其封面已经充分表达了FredBrooks的观点------群史前动物陷入泥潭而不能自拔。Silberschatz等人（2012）的封面也表达了操作系统如同恐龙一般的类似观点。

抛开OS/360的庞大和存在的问题,OS/360和其他公司类似的第三代操作系统的确合理地满足了大多数用户的要求。同时,它们也使第二代操作系统所缺乏的几项关键技术得到了广泛应用。其中最重要的应该是多道程序设计（multiprogramming）。在7094机上,若当前作业因等待磁带或其他I/O操作而暂停,CPU就只能简单地踏步直至该I/O完成。对于CPU操作密集的科学计算问题,I/O操作较少,因此浪费的时间很少。然而,对于商业数据处理,I/O操作等待的时间通常占到80%〜90%,所以必须采取某种措施减少（昂贵的）CPU空闲时间的浪费。

解决方案是将内存分几个部分,每一部分存放不同的作业,如图1・5所示。当ー个作业等待I/O操作完成时,另ー个作业可以使用CPU。如果内存中可以同时存放足够多的作业,则CPU利用率可以接近100%。在内存中同时驻留多个作业需要特殊的硬件来对其进行保护,以避免作业的信息被窃取或受到攻击。360及其他第三代计算机都配有此类硬件。

![image-20240914174401835](现代操作系统_上.assets/image-20240914174401835.png)

> 图1-5 ー个内存中有三个作 业的多道程序系统

第三代计算机的另ー个特性是,卡片被拿到机房后能够很快地将作业从卡片读入磁盘。于是,任何时刻当一个作业运行结束时,操作系统就能将一个新作业从磁盘读出,装进空出来的内存区域运行。这种技术叫作同时的外部设备联机操作（SimultaneousPeripheralOperationOnLine,SPOOLing）,该技术同时也用于输出。当采用了SPOOLiiig技术后,就不再需要IBM1401机,也不必再将磁带搬来搬去了。

第三代操作系统很适用于大型科学计算和繁忙的商务数据处理,但其实质上仍旧是批处理系统。许多程序员很怀念第一代计算机的使用方式,那时他们可以几个小时地独占一台机器,可以即时地调试他们的程序。而对第三代计算机而言,从ー个作业提交到运算结果取回往往长达数小时,更有甚者,一个逗号的误用就会导致编译失败,而可能浪费了程序员半天的时间,程序员并不喜欢这样。

程序员的希望很快得到了响应,这种需求导致了分时系统（timesharing）的出现。它实际上是多道程序的ー个变体,每个用户都有一个联机终端。在分时系统中,假设有20个用户登录,其中17个在思考、谈论或喝咖啡,则CPU可分配给其他三个需要的作业轮流执行。由于调试程序的用户常常只发出简短的命令（如编译ー个五页的源文件）,而很少有长的费时命令（如上百万条记录的文件排序）,所以计算机能够为许多用户提供快速的交互式服务,同时在CPU空闲时还可能在后台运行一个大作业。第一个通用的分时系统—兼容分时系统（CompatibleTimeSharingSystem,CTSS）,是MIT（麻省理工学院）在一台改装过的7094机上开发成功的（Corbat6等人,1962）。但直到第三代计算机广泛采用了必需的保护硬件之后,分时系统オ逐渐流行开来。

在CTSS成功研制之后，MIT,贝尔实验室和通用电气公司（GE,当时ー个主要的计算机制造厂商）决定开发ー种“公用计算服务系统”,即能够同时支持数百名分时用户的ー种机器。它的模型借鉴了供电系统—当需要电能时,只需将电气设备接到墻上的插座即可,于是,在合理范围内,所需要的电能随时可提供。该系统称作MULTICS（MULTiplexedInformationandComputingService）,其设计者着眼于建造满足波士顿地区所有用户计算需求的一台机器。在当时看来,仅仅40年之后,就能成百万台地销售（价值不到1000美元）速度是GE-645主机10000倍的计算机,完全是科学幻想。这种想法同现在关于穿越大西洋的超音速海底列车的想法一样,是幻想。

MULTICS是ー种混合式的成功。尽管这台机器具有较强的I/O能力,却要在一台仅仅比Intel386PC性能强一点的机器上支持数百个用户。可是这个想法并不像表面上那么荒唐,因为那时的人们已经知道如何编写精练的高效程序,虽然这种技巧随后逐渐丢失了。有许多原因造成MULTICS没有能够普及到全世界,至少它不应该采用PL”编程语言编写,因为PLハ编译器推迟了好几年オ完成,好不容易完成的编译器又极少能够成功运行。另外,当时的MULTICS有太大的野心,犹如19世纪中期CharlesBabbage的分析机。

简要地说,MULTICS在计算机文献中播撒了许多原创的概念,但要将其造成一台真正的机器并想实现商业上的巨大成功的难度超出了所有人的预料。贝尔实验室退出了,通用电气公司也退出了计算机领域。但是MIT坚持下来并且最终使MULTICS成功运行。MULTICS最后成为商业产品,由购买了通用电气公司计算机业务的公司Honeywell销售,并安装在世界各地80多个大型公司和大学中。尽管MULTICS的数量很小,但是MULTICS的用户却非常忠诚,例如,通用汽车、福特和美国国家安全局直到20世纪90年代后期,在试图让Honeywell更新其硬件多年之后,オ关闭了MULTICS系统,而这已经是在MULTICS推出之后30年了。

到20世纪末,计算服务的概念已经被遗弃,但是这个概念却以云计算（cloudcomputing）的形式回归。在这种形式中,相对小型的计算机（包括智能手机、平板电脑等）连接到巨大的远程数据中心的服务器,本地计算机处理用户界面,而服务器进行计算。回归的动机可能是多数人不愿意管理日益过分复杂的计算机系统,宁可让那些运行数据中心的公司的专业团队去做。电子商务已经向这个方向演化了,各种公司在多处理器的服务器上经营各自的电子商场,简单的客户端连接着多处理器服务器,这同MULTICS的设计精神非常类似。

尽管MULTICS在商业上失败了,但MULTICS对随后的操作系统（特别是UNIX和它的衍生系统,如FreeBSD、Linux、iOS以及Android）却有着巨大的影响,详情请参阅有关文献和书籍（Corbat6等人,19721Corbato⅛Vyssotsky,1965,Daley和Dennis,1968；Organick,1972；Saltzer,1974）.还有一个活跃的Web站点www.multicians.org,上面有大量关于系统、设计人员及其用户的信息资料。

另ー个第三代计算机的主要进展是小型机的崛起,以1961年DEC的PDP-1作为起点。PDP-1计算机只有4K个18位的内存,每台售价120000美元（不到IBM7094的5%）,该机型非常热销。对于某些非数值的计算,它和7094几乎ー样快。PDP-1开辟了一个全新的产业。很快有了一系列PDP机型（与IBM系列机不同,它们互不兼容）,其顶峰为PDP-11。

曾参与MULTICS研制的贝尔实验室计算机科学家KenThompson,后来找到ー台无人使用的PDP-7机器,并开始开发ー个简化的单用户版MULTICS。他的工作后来导致了UNIX操作系统的诞生。接着,UNIX在学术界、政府部门以及许多公司中流行。

UNIX的历史已经在别处讲述了（例如Salus,1994）。这段故事的部分放在第10章中介绍。现在,有充分的理由认为,由于到处可以得到源代码,多个机构发展了自己的（不兼容）版本,从而导致了混乱。UNIX有两个主要的版本，即AT&T的SystemV和加州大学伯克利分校的BSD（BerkeleySoftwareDistribution）o当然还有一些小的变种。为了使编写的程序能够在任何版本的UNIX上运行,IEEE提出了ー个UNIX的标准，称作POSIX,目前大多数UNIX版本都支持它。POSIX定义了一个凡是UNIX必须支持的小型系统调用接口。事实上,某些其他操作系统也支持POSIX接口。

顺便值得一提的是,在1987年,本书作者发布「ー个UNIX的小型克隆,称为MINIX,用于教学目的。在功能上,MINIX非常类似于UNIX,包括对POSIX的支持。从那时以后,MINIX的原始版本已经演化为MINIX3,该系统是高度模块化的,并专注于高可靠性。它具有快速检测和替代有故障甚至已崩溃模块（如i/o设备驱动器）的能力,不用重启也不会干扰运行着的程序。它致カ于提高可靠性和可用性。有一本叙述其内部操作并在附录中列出源代码的书（Tanenbaum和Woodhull,2006）1该书现在仍然有售。在www.minix3.org上,MINIX3是免费使用的（包括所有源代码）。

对UNIX版本免费产品（不同于教育目的）的愿望，促使芬兰学生LinusTorvalds编写了Lin”。这个系统直接受到在MINIX上开发的启示,而且最初支持各种MINIX的功能（例如MINIX文件系统）。尽管它已经被很多人通过多种方式扩展，但是该系统仍然保留了某些与MINIX和UNIX共同的基本结构。对Linux和开放源码运动的具体历史感兴趣的读者可以阅读GlynMoody（2001）o本书所叙述的有关UNIX的多数内容,也适用于SystemV、MINIX,Linux以及UNIX的其他版本和克隆。

### 1.2.4 第四代（1980年至今）:个人计算机

随着LSI（大规模集成）电路的发展,在每平方厘米的硅片芯片上可以集成数千个晶体管，个人计算机时代到来了。从体系结构上看,个人计算机（最早称为微型计算机）与PDP-11并无二致,但就价格而言却相去甚远。以往,公司的一个部门或大学里的一个院系オ配备一台小型机,而微处理器却使每个人都能拥有自己的计算机。

1974年,当Intel8080—第亠代通用8位CPU出现时,Intel希望有一个用干8080的操作系统,部分是为了测试目的。Intel请求其顾问GaryKildall编写。Kildall和一位朋友首先为新推出的ShugartAssociates8英寸软盘构造了一个控制器,并把这个软磁盘同8080相连,从而制造了第一个配有磁盘的微型计算机。然后Kildall为它写了一个基于磁盘的操作系统,称为CP/M（ControlProgramforMicrocomputer）β由于Intel不认为基于磁盘的微型计算机有什么前景,所以当Kildall要求CP/M的版权时,Intel同意了他的要求。Kildall于是组建了一家公司DigitalResearch,进ー步开发和销售CP/M。

1977年,DigitalResearch重写了CP/M,使其可以在使用808〇、ZilogZ80以及其他CPU芯片的多种微型计算机上运行,从而完全控制了微型计算机世界达5年之久。

在20世纪80年代早期,IBM设计了IBMPC并寻找可在上面运行的软件。来自IBM的人员同BillGates联系有关他的BASIC解释器的许可证事宜,他们也询问他是否知道可在PC上运行的操作系统。Gates建议IBM同DigitalResearch联系,即当时世界上主宰操作系统的公司。在做出毫无疑问是近代历史上最糟的商业决策后,Kildall拒绝与IBM会见,代替他的是一位次要人员。更糟糕的是,他的律师甚至拒绝签署IBM的有关尚未公开的PC的保密协议。结果，IBM回头询问Gates可否提供给他们ー个操作系统。

在IBM返回来时,Gates了解到ー家本地计算机制造商SeattleComputerProducts有合适的操作系统DOS（DiskOperatingSystem）o他联系对方并提出购买（宣称フ5000美元）,对方接受了。然后Gates提供给IBM成套的DOS/BASIC,IBM也接受了。IBM希望做某些修改,于是Gates雇佣了写DOS的作者TimPaterson进行修改。修改版称为MS-DOS（MicrosoftDiskOperatingSystem）,并且很快主导了IBMPC市场。同Kildall试图将CP/M每次卖给用户ー个产品相比（至少开始是这样）,这里一个关键因素是Gates极其聪明的决策—将MS-DOS与计算机公司的硬件捆绑在ー起出售。在所有这一切烟消云散之后,Kilda∏突然不幸去世,其原因从来没有公布过。

1983年,IBMPC后续机型IBMPC/AT推出,配有k∏el80286CPU。此时,MS-DOS已经确立了地位,而CP/M只剩下最后的支撑。MS-DOS后来在80386和80486中得到广泛的应用。尽管MS-DOS的早期版本是相当原始的,但是后期的版本提供了更多的先进功能,包括许多源自UNIX的功能。（微软对UNIX是如此娴熟,甚至在公司的早期销售过ー个微型计算机版本,称为XENIX。）

用于早期微型计算机的CP/M、MS-DOS和其他操作系统,都是通过键盘输入命令的。由于DougEngelbart于20世纪60年代在斯坦福研究院（StanfordResearchInstitute）工作,这种情况最终有了改变。DougEngelbart发明了图形用户界面,包括窗ロ、图标、菜单以及鼠标。这些思想被XeroxPARC的研究人员采用,并用在了他们所研制的机器中。

一天,SteveJobs（他和其他人ー起在车库里发明了苹果计算机）访问PARC,ー看到GUI,立即意识到它的潜在价值,而Xerox管理层恰好没有认识到。这种战略失误的庞大比例,导致名为《摸索未来》ー书的出版（Smith和Alexander,1988）。Jobs随后着手设计了带有GUI的苹果计算机。这个项目导致了Lisa的推出,但是Lisa过于昂贵,所以在商业上失败了°Jobs的第二次尝试,即苹果Macintosh,取得了巨大的成功,这不仅是因为它比Lisa便宜得多,而且它还是用户友好的（userfriendly）,也就是说,它是为那些不仅没有计算机知识而且根本不打算学习计算机的用户准备的。在图形设计、专业数码摄影以及专业数字视频制作的创意世界里,Macintosh得到广泛的应用,这些用户对苹果公司及Macintosh有着极大的热情。1999年,苹果公司采用了一种内核,它来自本是为替换BSDUNIX内核而开发的卡内基・梅隆大学的Mach微核。因此,尽管有着截然不同的界面,但MACOSX是基于UNIX的操作系统。

在微软决定构建MS-DOS的后继产品时,受到了Macintosh成功的巨大影响。微软开发了名为Windows的基于GUI的系统,早期它运行在MS-DOS上层（它更像shell而不像真正的操作系统）。在从1985年至1995年的十年间,Windows只是运行在MS-DOS上层的ー个图形环境。然而,至U了1995年,一个独立的Windows版本具有许多操作系统功能的Windows95发布了。Windows95仅仅把底层的MS-DOS作为启动和运行老的MS-DOS程序之用。1998年,ー个稍做修改的系统Windows98发布。不过Windows95和Windows98仍然使用了大量16位Intel汇编语言。

另ー个微软操作系统是Wind嬴sNT（NT表示新技术）,它在一定的范围内同Windows95兼容,但是内部是完全新编写的。它是ー个32位系统。WindowsNT的首席设计师是DavidCutler,他也是VAXVMS操作系统的设计师之ー,所以有些VMS的概念用在了NT上。事实上,NT中有太多来自VMS的思想,所以VMS的所有者DEC公司控告了微软公司。法院对该案件判决的结果引出了一大笔需要用多位数字表达的金钱。微软公司期待NT的第一个版本可以消灭MS-DOS和其他的Windows版本,因为NT是ー个巨大的超级系统,但是这个想法失败了。只有WindowsNT4.0踏上了成功之路,特别在企业网络方面取得了成功。1999年年初,WindowsNT5.0改名为Windows2000。微软期望它成为Windows98和WindowsNT4.0的接替者。

不过这两个版本都不太成功,于是微软公司发布了Windows98的另ー个版本,名为WindowsMe（千年版）。2001年,发布了Windows2000的ー个稍加升级的版本,称为WindowsXP。这个版本的寿命比较长（6年）,基本上替代了Windows所有原先版本。

版本的更替还在继续。在Windows2000之后,微软将Windows家族分解成客户端和服务器端两条路线。客户端基于XP及其后代,而服务器端则包括WindowsServer2003和Windows2008。为嵌入式系统打造的第三条路线也随后出现。这些Windows版本都以服务包（servicepack）的形式派生出各自的变种。这足以让ー些管理员（以及操作系统书籍作者）发疯。

200フ年1月,微软公司发布了WindowsXP的后继版,名为Vista。它有一个新的图形接口、改进的安全性以及许多新的或升级的用户程序。微软公司希望Vista能够完全替代XP,但事与愿违。相反,由于对系统要求高、授权条件严格以及对数字版权管理（DigitalRightsManagement,ー种使用户更难复制被保护资料的技术）的支持,Vista受到了大量批评,负面报道不断。

随着全新的且并不那么消耗资源的操作系统Windows7的到来,很多人决定跳过Vista。Windows7并没有引进很多特性,但它相对较小且十分稳定。不到三周时间,Windows7就抢占了比Vista七周获得的还多的市场份额。2012年,微软发布了它的后继者,即针对触摸屏、拥有全新外观和体验的Windows8。微软希望这个全新设计会成为台式机、便携式电脑、笔记本电脑、平板电脑、手机、家庭影院电脑等各种设备上的主流操作系统。然而,到目前为止,其市场渗透相比Windowsフ而言要慢很多。

个人计算机世界中的另ー个主要竞争者是UNIX（及其各种变种）。UNIX在网络和企业服务器等领域很强大,在台式机、笔记本电脑、平板电脑以及智能手机上也很常见。在基于x86的计算机上,Linux成为学生和不断增加的企业用户替代Windows的流行选择。

顺便说明一下,在本书中我们使用x86这个术语代表所有使用指令集体系结构家族的现代处理器,这类处理器的源头可以追溯到20世纪70年代的8086芯片。很多像AMD和Intel这样的公司制造的处理器底层实现大相径庭:32位或64位、核或多或少、流水线或深或浅,等等。然而对程序员而言,它们看起来都是相似的,并且都能运行35年前写的8086代码。在需要强调不同处理器的差异时,我们会提到明确的模型,并且使用メ86∙32和x86-64分别表示32位和64位的变种。

FreeBSD是ー个源自Berkeley的BSD项目,也是ー个流行的UNIX变体。所有现代Macintosh计算机都运行着FreeBSD的某个修改版。在使用高性能RISC芯片的工作站上,UNIX系统也是ー种标准配置。它的衍生系统在移动设备上被广泛使用,例如那些运行iOS7和Android的设备。

尽管许多UNIX用户,特别是富有经验的程序员更偏好基于命令的界面而不是GUI,但是几乎所有的UNIX系统都支持由MIT开发的称为XWindow的视窗系统（如众所周知的XU）。这个系统具有基本的视窗管理功能,允许用户通过鼠标创建、删除、移动和变比视窗。对于那些希望有图形系统的UNIX用户,通常在XII之上还提供ー个完整的GUI,如Gnome或KDE,从而使得UNIX在外观和感觉上类似于Macintosh或MicrosoftWindows.

另ー个开始于20世纪80年代中期的有趣发展是,那些运行网络操作系统和分布式操作系统（Tanenbaum和VanSteen,2007）的个人计算机网络的增长。在网络操作系统中,用户知道多台计算机的存在,能够登录到ー台远程机器上并将文件从一台机器复制到另一台机器,每台计算机都运行自己本地的操作系统,并有自己的本地用户（或多个用户）。

网络操作系统与单处理器的操作系统没有本质区别。很明显,它们需要一个网络接口控制器以及ー些底层软件来驱动它,同时还需要一些程序来进行远程登录和远程文件访问,但这些附加成分并未改变操作系统的本质结构。

相反,分布式操作系统是以ー种传统单处理器操作系统的形式出现在用户面前的,尽管它实际上是由多处理器组成的。用户应该不知晓自己的程序在何处运行或者自己的文件存放于何处,这些应该由操作系统自动和有效地处理。

真正的分布式操作系统不仅仅是在单机操作系统上增添ー小段代码,因为分布式系统与集中式系统有本质的区别。例如,分布式系统通常允许一个应用在多台处理器上同时运行,因此,需要更复杂的处理器调度算法来获得最大的并行度优化。

网络中的通信延迟往往导致分布式算法必须能适应信息不完备、信息过时甚至信息不正确的环境。这与单机系统完全不同,对于后者,操作系统掌握着整个系统的完备信息。

### 1.2.5 第五代（1990年至今）:移动计算机

自从20世纪40年代连环漫画中的DickTracy警探对着他的“双向无线电通信腕表”说话开始,人们就在渴望ー款无论去哪里都可以随身携带的交流设备。第一台真正的移动电话出现在1946年并且重达80斤。你可以带它去任何地方,前提是你得有一辆拉着它的汽车。

第一台真正的手持电话出现在20世纪70年代,大约2斤重,绝对属于轻量级。它被人们爱称为“转头”。很快,每个人都想要一块这样的“砖头ス现在,移动电话已经渗入全球90%人口的生活中。我们不仅可以通过便携电话和腕表打电话,在不久的将来还可以通过眼镜和其他可穿戴设备打电话。而且,手机这种东西已不再那么引人注目,我们在车水马龙间从容地收发邮件、上网冲浪、给朋友发信息、玩游戏,一切都是那么习以为常。

虽然在电话设备上将通话和计算合二为ー的想法在20世纪70年代就已经出现了,但第一台真正的智能手机直到20世纪90年代中期オ出现.这部手机就是诺基亚发布的N9000,它真正做到了将通常处于独立工作状态的两种设备合二为ー:手机和个人数字助理(PersonalDigitalAssistant,PDA)o1997年,爱立信公司为它的GS88uPenelope"手机创造出未语智能手机(smartphone)。

随着智能手机变得十分普及,各种操作系统之间的竞争也变得更加激烈,并且形势比个人电脑领域更加模糊不清。在编写本书时,谷歌公司的Android是最主流的操作系统,而苹果公司的iOS也牢牢占据次席,但这并不会是常态,在接下来的几年可能会发生很大变化。在智能手机领域唯一可以确定的是,长期保持在巅峰并不容易。

毕竟,在智能手机出现后的第一个十年中,大多数手机自首款产品出厂以来都运行着SymbianOS。Symbian操作系统被许多主流品牌选中，包括三星、索尼爱立信和摩托罗拉,特别是诺基亚也选择了它。然而,其他操作系统已经开始侵吞Symbian的市场份额,例如RIM公司的BlackberryOS(2002年引入智能手机)和苹果公司的iOS(2007年随第一代iPhone发布)。很多公司都预期RIM能继续主导商业市场,而iOS会成为消费者设备中的王者。然而,Symbian的市场份额骤跌。2011年,诺基亚放弃Symbian并且宣布将WindowsPhone作为自己的主流平台。在一段时间内,苹果公司和RIM公司是市场的宠儿(虽然不像曾经的Symbian那样占有绝对地位),但谷歌公司2008年发布的基于Linux的操作系统Android,没有花费太长时间就追上了它的竞争对手。

对于手机厂商而言,Android有着开源的优势,获得许可授权后便可使用。于是,厂商可以修改它并轻松地适配自己的硬件设备。并且,Android拥有大量软件开发者,他们大多通晓Java编程语言。即使如此,最近几年也显示出Android的优势可能不会持久,并且其竞争对手极其渴望从它那里夺回ー些市场份额〇我们将在10.8节进ー步介绍Android。

## 1.3 计算机硬件简介

操作系统与运行该操作系统的计算机硬件联系密切。操作系统扩展了计算机指令集并管理计算机的资源。为了能够工作,操作系统必须了解大量的硬件,至少需要了解硬件如何面对程序员。出于这个原因,这里我们先简要地介绍现代个人计算机中的计算机硬件,然后开始讨论操作系统的具体工作细节。

从概念上讲,一台简单的个人计算机可以抽象为类似于图1-6中的模型。CPU、内存以及I/O设备都由一条系统总线连接起来并通过总线与其他设备通信。现代个人计算机结构更加复杂,包含多重总线,我们将在后面讨论。目前,这ー模式还是够用的。在下面各小节中,我们将简要地介绍这些部件,并且讨论ー些操作系统设计师所考虑的硬件问题。毫无疑问,这是ー个非常简要的概括介绍。现在有不少讨论计算机硬件和计算机组织的书籍。其中两本有名的书分别是Tanenbaum和Austin(2012)以及Patterson和Hennessy(2013)。

![image-20240914174428443](现代操作系统_上.assets/image-20240914174428443.png)

> 图1-6简单个人计算机中的一些部件

### 1.3.1 处理器

计算机的“大脑”是CPU,它从内存中取出指令并执行之。在每个CPU基本周期中,首先从内存中取出指令,解码以确定其类型和操作数,接着执行之,然后取指、解码并执行下一条指令。按照这一方式,程序被执行完成。

每个CPU都有一套可执行的专门指令集。所以,x86处理器不能执行ARM程序,而ARM处理器也不能执行x86程序。由干用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多,因此,所有的CPU内都有一些用来保存关键变量和临时数据的寄存器。这样,通常在指令集中提供ー些指令,用以将一个字从内存调入寄存器,以及将一个字从寄存器存入内存。其他的指令可以把来自寄存器、内存的操作数组合,或者用两者产生一个结果,如将两个字相加并把结果存在寄存器或内存中。

除了用来保存变量和临时结果的通用寄存器之外,多数计算机还有一些对程序员可见的专用寄存器。其中之一是程序计数器,它保存了将要取出的下一条指令的内存地址。在指令取出之后,程序计数器就被更新以便指向后继的指令。

另ー个寄存器是堆栈指针,它指向内存中当前栈的顶端。该栈包含了每个执行过程的栈帧。ー个过程的栈帧中保存了有关的输入参数、局部变量以及那些没有保存在寄存器中的临时变量。

当然还有程序状态字(ProgramStatusWord,PSW)寄存器。这个寄存器包含了条件码位(由比较指令设置)、CPU优先级、模式(用户态或内核态),以及各种其他控制位。用户程序通常读入整个PSW,但是,只对其中的少量字段写入。在系统调用和I/O中,PSW的作用很重要。

操作系统必须知晓所有的寄存器。在时间多路复用(timemultiplexing)CPU中,操作系统经常会中止正在运行的某个程序并启动(或再启动)另ー个程序。每次停止ー个运行着的程序时,操作系统必须保存所有的寄存器值,这样在稍后该程序被再次运行时,可以把这些寄存器重新装入。

为了改善性能,CPU设计师早就放弃了同时读取、解码和执行一条指令的简单模型。许多现代CPU具有同时取出多条指令的机制。例如,ー个CPU可以有单独的取指单元、解码单元和执行单元，于是当它执行指令〃时,还可以对指令れ+1解码,并且读取指令ス+2。这样的机制称为流水线(pipeline)»图l∙7a是一个有着三个阶段的流水线示意图。更长的流水线也是常见的。在多数的流水线设计中,一旦一条指令被取进流水线中,它就必须被执行完毕,即便前一条取出的指令是条件转移,它也必须被执行完毕。流水线使得编译器和操作系统的编写者很头疼,因为它造成了在机器中实现这些软件的复杂性问题,而机器必须处理这些问题。

![image-20240914174446966](现代操作系统_上.assets/image-20240914174446966.png)

> 图1-7 a)有三个阶段的流水线,b)ー个超标量CPU

比流水线更先进的设计是超标量CPU,如图l-7b所示。在这种设计中,有多个执行单元,例如,一个CPU用干整数算术运算,ー个CPU用于浮点算术运算,ー个CPU用于布尔运算。两个或更多的指令被同时取出、解码并装入暂存缓冲区中,直至它们执行完毕。只要有一个执行单元空闲,就检査保持缓冲区中是否还有可处理的指令,如果有,就把指令从缓冲区中移出并执行之。这种设计存在ー种隐含的作用,即程序的指令经常不按顺序执行。在多数情况下,硬件负责保证这种运算的结果与顺序执行指令时的结果相同,但是,仍然有部分令人烦恼的复杂情形被强加给操作系统处理,我们在后面会讨论这种情况。

除了用在嵌入式系统中的非常简单的CPU之外,多数CPU都有两种模式,即前面已经提及的内核态和用户态。通常,在PSW中有一个二进制位控制这两种模式。当在内核态运行时,CPU可以执行指令集中的每一条指令,并且使用硬件的每种功能。在台式机和服务器上,操作系统在内核态下运行,从而可以访问整个硬件。而在大多数嵌入式系统中,一部分操作系统运行在内核态,其余的部分则运行在用户态。

相反,用户程序在用户态下运行,仅允许执行整个指令集的ー个子集和访问所有功能的ー个子集。一般而言,在用户态中有关1/。和内存保护的所有指令是禁止的。当然,将PSW中的模式位设置成内核态也是禁止的。

为了从操作系统中获得服务,用户程序必须使用系统调用（systemcall）以陷入内核并调用操作系统。TRAP指令把用户态切换成内核态,并启用操作系统。当有关工作完成之后,在系统调用后面的指令把控制权返回给用户程序。在本章的后面我们将具体解释系统调用过程,但是在这里,请读者把它看成是ー个特别的过程调用指令,该指令具有从用户态切换到内核态的特别能力。

有必要指出的是,计算机使用陷阱而不是一条指令来执行系统调用。其他的多数陷阱是由硬件引起的,用于警告有异常情况发生,如试图被零除或浮点下溢等。在所有的情况下,操作系统都得到控制权并决定如何处理异常情况。有时,由于出错的原因,程序不得不停止。在其他情况下可以忽略出错（如下溢数可以被置为零）。最后,若程序已经提前宣布它希望处理某类条件,那么控制权还必须返回给该程序,让其处理相关的问题。

**多线程和多核芯片**

Moore定律指出,芯片中晶体管的数量毎18个月翻一番。这个“定律”并不是物理学上的某种规律,诸如动量守恒定律等,它是Int»公司的共同创始人GordonMoore对半导体公司快速缩小晶体管能力上的ー个观察结果。Moore定律已经保持了30年,有希望至少再保持10年。在那以后,毎个晶体管中原子的数目会变得太少,并且量子力学将扮演重要角色,这将阻止晶体管尺寸的进ー步缩小。

使用大量的晶体管引发了一个问题:如何处理它们呢?这里我们可以看到ー种处理方式:具有多个功能部件的超标量体系结构。但是,随着晶体管数量的增加,再多晶体管也是可能的。ー个由此而来的必然结果是,在CPU芯片中加入了更大的缓存,人们肯定会这样做,然而,原先获得的有用效果将最终消失。

显然,下ー步不仅是有多个功能部件,某些控制逻辑也会出现多个。1ntelPentium4引入了被称为多线程（multithreading）或超线程（hyperthreading,这是Intel公司的命名）的特性,x86处理器和其他一些CPU芯片就是这样做的,包括SPARC、Power5,IntelXeon和IntelCore系列。近似地说,多线程允许CPU保持两个不同的线程状态,然后在纳秒级的时间尺度内来回切换。（线程是ー种轻量级进程,即ー个运行中的程序。我们将在第2章中具体讨论.）例如,如果某个进程需要从内存中读出ー个字（需要花费多个时钟周期）,多线程CPU则可以切换至另ー个线程。多线程不提供真正的并行处理。在ー个时刻只有一个进程在运行,但是线程的切换时间则减少到纳秒数量级。

多线程对操作系统而言是有意义的,因为每个线程在操作系统看来就像是单个的CPU。考虑ー个实际有两个CPU的系统，每个CPU有两个线程。这样操作系统将把它看成是4个CPU。如果在某个特定时间点上,只有能够维持两个CPU忙碌的工作量，那么在同一个CPU上调度两个线程,而让另ー个CPU完全空转,就没有优势了。这种选择远远不如在毎个CPU上运行ー个线程的效率高。

![image-20240914174505365](现代操作系统_上.assets/image-20240914174505365.png)

> 图a）带有共享L2缓存的4核芯片,  b）带有分离L2缓存的4核芯片

除了多线程,还出现了包含2个或4个完整处理器或内核的CPU芯片。图1-8中的多核芯片上有效地装有4个小芯片,每个小芯片都是ー个独立的CPU（后面将解释缓存）。!ntelXeonPhi和TileraTilePro等处理器,已经炫技般地在一枚芯片上集成了60多个核。要使用这类多核芯片肯定需要多处理器操作系统。

其实在绝对数目方面,没什么能赢过现代的GPU（GraphicsProcessingUnit）oGPU指的是由成千上万个微核组成的处理器。它们擅长处理大量并行的简单计算,比如在图像应用中渲染多边形。它们不太能胜任串行任务,并且很难编程。虽然GPU对操作系统很有用（比如加密或者处理网络传输）,但操作系统本身不太可能运行在GPU上。

### 1.3.2 存储器

在任何ー种计算机中,第二种主要部件都是存储器。在理想情形下,存储器应该极为迅速（快于执行一条指令,这样CPU不会受到存储器的限制）,充分大,并且非常便宜。但是目前的技术无法同时满足这三个目标,于是出现了不同的处理方式。存储器系统采用ー种分层次的结构,如图1-9所示。顶层的存储器速度较高,容量较小,与底层的存储器相比每位成本较高,其差别往往是十亿数量级。

![image-20240914174522438](现代操作系统_上.assets/image-20240914174522438.png)

> 图1-9典型的存储层次结构,图中的数据是非常粗略的估计

存储器系统的顶层是CPU中的寄存器。它们用与CPU相同的材料制成,所以和CPUー样快。显然,访问它们是没有时延的。其典型的存储容量是,在32位CPU中为32x32位,而在64位CPU中为64χ64位。在这两种情形下,其存储容量都小于1KBo程序必须在软件中自行管理这些寄存器（即决定如何使用它们）。

下一层是高速缓存,它多数由硬件控制。主存被分割成高速缓存行（cacheline）,其典型大小为64字节,地址。至63对应高速缓存行（）,地址64至127对应高速缓存行1,以此类推。最常用的高速缓存行放置在CPU内部或者非常接近CPU的高速缓存中。当某个程序需要读ー个存储字时,高速缓存硬件检査所需要的高速缓存行是否在高速缓存中。如果是,称为高速缓存命中,缓存满足了请求,就不需要通过总线把访问请求送往主存。高速缓存命中通常需要两个时钟周期。高速缓存未命中就必须访问内存,这要付出大量的时间代价。由于高速缓存的价格昂贵,所以其大小有限。有些机器具有两级甚至三级高速缓存,每ー级高速缓存比前ー级慢且容量更大。

缓存在计算机科学的许多领域中起着重要的作用,并不仅仅是RAM的缓存行。只要存在大量的资源可以划分为小的部分,那么,这些资源中的某些部分就会比其他部分更频繁地得到使用,通常缓存的使用会带来性能上的改善。操作系统一直在使用缓存。例如,多数操作系统在内存中保留频繁使用的文件（的一部分）,以避免从磁盘中重复地调取这些文件。相似地,类似于

```
∕home∕ast∕projects∕miπix3∕src∕kernel∕clock.c
```

的长路径名转换成文件所在的磁盘地址的结果,也可以放入缓存,以避免重复寻找地址。还有,当ー个Web页面（URL）的地址转换为网络地址（IP地址）后,这个转换结果也可以缓存起来供将来使用。还有许多其他的类似应用。

在任何缓存系统中,都有若干需要尽快考虑的问题,包括:

1）何时把一个新的内容放入缓存。

2）把新内容放在缓存的哪一行上。

3）在需要时,应该把哪个内容从缓存中移走。

4）应该把新移走的内容放在某个较大存储器的何处。

并不是毎个问题的解决方案都符合每种缓存处理。对于CPU缓存中的主存缓存行,每当有缓存未命中时,就会调入新的内容°通常通过所引用内存地址的高位计算应该使用的缓存行。例如,对于64字节的4096个缓存行以及32位地址,其中6~17位用来定位缓存行,而0~5位则用来确定缓存行中的字节。在这个例子中,被移走内容的位置就是新数据要进入的位置,但是在有的系统中未必是这样。最后,当将一个缓存行的内容重写进主存时（该内容被缓存后,可能会被修改）,通过该地址来唯一确定需重写的主存位置。

缓存是ー种好方法,所以现代CPU中设计了两个缓存。第一级或称为L1缓存总是在CPU中，通常用来将已解码的指令调入CPU的执行引擎。对于那些频繁使用的数据字,多数芯片安排有第二个L1缓存。典型的L1缓存大小为16KB。另外,往往还设计有二级缓存,称为L2缓存,用来存放近来使用过的若干兆字节的内存字。L1和L2缓存之间的差别在于时序。对L1缓存的访问,不存在任何延时;而对L2缓存的访问,则会延时1或2个时钟周期。

在多核芯片中,设计师必须确定缓存的位置。在图l∙8a中,一个L2缓存被所有的核共享。In⑹多核芯片采用了这个方法。相反,在图l-8b中,每个核有自己的L2缓存。AMD采用这个方法。不过每种策略都有自己的优缺点。例如,皿⑹的共享L2缓存需要有一种更复杂的缓存控制器,而AMD的方式在设法保持L2缓存一致性上存在困难。

在图1・9的层次结构中,再往下ー层是主存。这是存储器系统的主力。主存通常称为随机访问存储器(RandomAccessMemory,RAM)β过去有时称之为磁芯存储器,因为在20世纪50年代和60年代,使用很小的可磁化的铁磁体制作主存。虽然它们已经绝迹了很多年,但名称还是传承了下来。目前,存储器的容量在几百兆字节到若干吉字节之间,并且其容量正在迅速增长。所有不能在高速缓存中得到满足的访问请求都会转往主存。

除了主存之外,许多计算机已经在使用少量的非易失性随机访问存储器。它们与RAM不同,在电源切断之后,非易失性随机访问存储器并不丢失其内容。只读存储器(ReadOnlyMemory,ROM)在工厂中就被编程完毕,然后再也不能被修改。ROM速度快且便宜。在有些计算机中,用于启动计算机的引导加载模块就存放在ROM中。另外,ー些I/O卡也采用ROM处理底层设备控制。

EEPROM(ElectricallyErasablePROM,电可擦除可编程ROM)和闪存(flashmemory)也是非易失性的,但是与ROM相反,它们可以擦除和重写。不过重写它们需要比写入RAM更高数量级的时间,所以它们的使用方式与ROM相同,而其与众不同的特点使它们有可能通过字段重写的方式纠正所保存程序中的错误。

在便携式电子设备中,闪存通常作为存储媒介。闪存是数码相机中的胶卷,是便携式音乐播放器的磁盘,这仅仅是闪存用途中的两项。闪存在速度上介于RAM和磁盘之间。另外,与磁盘存储器不同,如果闪存擦除的次数过多,就被磨损了。

还有一类存储器是CMOS,它是易失性的。许多计算机利用CMOS存储器保持当前时间和日期。CMOS存储器和递增时间的时钟电路由一块小电池驱动,所以,即使计算机没有上电,时间也仍然可以正确地更新.CMOS存储器还可以保存配置参数,如哪ー个是启动磁盘等。之所以采用CMOS是因为它消耗的电能非常少,ー块エ厂原装的电池往往能使用若干年。但是,当电池开始失效时,计算机就会出现“Abheimer病症”θ—计算机会忘掉记忆多年的事物,比如应该由哪个磁盘启动等。

### 1.3.3 磁盘

下ー个层次是磁盘(硬盘)。磁盘同RAM相比,每个二进制位的成本低了两个数量级,而且经常也有两个数量级大的容量。磁盘唯一的问题是随机访问数据时间大约慢了三个数量级。其低速的原因是因为磁盘是ー种机械装置,如图1-10所示。

![image-20240914174543407](现代操作系统_上.assets/image-20240914174543407.png)

> 图1-10 磁盘驱动的构造

在ー个磁盘中有一个或多个金属盘片,它们以5400rpm,7200rpm、108001pm或更高的速度旋转。从边缘开始有一个机械臂悬横在盘面上,这类似于老式播放塑料唱片33转唱机上的拾音臂。信息写在磁盘的ー系列同心圆上。在任意ー个给定臂的位置,每个磁头可以读取一段环形区域,称为磁道(track)。把ー个给定臂的位置上的所有磁道合并起来,组成了一个柱面(cylinder)。

毎个磁道划分为若干扇区,扇区的典型值是512字节。在现代磁盘中,较外部的柱面比较内部的柱面有更多的扇区。机械臂从ー个柱面移到相邻的柱面大约需要1ms。而随机移到一个柱面的典型时间为5ms至10ms,其具体时间取决于驱动器。一旦磁臂到达正确的磁道上,驱动器必须等待所需的扇区旋转到磁头之下,这就增加了5ms至10ms的时延,其具体延时取决于驱动器的转速。一旦所需要的扇区移到磁头之下,就开始读写,低端硬盘的速率是50MB/s,而高速磁盘的速率是160MB/S。

有时,你会听到人们在谈论ー些实际上根本不是磁盘的磁盘,比如固态硬盘(SolidStateDisk,SSD)o固态硬盘并没有可以移动的部分,外形也不像唱片那样,并且数据是存储在存储器(闪存)中的。与磁盘唯一的相似之处就是它也存储了大量即使在电源关闭时也不会丢失的数据。

许多计算机支持ー种著名的虚拟内存机制,这将在第3章中讨论。这种机制使得期望运行大于物理内存的程序成为可能,其方法是将程序放在磁盘上,而将主存作为ー种缓存,用来保存最频繁使用的部分程序。这种机制需要快速地映像内存地址,以便把程序生成的地址转换为有关字节在RAM中的物理地址。这种映像由CPU中的ー个称为存储器管理单元(MemoryManagementUnit,MMU)的部件来完成,如图1-6所示。

缓存和MMU的出现对系统的性能有着重要的影响。在多道程序系统中,从ー个程序切换到另ー个程序,有时称为上下文切换(contextswitch),有必要对来自缓存的所有修改过的块进行写回磁盘操作,并修改MMU中的映像寄存器。但是这两种操作的代价很昂贵,所以程序员努力避免使用这些操作。我们稍后将看到这些操作产生的影响。

### 1.3.4 I/O设备

CPU和存储器不是操作系统唯一需要管理的资源。I/o设备也与操作系统有密切的相互影响。如图レ6所示,I/O设备一般包括两个部分:设备控制器和设备本身。控制器是插在电路板上的ー块芯片或ー组芯片,这块电路板物理地控制设备。它从操作系统接收命令,例如,从设备读数据,并且完成数据的处理。

在许多情形下,对这些设备的控制是非常复杂和具体的,所以,控制器的任务是为操作系统提供ー个简单的接口(不过还是很复杂)。例如,磁盘控制器可以接受一个命令从磁盘2读出11206号扇区,然后,控制器把这个线性扇区号转化为柱面、扇区和磁头。由于外柱面比内柱面有较多的扇区,而且一些坏扇区已经被映射到磁盘的其他地方,所以这种转换将是很复杂的。磁盘控制器必须确定磁头臂应该在哪个柱面上,并对磁头臂发出指令以使其前后移动到所要求的柱面号上,接着必须等待对应的扇区转动到磁头下面并开始读出数据,随着数据从驱动器读出,要消去引导块并计算校验和。最后,还得把输入的二进制位组成字并存放到存储器中。为了完成这些工作,在控制器中经常安装ー个小的嵌入式计算机,该嵌入式计算机运行为执行这些工作而专门编好的程序。

I/O设备的另ー个部分是实际设备的自身。设备本身有个相对简单的接口,这是因为接口既不能做很多工作,又已经被标准化了。例如,标准化后任何ー个SATA磁盘控制器就可以适配任一种SATA磁盘,所以标准化是必要的。ATA代表高级技术附件(ATAttachment),而SATA表示串行高级技术附件(SerialATA)。想必你们在好奇AT代表着什么,它是IBM公司的第二代个人计算机高级技术(AdvancedTechnology),采用该公司于1984年推出的6MHz 80286处理器,这ー处理器是当年最为强大的。从中我们可以看出,计算机エ业有着不断用新的前缀或后缀来扩展首字母缩写词的习惯。我们还能看出,像“髙级”这样的形容词应当谨慎使用,否则30年后再回首时会显得非常愚昧。

现在SATA是很多计算机的标准硬盘接口。由干实际的设备接口隐藏在控制器中,所以,操作系统看到的是对控制器的接口,这个接口可能和设备接口有很大的差别。

每类设备控制器都是不同的,所以,需要不同的软件进行控制。专门与控制器对话,发出命令并接收响应的软件,称为设备驱动程序(devicedriver)0每个控制器厂家必须为所支持的操作系统提供相应的设备驱动程序。例如,一台扫描仪会配有用于OS X、Windows7,Windows8以及Linux的设备驱动程序。

为了能够使用设备驱动程序,必须把设备驱动程序装入操作系统中,这样它可在核心态运行。设备驱动程序可以在内核外运行,现代的Linux和Windows操作系统也的确对这种方式提供ー些支持口绝大多数驱动程序仍然需要在内核态运行。只有很少一部分现代系统(如MINIX 3)在用户态运行全部驱动程序。在用户态运行的驱动程序必须能够以某种受控的方式访问设备,然而这并不容易。

要将设备驱动程序装入操作系统,有三个途径。第一个途径是将内核与设备驱动程序重新链接,然后重启动系统.许多UNIX系统以这种方式工作。第二个途径是在ー个操作系统文件中设置ー个入口,并通知该文件需要一个设备驱动程序,然后重启动系统。在系统启动时,操作系统去找寻所需的设备驱动程序并装载之。Windows就是以这种方式工作。第三种途径是,操作系统能够在运行时接受新的设备驱动程序并且立即将其安装好,无须重启动系统。这种方式采用得较少,但是正在变得普及起来。热插拔设备,诸如USB和IEEE1394设备（后面会讨论）都需要动态可装载设备驱动程序。

毎个设备控制器都有少量用于通信的寄存器。例如,ー个最小的磁盘控制器也会有用于指定磁盘地址、内存地址、扇区计数和方向（读或写）的寄存器。要激活控制器,设备驱动程序从操作系统获得一条命令,然后翻译成对应的值,并写进设备寄存器中。所有设备寄存器的集合构成了リ。端口空间,我们将在第5章讨论有关内容。

在有些计算机中,设备寄存器被映射到操作系统的地址空间（操作系统可使用的地址）,这样,它们就可以像普通存储字ー样读出和写入。在这种计算机中,不需要专门的i/o指令,用户程序可以被硬件阻挡在外,防止其接触这些存储器地址（例如,采用基址和界限寄存器）。在另外一些计算机中,设备寄存器披放入一个专门的I/O端口空间中,毎个寄存器都有一个端口地址。在这些机器中,提供在内核态中可使用的专门IN和〇UT指令,供设备驱动程序读写这些寄存器用。前ー种方式不需要专门的I/O指令,但是占用了一些地址空间。后者不占用地址空间,但是需要专门的指令。这两种方式的应用都很广泛。

实现输入和输出的方式有三种。在最简单的方式中,用户程序发出ー个系统调用,内核将其翻译成ー个对应设备驱动程序的过程调用。然后设备驱动程序启动i/o并在ー个连续不断的循环中检査该设备,看该设备是否完成了工作（一般有一些二进制位用来指示设备仍在忙碌中）•当i/o结束后,设备驱动程序把数据送到指定的地方（若有此需要）,并返回。然后操作系统将控制返回给调用者。这种方式称为忙等待（busywaiting）,其缺点是要占据CPU,CPU一直轮询设备直到对应的I/O操作完成。

第二种方式是设备驱动程序启动设备并且让该设备在操作完成时发出ー个中断。设备驱动程序在这个时刻返回.操作系统接着在需要时阻塞调用者并安排其他工作进行。当设备驱动程序检测到该设备的操作完毕时,它发出ー个中断通知操作完成。

在操作系统中,中断是非常重要的,所以需要更具体地讨论。在图1-11 a中,有一个I/O的三步过程。在第1步,设备驱动程序通过写设备寄存器通知设备控制器做什么。然后,设备控制器启动该设备。当设备控制器传送完毕被告知要进行读写的字节数量后,它在第2步中使用特定的总线发信号给中断控制器芯片。如果中断控制器已经准备接收中断（如果正忙于ー个更高级的中断,也可能不接收）,它会在CPU芯片的ー个管脚上声明,这就是第3步。在第4步中,中断控制器把该设备的编号放到总线上,这样CPU可以读总线,并且知道哪个设备刚刚完成了操作（可能同时有许多设备在运行）。

![image-20240914174613717](现代操作系统_上.assets/image-20240914174613717.png)

> 图1-11a）启动ー个！/O设备并发出中断的过程Ib）中断处理过程包括取中断、运行中断处理程序和返回用户程序

一旦CPU决定取中断,通常程序计数器和PSW就被压入当前堆栈中,并且CPU被切换到用户态。设备编号可以成为部分内存的ー个引用,用于寻找该设备中断处理程序的地址。这部分内存称为中断向量(interruptvector)o当中断处理程序(中断设备的设备驱动程序的一部分)开始后,它取走已入栈的程序计数器和PSW,并保存之,然后査询设备的状态。在中断处理程序全部完成之后,它返回到先前运行的用户程序中尚未执行的头一条指令°这些步骤如图1-11 b所示。

第三种方式是,为I/O使用ー种特殊的直接存储器访问(DirectMemoryAccess,DMA)芯片,它可以控制在内存和某些控制器之间的位流,而无须持续的CPU干预。CPU对DMA芯片进行设置,说明需要传送的字节数、有关的设备和内存地址以及操作方向,接着启动DMA。当DMA芯片完成时,它引发ー个中断,其处理方式如前所述。有关DMA和I/O硬件会在第5章中具体讨论。

中断会(并且经常会)在非常不合适的时刻发生,比如,在另ー个中断程序正在运行时发生。正由于此,CPU有办法关闭中断并在稍后再开启中断ユ在中断关闭时,任何已经发出中断的设备,可以继续保持其中断信号,但是CPU不会被中断,直至中断再次启用为止。如果在关闭中断时,已有多个设备发出了中断,中断控制器将决定先处理哪个中断,通常这取决于事先赋予毎个设备的静态优先级。最高优先级的设备赢得竞争并且首先获得服务,其他设备则必须等待。

### 1.3.5 总线

图1-6中的结构在小型计算机中使用了多年,并用在早期的IBMPC中。但是,随着处理器和存储器速度越来越快,到了某个转折点时,单总线(当然还有IBMPC总线)就很难处理总线的交通流量了,只有放弃。其结果是导致其他的总线出现,它们处理I/O设备以及CPU到存储器的速度都更快。这种演化的结果是,目前一台大型x86系统的结构如图1・12所示。

![image-20240914174637769](现代操作系统_上.assets/image-20240914174637769.png)

> 图1-12 一个大整x86系统的结构

图中的系统有很多总线(例如高速缓存、内存、PCIe.PCI、USB、SATA和DMI),每条总线的传输速度和功能都不同。操作系统必须了解所有总线的配置和管理。其中主要的总线是PCk(PeripheralComponentInterconnectExpress)总线。

Intel发明的PCIe总线是陈旧的PCI总线的继承者,而PCI总线则是为了取代原来的ISA(IndustryStandardArchitecture)总线＜1数十Gb/s的传输能力使得PCle比它的前身快得多。它们在本质上也十分不同。直到发明PCIe总线的2004年,大多数总线都是并行且共享的。共享总线架构(sharedbusarchitecture)表示多个设备使用一些相同的导线传输数据。因此,当多个设备同时需要发送数据时,需要仲裁器决定哪个设备可以使用总线。PCIe恰好相反,它使用分离的端到端的链路。传统PCI使用的并行总线架构(parallelbusarchitecture)表示通过多条导线发送数据的每ー个字。例如，在传统的PCI总线上,ー个32位数据通过32条并行的导线发送。与之相反,PCIe使用串行总线架构(serialbus architecture),通过一条被称为数据通路的链路传递集合了所有位的一条消息,这非常像网络包。这样做简单了很多,因为不用再确保所有32位在同一时刻精确地到达目的地。通过将多个数据通路并行起来,并行性仍可有效利用。例如,可以使用32个数据通路并行传输32条消息。随着网卡和图形适配器这些外围设备速度的迅速增长,PCIe标准毎3~5年进行一次更新。例如,PCIe2.0规格的16个数据通路提供64Gb/s的速度,升级到PCIe30后会提速2倍,而PCIe40会再提速2倍。

同时,还有很多符合老的PCI标准的旧设备。正如我们在图1/2中看到的那样,这些设备连接到独立的集成处理器。未来,当我们觉得用“陈旧”已经不能形容PCI,而只能称其为“古老”时,很可能所有的PCI设备将连接到另ー个集成中心,这些中心再连接到主集成中心,从而形成总线树。

在图中,CPU通过DDR3总线与内存对话,通过PCIe总线与外围图形设备对话,通过DMI(DirectMediaInterface)总线经集成中心与所有其他设备对话。而集成中心通过通用串行总线与USB设备对话,通过SATA总线与硬盘和DVD驱动器对话,通过PCIe传输以太网络帧。我们已经提到过使用传统PCI总线的旧的PCI设备。

不仅如此,每ー个核不仅有独立的高速缓存,而且还共享一个大得多的高速缓存。每ー种高速缓存都引入了又一条总线。

USB(UniversalSerialBus)是用来将所有慢速I/O设备(如键盘和鼠标)与计算机连接的。然而,以5Gb/s运行的现代USB3.0设备被认为很慢,这对于伴随第一代IBM个人计算机(以8Mb/sISA作为主要总线)共同长大的人来说似乎并不自然。USB采用一种小型的4~11针(取决于版本)连接器,其中一些针为USB设备提供电源或者接地。USB是ー种集中式总线，其根设备毎1ms轮询一次I/O设备,看是否有信息收发。USB10可以处理总计12Mb/s的负载,USB2.0总线提速到480MHs,而USB3.0能达到不小于5Gb/s的速率。一所有USB设备都可以连接到计算机然后立即工作,而不像之前的设备那样要求重启,这让ー批沮丧的用户感到非常惊讶。

SCSI(SmallComputerSystemInterface)总线是ー种高速总线,用在高速硬盘、扫描仪和其他需要较大带宽的设备上。现在,它们主要用在服务器和工作站中,速度可以达到640MB/S。

要在如图1-12展示的环境下工作,操作系统必须了解有些什么外部设备连接到计算机上,并对它们进行配置。这种需求导致Intel和微软设计了一种名为即插即用(plugandplay)的I/O系统,这是基于ー种首先被苹果Macintosh实现的类似概念。在即插即用之前,每块I/O卡有一个固定的中断请求级别和用于其I/O寄存器的固定地址,例如,键盘的中断级别是1,并使用。x60至0x64的I/O地址,软盘控制器是中断6级并使用0X3F0至0X3Fフ的I/O地址,而打印机是中断7级并使用0X378至0X37A的I/O地址等。

到目前为止,一切正常。比如,用户买了一块声卡和调制解调卡,并且它们都是可以使用中断4的,但此时,问题发生了,两块卡互相冲突,结果不能在ー起工作。解决方案是在每块I/O卡上提供DIP开关或跳接器,并指导用户对其进行设置以选择中断级别和i/o地址,使其不会与用户系统的任何其他部件冲突。那些热衷于复杂PC硬件的十几岁的青少年有时可以不出差错地做这类工作。但是,没有人能够不出错。

即插即用所做的工作是,系统自动地收集有关I/O设备的信息,集中赋予中断级别和I/O地址,然后通知每块卡所使用的数值。这项工作与计算机的启动密切相关,所以下面我们开始讨论计算机的启动。不过这不是件轻松的工作。

### 1.3.6 启动计算机

简要启动过程如下。在每台计算机上有一块双亲板(在政治因素影响到计算机产业之前,它们曾称为“母板”)。在双亲板上有一个称为基本输入输出系统(BasicInputOutputSystem,BIOS)的程序。在BIOS内有底层I/O软件,包括读键盘、写屏幕、进行磁盘I/O以及其他过程。现在这个程序存放在ー块闪速RAM中,它是非易失性的,但是在发现BIOS中有错时可以通过操作系统对它进行更新。

在计算机启动时,BIOS开始运行。它首先检査所安装的RAM数量,键盘和其他基本设备是否已安装并正常响应。接着,它开始扫描PCIe和PCI总线并找出连在上面的所有设备。即插即用设备也被记录下来。如果现有的设备和系统上一次启动时的设备不同,则新的设备将被配置。

然后,BIOS通过尝试存储在CMOS存储器中的设备清单决定启动设备。用户可以在系统刚启动之后进入ー个BIOS配置程序,对设备清单进行修改。典型地,如果存在CD-ROM（有时是USB）,则系统试图从中启动,如果失败,系统将从硬盘启动。启动设备上的第一个扇区被读入内存并执行。这个扇区中包含ー个对保存在启动扇区末尾的分区表检査的程序,以确定哪个分区是活动的。

然后,从该分区读入第二个启动装载模块。来自活动分区的这个装载模块被读入操作系统,并启动之。然后,操作系统询问BIOS,以获得配置信息。对于每种设备,系统检查对应的设备驱动程序是否存在。如果没有,系统要求用户插入含有该设备驱动程序的CD-ROM（由设备供应商提供）或者从网络上下载驱动程序。一旦有了全部的设备驱动程序,操作系统就将它们调入内核。然后初始化有关表格,创建需要的任何背景进程,并在毎个终端上启动登录程序或GUI。

## 1.4 操作系统大观园

操作系统已经存在了半个多世纪。在这段时期内,出现了各种类型的操作系统,但并不是所有操作系统都很知名。本节中,我们将简要地介绍其中的9个。在本书的后面,我们还将回顾其中的一些类型。

### 1.4.1 大型机操作系统

在操作系统的高端是用于大型机的操作系统,这些房间般大小的计算机仍然可以在一些大型公司的数据中心见到。这些计算机与个人计算机的主要差别是其I/O处理能力。一台拥有1000个磁盘和几百万吉字节数据的大型机是很正常的,如果有这样一台个人计算机朋友会很羡慕。大型机也在高端的Web服务器、大型电子商务服务站点和事务ー事务交易服务器上有某种程度的卷土重来。

用于大型机的操作系统主要面向多个作业的同时处理,多数这样的作业需要巨大的I/O能力。系统主要提供三类服务:批处理、事务处理和分时。批处理系统处理不需要交互式用户干预的周期性作业。保险公司的索赔处理或连锁商店的销售报告通常就是以批处理方式完成的。事务处理系统负责大量小的请求,例如,银行的支票处理或航班预订。每个业务量都很小,但是系统必须每秒处理成百上千个业务。分时系统允许多个远程用户同时在计算机上运行作业,如在大型数据库上的查询。这些功能是密切相关的,大型机操作系统通常完成所有这些功能°大型机操作系统的ー个例子是OS/390（OS/360的后继版本）。但是,大型机操作系统正在逐渐被诸如Linux这类UNIX的变体所替代。

### 1.4.2 服务器操作系统

下ー个层次是服务器操作系统。它们在服务器上运行,服务器可以是大型的个人计算机、工作站,甚至是大型机。它们通过网络同时为若干个用户服务,并且允许用户共享硬件和软件资源。服务器可提供打印服务、文件服务或Web服务。Intemet提供商运行着许多台服务器机器,为用户提供支持,使Web站点保存Web页面并处理进来的请求。典型的服务器操作系统有Solaris、FreeBSD,Linux和WindowsServer201x。

### 1.4.3 多处理器操作系统

获得大量联合计算能力的常用方式是将多个CPU连接成单个的系统。依据连接和共享方式的不同,这些系统称为并行计算机、多计算机或多处理器。它们需要专门的操作系统,不过通常采用的操作系统是配有通信、连接和一致性等专门功能的服务器操作系统的变体。

个人计算机中近来出现了多核芯片,所以常规的台式机和笔记本电脑操作系统也开始与小规模的多处理器打交道,而核的数量正在与时俱进。幸运的是,由于先前多年的班究,已经具备不少关于多处理器操作系统的知识,将这些知识运用到多核处理器系统中应该不存在困难。难点在于要有能够运用所有这些计算能力的应用。许多主流操作系统,包括Windows和Linux,都可以运行在多核处理器上。

### 1.4.4 个人计算机操作系统

接着ー类是个人计算机操作系统。现代个人计算机操作系统都支持多道程序处理,在启动时,通常有几十个程序开始运行。它们的功能是为单个用户提供良好的支持。这类系统广泛用于字处理、电子表格、游戏和Internet访问°常见的例子是Linux、FreeBSD,Windows7,Windows8和苹果公司的OSX。个人计算机操作系统是如此地广为人知,所以不需要再做介绍了。事实上,许多人甚至不知道还有其他的操作系统存在。

### 1.4.5 掌上计算机操作系统

随着系统越来越小型化,我们看到了平板电脑、智能手机和其他掌上计算机系统。掌上计算机或者PDA（个人数字助理,PersonalDigitalAssistant）是ー种可以握在手中操作的小型计算机。平板电脑和智能手机是最为人熟知的例子。正如我们看到的那样,这部分市场已经被谷歌的Android系统和苹果的iOS主导,但它们仍有很多竞争对手。大多数设备基于的是多核CPU、GPS、摄像头及其他的传感器、大量内存和精密的操作系统。并且,它们都有多到数不清的第三方应用（app）。

### 1.4.6 嵌入式操作系统

嵌入式系统在用来控制设备的计算机中运行,这种设备不是一般意义上的计算机,并且不允许用户安装软件。典型的例子有微波炉,电视机、汽车、DVD刻录机、移动电话以及MP3播放器ー类的设备。区别嵌入式系统与掌上设备的主要特征是,不可信的软件肯定不能在嵌入式系统上运行。用户不能给自己的微波炉下载新的应用程序—所有的软件都保存在ROM中。这意味着在应用程序之间不存在保护,这样系统就获得了某种简化。在这个领域中,主要的嵌入式操作系统有嵌入式Linux、QNX和VxWorks等。

### 1.4.7 传感器节点操作系统

有许多用途需要配置微小传感器节点网络。这些节点是ー种可以彼此通信并且使用无线通信基站的微型计算机。这类传感器网络可以用于建筑物周边保护、国土边界保卫、森林火灾探测、气象预测用的温度和降水测量、战场上敌方运动的信息收集等。

传感器是ー种内建有无线电的电池驱动的小型计算机。它们能源有限,必须长时间工作在无人的户外环境中,通常是恶劣的条件下。其网络必须足够健壮,以允许个别节点失效。随着电池开始耗尽,这种失效节点会不断增加。

每个传感器节点是ー个配有CPU、RAM、ROM以及ー个或多个环境传感器的实实在在的计算机。节点上运行ー个小型但是真实的操作系统,通常这个操作系统是事件驱动的,可以响应外部事件,或者基于内部时钟进行周期性的测量。该操作系统必须小且简单,因为这些节点的RAM很小,而且电池寿命是一个重要问题。另外,和嵌入式系统ー样,所有的程序是预先装载的,用户不会突然启动从Internet上下载的程序,这样就使得设计大为简化。TinyOS是ー个用于传感器节点的知名操作系统。

### 1.4.8 实时操作系统

另ー类操作系统是实时操作系统。这些系统的特征是将时间作为关键参数。例如,在工业过程控制系统中,工厂中的实时计算机必须收集生产过程的数据并用有关数据控制机器。通常,系统还必须满足严格的最终时限。例如,汽车在装配线上移动时,必须在限定的时间内进行规定的操作。如果焊接机器人焊接得太早或太迟,都会毁坏汽车。如果某个动作必须绝对地在规定的时刻（或规定的时间范围）发生,这就是硬实时系统。可以在工业过程控制、民用航空、军事以及类似应用中看到很多这样的系统。这些系统必须提供绝对保证,让某个特定的动作在给定的时间内完成。

另一类实时系统是软实时系统,在这种系统中,虽然不希望偶尔违反最终时限,但仍可以接受,并且不会引起任何永久性的损害。数字音频或多媒体系统就是这类系统。智能手机也是软实时系统。

由于在（硬）实时系统中满足严格的时限是关键,所以操作系统就是ー个简单的与应用程序链接的库,各个部分必须紧密耦合并且彼此之间没有保护。这种实时系统的例子有eCos。

掌上、嵌入式以及实时系统的分类之间有不少是彼此重叠的。几乎所有这些系统至少存在某种软实时情景。嵌入式和实时系统只运行系统设计师安装的软件,用户不能添加自己的软件,这样就使得保护工作很容易。掌上和嵌入式系统是给普通消费者使用的,而实时系统则更多用于エ业领域。无论怎样,这些系统确实存在一些共同点。

### 1.4.9 智能卡操作系统

最小的操作系统运行在智能卡上。智能卡是ー种包含ー块CPU芯片的信用卡。它有非常严格的运行能耗和存储空间的限制。其中,有些智能卡只具有单项功能,如电子支付,但是其他的智能卡则拥有多项功能,它们有专用的操作系统。

有些智能卡是面向Java的。这意味着在智能卡的ROM中有一个Java虚拟机（JavaVirtualMachine,JVM）解释器。Java小程序被下载到卡中并由JVM解释器解释。有些卡可以同时处理多个Java小程序,这就是多道程序,并且需要对它们进行调度。在两个或多个小程序同时运行时,资源管理和保护就成为突出的问题。这些问题必须由卡上的操作系统（通常是非常原始的）处理。

## 1.5 操作系统概念

多数操作系统都使用某些基本概念和抽象,如进程、地址空间以及文件等,它们是需要理解的核心内容。作为引论,在下面的几节中,我们将较为简要地考察这些基本概念中的一部分。在本书的后面,我们将详细地讨论它们。为了说明这些概念,我们有时使用示例,这些示例通常源自UNIX。不过,类似的例子在其他操作系统中也明显地存在,我们将在之后深入了解其中的一些操作系统。

### 1.5.1 进程

在所有操作系统中,ー个重要的概念是进程（process）o进程本质上是正在执行的ー个程序。与每个进程相关的是地址空间（addressspace）,这是从某个最小值的存储位置（通常是零）到某个最大值的存储位置的列表。在这个地址空间中,进程可以进行读写。该地址空间中存放有可执行程序、程序的数据以及程序的堆栈。与每个进程相关的还有资源集,通常包括寄存器（含有程序计数器和堆桟指针）、打开文件的清单、突出的报警、有关进程清单,以及运行该程序所需要的所有其他信息。进程基本上是容纳运行ー个程序所需要所有信息的容器。

进程的概念将在第2章详细讨论,不过,对进程建立一种直观感觉的最便利方式是分析一个多道程序设计系统。用户启动ー个视频编辑程序,指示它按照某个格式转换ー小时的视频（有时会花费数小时），然后离开去浏览网页。.同时,ー个被周期性喚醒、用来检査进来的电子邮件的后台进程会开始运行。这样,我们就有了（至少）三个活动进程:视频编辑器、Web浏览器以及电子邮件接收程序。操作系统周期性地挂起一个进程然后启动运行另ー个进程,这可能是由于在过去的ー两秒钟内,第一个进程已使用完分配给它的时间片。

ー个进程暂时被挂起后,在随后的某个时刻里,该进程再次启动时的状态必须与先前暂停时完全相同,这就意味着在挂起时该进程的所有信息都要保存下来。例如,为了同时读入信息,进程打开了若干文件。与每个被打开文件有关的是指向当前位置的指针（即下一个将读出的字节或记录）。在ー个进程暂时被挂起时,所有这些指针都必须保存起来,这样在该进程重新启动之后,所执行的读调用才能读到正确的数据。在许多操作系统中,与一个进程有关的所有信息,除了该进程自身地址空间的内容以外,均存放在操作系统的ー张表中,称为进程表（processtable）,进程表是数组（或链表）结构,当前存在的每个进程都要占用其中一项。

所以,一个（挂起的）进程包括:进程的地址空间（往往称作磁芯映像,coreimage,纪念过去使用的磁芯存储器）,以及对应的进程表项（其中包括寄存器以及稍后重启动该进程所需要的许多其他信息）。

与进程管理有关的最关键的系统调用是那些进行进程创建和进程终止的系统调用。考虑ー个典型的例子°有一个称为命令解释器（commandinterpreter）或shell的进程从终端上读命令。此时,用户刚键入一条命令要求编译ー个程序。shell必须先创建一个新进程来执行编译程序。当执行编译的进程结束时,它执行ー个系统调用来终止自己。

![image-20240914174726162](现代操作系统_上.assets/image-20240914174726162.png)

> 图1-13一个进程树。进程A创建两个子进程B和C,进程B创建三个子进程D、E⅛F

若一个进程能够创建一个或多个进程（称为子进程），而且这些进程又可以创建子进程,则很容易得到进程树,如图L13所示。合作完成某些作业的相关进程经常需要彼此通信以便同步它们的行为。这种通信称为进程间通信（interprocesscommunication）,将在第2章中详细讨论。

其他可用的进程系统调用包括:申请更多的内存（或释放不再需要的内存）、等待一个子进程结束、用另一个程序覆盖该程序等。

有时,需要向ー个正在运行的进程传送信息,而该进程并没有等待接收信息。例如,ー个进程通过网络向另一台机器上的进程发送消息进行通信。为了保证一条消息或消息的应答不会丢失,发送者要求它所在的操作系统在指定的若干秒后给ー个通知,这样如果对方尚未收到确认消息就可以进行重发。

在设定该定时器后,程序可以继续做其他工作。在限定的秒数流逝之后,操作系统向该进程发送ー个警告信号(alarmsignal)。此信号引起该进程暂时挂起,无论该进程正在做什么,系统将其寄存器的值保存到堆栈,并开始运行一个特别的信号处理过程,比如重新发送可能丢失的消息。这些信号是软件模拟的硬件中断,除了定时器到期之外,该信号可以由各种原因产生。许多由硬件检测出来的陷阱,如执行了非法指令或使用了无效地址等,也被转换成该信号并交给这个进程。

系统管理器授权每个进程使用ー个给定的UID(User!Dentification)。每个被启动的进程都有一个启动该进程的用户UID。子进程拥有与父进程一样的UID。用户可以是某个组的成员,每个组也有一个GÏD(Group!Dentification)

在UNIX中,有一个U!D称为超级用户(superuser),或者Windows中的管理员(administrator),它具有特殊的权カ,可以违背ー些保护规则。在大型系统中,只有系统管理员掌握着成为超级用户的密码,但是许多普通用户(特别是学生)做出了可观的努力,试图找出系统的缺陷,从而使他们不用密码就可以成为超级用户。

在第2章中,我们将讨论进程以及进程间通信的相关内容。

### 1.5.2 地址空间

每台计算机都有一些主存,用来保存正在执行的程序。在非常简单的操作系统中,内存中一次只能有一个程序。如果要运行第二个程序,第一个程序就必须被移出内存,再把第二个程序装入内存。

较复杂的操作系统允许在内存中同时运行多道程序。为了避免它们互相干扰(包括操作系统),需要有某种保护机制。虽然这种机制必然是硬件形式的,但是由操作系统掌控。

上述的观点涉及对计算机主存的管理和保护。另ー种不同但是同样重要并与存储器有关的内容,是管理进程的地址空间。通常,每个进程有一些可以使用的地址集合,典型值从()开始直到某个最大值。在最简单的情形下,ー个进程可拥有的最大地址空间小于主存。在这种方式下,进程可以用满其地址空间,而且内存中也有足够的空间容纳该进程。

但是,在许多32位或64位地址的计算机中,分别有232或264字节的地址空间。如果ー个进程有比计算机拥有的主存还大的地址空间,而且该进程希望使用全部的内存,那怎么办呢?在早期的计算机中,这个进程只好“认命”了。现在,有了一种称为虚拟内存的技术,正如前面已经介绍过的,操作系统可以把部分地址空间装入主存,部分留在磁盘上,并且在需要时来回交换它们。在本质上,操作系统创建了一个地址空间的抽象,作为进程可以引用地址的集合。该地址空间与机器的物理内存解耦,可能大于也可能小于该物理空间。对地址空间和物理空间的管理组成了操作系统功能的ー个重要部分,整个第3章都与这个主题有关。

### 1.5.3 文件

实际上,支持操作系统的另ー个关键概念是文件系统。如前所述,操作系统的ー项主要功能是隐藏磁盘和其他I/o设备的细节特性,给提供程序员一个良好、清晰的独立于设备的抽象文件模型。显然,创建文件、删除文件、读文件和写文件等都需要系统调用。在文件可以读取之前,必须先在磁盘上定位和打开文件,在文件读过之后应该关闭该文件,有关的系统调用则用于完成这类操作。

为了提供保存文件的地方,大多数操作系统支持目录(directory)的概念,从而可把文件分类成组。比如,学生可给所选的每个课程创建一个目录(用于保存该课程所需的程序),另设ー个目录存放电子邮件,再有一个目录用于保存万维网主页。这就需要系统调用创建和删除目录、将已有的文件放入目录中、从目录中删除文件等。目录项可以是文件或者目录,这样就产生了层次结构—文件系统,如图1-14所示。

进程和文件层次都可以组织成树状结构,但这两种树状结构有不少不同之处。一般进程的树状结构层次不深(很少超过三层),而文件树状结构的层次常常多达四层、五层或更多层。进程树层次结构是暂时的,通常最多存在几分钟,而目录层次则可能存在数年之久。进程和文件在所有权及保护方面也是有区别的。典型地,只有父进程能控制和访问子进程,而在文件和目录中通常存在ー种机制,使文件所有者之外的其他用户也可以访问该文件。

![image-20240914174748071](现代操作系统_上.assets/image-20240914174748071.png)

> 图1-14大学院系的文件系统

目录层结构中的每一个文件都可以通过从目录的顶部即根目录(rootdirectory)开始的路径名(pathname)来确定。绝对路径名包含了从根目录到该文件的所有目录清单,它们之间用正斜线隔开。如在图L14中,文件CS101的路径名是/Faculty/Prof.Brown/Courses/CS101。最开始的正斜线表示这是从根目录开始的绝对路径。顺便提及,出于历史原因在Windows中用反斜线(\)字符作为分隔符,替代了正斜线(/),这样,上面给出的文件路径会写为XFaculty∖Prof.Brown∖Courses∖CS101在本书中,我们ー般使用UNIX的路径惯例。

在实例中,每个进程有一个工作目录(workingdirectory),对于没有以斜线开头给出绝对地址的路径,将在这个工作目录下寻找。如在图1-14中的例子,如果/Faculty/Prof.Brown是工作目录,那么Courses/CS101与上面给定的绝对路径名表示的是同一个文件.进程可以通过使用系统调用指定新的エ作目录,从而变更其工作目录。

在读写文件之前,首先要打开文件,检査其访问权限。若权限许可,系统将返回一个小整数,称作文件描述符(filedescriptor),供后续操作使用。若禁止访问,系统则返回一个错误码。

Unix中的另ー个重要概念是安装文件系统。大多数台式机都有一个或多个光盘驱动器,可以插入cd-rom、DVD和蓝光光盘。它们几乎都有USB接口,可以插入USB存储棒(实际是固态磁盘驱动器)。为了提供ー个出色的方式处理可移动介质,UNIX允许把光盘上的文件系统接到主文件树上。考虑图l-15a的情形。在mount调用之前,根文件系统在硬盘上,而第二个文件系统在CD-ROM上,它们是分离且无关的。

![image-20240914174808590](现代操作系统_上.assets/image-20240914174808590.png)

> 图1-15a)在安装前,CD-ROM上的文件不可访问.b)在安装后,它们成了文件层次的一部分

然而,不能使用CD-ROM上的文件系统,因为上面没有可指定的路径。UNIX不允许在路径前面加上驱动器名称或代码,那样做就完全成了设备相关类型了,这是操作系统应该消除的。代替的方法是,mount系统调用允许把在CD-ROM上的文件系统连接到程序所希望的根文件系统上。在图i-15b中,CD-ROM上的文件系统安装到了目录b上,这样就允许访问文件/b/x以及/b/y。如果CD-ROM已安装好,但目录b中有任何不能访问的文件,则是因为/b指向了CD∙ROM的根目录。（在开始时,不能访问这些文件似乎并不是ー个严重问题:文件系统几乎总是安装在空目录上。）如果系统有多个硬盘,它们可以都安装在单个树上。

在UNIX中,另ー个重要的概念是特殊文件（special file）。提供特殊文件是为了使I/O设备看起来像文件一般。这样,就像使用系统调用读写文件ー样,i/o设备也可通过同样的系统调用进行读写。有两类特殊文件:块特殊文件（blockspecialfile）和字符特殊文件（characterspecialfile）o块特殊文件指那些由可随机存取的块组成的设备,如磁盘等。比如打开ー个块特殊文件,然后读第4块,程序可以直接访问设备的第4块而不必考虑存放该文件的文件系统结构。类似地,字符特殊文件用于打印机、调制解调器和其他接收或输出字符流的设备。按照惯例,特殊文件保存在/加V目录中。例如,/dev/lp是打印机（曾经称为行式打印机）。

本小节中讨论的最后ー个特性既与进程有关也与文件有关:管道。管道（pipe）是ー种虚文件,它可连接两个进程,如图1-16所示。如果进程A和B希望通过管道对话,它们必须提前设置该管道。当进程A想对进程B发送数据时,它把数据写到管道上,仿佛管道就是输出文件一样。进程B可以通过读该管道而得到数据,仿佛该管道就是一个输入文件ー样。这样,在UNIX中两个进程之间的通信就非常类似于普通文件的读写了。更为强大的是,若进程想发现它所写入的输出文件不是真正的文件而是管道,则需要使用特殊的系统调用。文件系统是非常重要的。我们将在第4章以及第10章和第11章中具体讨论它们。

![image-20240914174824216](现代操作系统_上.assets/image-20240914174824216.png)

> 图1-16 由杳道连接的两个进程

### 1.5.4 输入/输出

所有的计算机都有用来获取输入和产生输出的物理设备。毕竟,如果用户不能告诉计算机该做什么,而在计算机完成了所要求的工作之后竟不能得到结果,那么计算机还有什么用处呢?有各种类型的输入和输出设备,包括键盘、显示器、打印机等。对这些设备的管理全然依靠操作系统。

所以,每个操作系统都有管理其I/O设备的I/O子系统。某些I/O软件是设备独立的,即这些I/O软件部分可以同样应用于许多或者全部的I/o设备上。I/O软件的其他部分,如设备驱动程序,是专门为特定的1Z。设备设计的。在第5章中,我们将讨论I/o软件。

### 1.5.5 保护

计算机中有大量的信息,用户经常希望对其进行保护,并保守秘密。这些信息包括电子邮件、商业计划、退税等诸多内容。管理系统的安全性完全依靠操作系统,例如,文件仅供授权用户访问。

作为ー个简单的例子,以便读者对如何实现安全有一个概念,请考察UNIX。UNIX操作系统通过对毎个文件赋予ー个9位的二逬制保护代码,对UNIX中的文件实现保护。该保护代码有三个3位字段,一个用于所有者,ー个用于与所有者同组（用户被系统管理员划分成组）的其他成员,ー个用于其他人。毎个字段中有一位用于读访问,一位用于写访问,一位用于执行访问。这些位就是知名的rwx位。例如,保护代码rwxr-x--x的含义是所有者可以读、写或执行该文件,其他的组成员可以读或执行（但不能写）该文件,而其他人可以执行（但不能读和写）该文件。对ー个目录而言,X的含义是允许査询。一条短横线的含义是,不存在对应的许可。

除了文件保护之外,还有很多有关安全的问题。保护系统不被人类或非人类（如病毒）入侵,则是其中之一。我们将在第9章中研究各种安全性问题。

### 1.5.6 shell

操作系统是进行系统调用的代码。编辑器、编译器、汇编程序、链接程序、效用程序以及命令解释器等,尽管非常重要,也非常有用,但是它们确实不是操作系统的组成部分。为了避免可能发生的混淆,本小节將大致介绍一下UNIX的命令解释器,称为shell。尽管sheH本身不是操作系统的一部分,但它体现了许多操作系统的特性,并很好地说明了系统调用的具体用法。shell同时也是终端用户与操作系统之间的接口,除非用户使用的是图形用户界面。有许多种shell,如sh、csh,ksh以及bash等。它们全部支持下面所介绍的功能,这些功能可追溯到早期的shell(即sh)。

用户登录时,同时启动了一个shell。它以终端作为标准输入和标准输出。首先显示提示符(prompt),它可能是一个美元符号,提示用户shell正在等待接收命令。假如用户键入

```
date
```

shell创建一个子进程,并运行date程序作为子进程。在该子进程运行期间,shell等待它结束。在子进程结束后,shell再次显示提示符,并等待下一行输入。

用户可以将标准输出重定向到ー个文件,如键入

```
date>file
```

同样,也可以将标准输入重定向,如:

```
sort<file1>file2
```

该命令调用sort程序,从filel中取得输入,输出送到file2.

可以将一个程序的输出通过管道作为另ー程序的输入,因此有

```
cat file1 file2 file3 | sort >/dev/lp
```

所调用的cat程序将这三个文件合并,其结果送到sort程序并按字典序排序。sort的输出又被重定向到文件/dev/lp中,显然,这是打印机。

如果用户在命令后加上一个"&"符号,则shell将不等待其结束,而直接显示出提示符。所以

```
cat file1 file2 file3 |sort>/dev/lp &
```

将启动sort程序作为后台任务执行,这样就允许用户继续工作,而sort命令也继续进行。shell还有许多其他有用的特性,由于篇幅有限而不能在这里讨论。有许多UNIX的书籍具体地讨论了shell(例如,Kemighan⅛Pike,1984iQuigley,2004jRobbins,2005)

现在,许多个人计算机使用GUI。事实上,GUI与shell类似,GUI只是一个运行在操作系统顶部的程序。在Linux系统中,这个事实更加明显,因为用户(至少)可以在两个GUI中选择ー个:Gnome和KDE,或者干脆不用(使用XII上的终端视窗)。在Windows中也可以用不同的程序代替标准的GUI桌面(WindowsExplorer),这可以通过修改注册表中的某些数值实现,不过极少有人这样做。

### 1.5.7 个体重复系统发育

在达尔文的《物种起源》(OntheOriginoftheSpecies)ー书出版之后,德国动物学家ErnstHaeckel论述了“个体重复系统发育”(ontogenyrecapitulatesphylogeny)o他这句话的含义是,个体重复着物种的演化过程。换句话说,在ー个卵子受精之后成为人体之前,这个卵子要经过是鱼、是猪等阶段。现代生物学家认为这是ー种粗略的简化,不过这种观点仍旧包含了真理的核心部分。

在计算机的历史中,类似情形也有发生。每个新物种(大型机、小型计算机、个人计算机、掌上、嵌入式计算机、智能卡等),无论是硬件还是软件,似乎都要经过它们前辈的发展阶段。计算机科学和许多领域ー样,主要是由技术驱动的。古罗马人缺少汽车的原因不是因为他们非常喜欢步行,是因为他们不知道如何造汽车。个人计算机的存在,不是因为数以百万计的人有着迫切的愿望—拥有一台计算机,而是因为现在可以很便宜地制造它们。我们常常忘了技术是如何影响我们对各种系统的观点的,所以有时值得再仔细考虑它们。特别地,技术的变化会导致某些思想过时并迅速消失,这种情形经常发生。但是,技术的另ー种变化还可能使某些思想再次复活。在技术的变化影响了某个系统不同部分之间的相对性能时,情况就是这样。例如,当CPU远快于存储器时,为了加速“慢速”的存储器,高速缓存是很重要的。某一天,如果新的存储器技术使得存储器远快于CPU,高速缓存就会消失。而如果新的CPU技术又使CPU远快于存储器,高速缓存就会再次出现。在生物学上,消失是永远的,但是在计算机科学中,这种消失有时只有几年时间。

在本书中,暂时消失的结果会造成我们有时需要反复考察ー些“过时”的概念,即那些在当代技术中并不理想的思想。而技术的变化会把ー些“过时概念”带回来。正由于此,更重要的是要理解为什么ー个概念会过时,什么样环境的变化又会启用“过时概念”。

为了把这个观点叙述得更透彻,我们考虑ー些例子。早期计算机采用了硬连线指令集。这种指令可由硬件直接执行,且不能改变。然后出现了微程序设计（首先在IBM360上大规模引入）,其中的解释器执行软件中的指令。于是硬连线执行过时了,因为不够灵活。接着发明了RISC计算机,微程序设计（即解释执行）过时了,这是因为直接执行更快。而在通过lmemet发送并且到达时オ解释的Java小程序形式中,我们又看到了解释执行的复苏。执行速度并不总是关键因素,但由于网络的延迟非常大,以至于它成了主要因素。这样,“钟摆”在直接执行和解释执行之间已经晃动了好几个周期,也许在未来还会再次晃动。

#### 1.大型内存

现在来分析硬件的某些历史发展过程,并看看硬件是如何重复地影响软件的。第一代大型机内存有限。在1959年至1964年之间,称为“山寨王”的IBM7090或7094满载也只有128KB多的内存。该机器多数用汇编语言编程,为了节省内存,其操作系统用汇编语言编写。

随着时间的推移,在汇编语言宣告过时时,FORTRAN和COBOL之类语言的编译器已经足够好了。但是在第一个商用小型计算机（PDP-1）发布时,却只有4096个18位字的内存,而且令人吃惊的是,汇编语言又回来了。最终,小型计算机获得了更多的内存,而且高级语言也在小型机上盛行起来。

在20世纪80年代早期微型计算机出现时，第一批机器只有4KB内存,汇编语言又复活了。嵌入式计算机经常使用和微型计算机ー样的CPU芯片（8080、Z80、后来的8086）,而且ー开始也使用汇编编程。现在,它们的后代—个人计算机拥有大量的内存,使用C、C++、Java和其他高级语言编程。智能卡正在走着类似的发展道路,而且除了确定的大小之外,智能卡通常使用Java解释器,解释执行Java程序,而不是将Java编译成智能卡的机器语言。

#### 2.保护硬件

早期的IBM7090/7094等大型机没有保护硬件,所以这些机器一次只运行一个程序。ー个有问题的程序就可能毁掉操作系统,并且很容易使机器崩溃。在IBM360发布时，提供了保护硬件的原型,这些机器可以在内存中同时保持若干程序,并让它们轮流运行（多道程序处理）。于是单道程序处理宣告过时。

至少是到了第一个小型计算机出现时一还没有保护硬件—所以多道程序处理也不可能有。尽管PDP-1和PDP-8没有保护硬件,但是PDP∙11型机器有了保护硬件,这ー特点导致了多道程序处理的应用,并且最终导致UNIX操作系统的诞生。

在建造第一代微型计算机时,使用了Intel8080CPU芯片,但是没有保护硬件,这样我们又回到了单道程序处理—毎个时刻只运行ー个程序。直到Intel80286オ增加了保护硬件,于是有了多道程序处理。直到现在,许多嵌入式系统仍旧没有保护硬件,而且只运行单个程序。

现在来考察操作系统。第一代大型机原本没有保护硬件,也不支持多道程序处理,所以这些机器只运行简单的操作系统,一次只能手工装载ー个程序。后来,大型机有了保护硬件,操作系统可以同时支持运行多个程序,接着系统拥有了全功能的分时能力。

在小型计算机刚出现时,也没有保护硬件,一次只运行一个手工装载的程序。逐渐地,小型机有了保护硬件,有了同时运行两个或更多程序的能力。第一代微型计算机也只有一次运行一个程序的能力,但是随后具有了一次处理多道程序的能力。掌上计算机和智能卡也走着类似的发展之路。

在所有这些案例中,软件的发展是受制于技术的.例如,第一代微型计算机有约4KB内存,没有保护硬件。髙级语言和多道程序处理对于这种小系统而言,无法获得支持。随着微型计算机演化成为现代个人计算机,拥有了必要的硬件,从而有了必需的软件处理以支持多种先进的功能。这种演化过程看来还要持续多年。其他领域也有类似的这种轮回现象,但是在计算机行业中,这种轮回现象似乎变化得更快。

#### 3.硬盘

早期大型机主要是基于磁带的。机器从磁带上读入程序、编译、运行,并把结果写到另一个磁带上。那时没有磁盘也没有文件系统的概念。在IBM于1956年引入第一个磁盘—RAMAC（RAndoMACcess）之后,事情开始变化。这个磁盘占据4平方米空间,可以存储500万フ位长的字符,这足够存储ー张中等分辨率的数字照片。但是其年租金高达35000美元,比存储占据同样空间数量的胶卷还要贵°不过这个磁盘的价格终于还是下降了,并开始出现了原始的文件系统。

拥有这些新技术的典型机器是CDC6600,该机器于1964年发布,在多年之内始终是世界上最快的计算机。用户可以通过指定名称的方式创建所谓“永久文件”,希望这个名称还没有被别人使用,比如“data”就是一个适合于文件的名称。这个系统使用单层目录。后来在大型机上开发出了复杂的多层文件系统,MULTICS文件系统可以算是多层文件系统的顶峰。

接着小型计算机投入使用,该机型最后也有了硬盘。1970年在PDP-11上引入了标准硬盘—RK05磁盘,容量为2.5MB,只有IBMRAMAC一半的容量,但是这个磁盘的直径只有40厘米,5厘米厚。不过,其原型也只有单层目录。随着微型计算机的出现,CP/M开始成为操作系统的主流,但是它也只是在（软）盘上支持单目录。

#### 4.虚拟内存

虚拟内存（安排在第3章中讨论）通过在RAM和磁盘中反复移动信息块的方式,提供了运行比机器物理内存大的程序的能力。虚拟内存也经历了类似的历程,首先出现在大型机上,然后是小型机和微型机。虚拟内存还使得程序可以在运行时动态地链接库,而不是必须在编译时链接。MULTICS是第ー个可以做到这点的系统。最终,这个思想传播到所有的机型上,现在广泛用于多数UNIX和Windows系统中。

在所有这些发展过程中,我们看到,在ー种环境中出现的思想,随着环境的变化被抛弃（汇编语言设计、单道程序处理、单层目录等）,通常在十年之后,该思想在另ー种环境下又重现了。由于这个原因,本书中,我们将不时回顾那些在今日的吉字节PC中过时的思想和算法,因为这些思想和算法可能会在嵌入式计算机和智能卡中再现。

## 1.6系统调用

我们已经看到操作系统具有两种功能:为用户程序提供抽象和管理计算机资源。在多数情形下,用户程序和操作系统之间的交互处理的是前者,例如，创建、写入、读出和删除文件。对用户而言,资源管理部分主要是透明和自动完成的。这样,用户程序和操作系统之间的交互主要就是处理抽象。为了真正理解操作系统的行为,我们必须仔细地分析这个接口。接口中所提供的调用随着操作系统的不同而变化（尽管基于的概念是类似的）。

这样我们不得不在如下的可能方式中进行选择:（1）含混不清的一般性叙述（”操作系统提供读取文件的系统调用"）；（2）某个特定的系统（“UNIX提供ー个有三个参数的read系统调用:ー个参数指定文件,ー个说明数据应存放的位置,另一个说明应读出多少字节）。

我们选择后ー种方式。这种方式需要更多的努力,但是它能更多地洞察操作系统具体在做什么。尽管这样的讨论会涉及专门的POSIX（InternationalStandard9945-1）,以及UNIX、SystemV,BSD、Linux,MINIX3等,但是多数现代操作系统都有实现相同功能的系统调用,尽管它们在细节上差别很大。由于引发系统调用的实际机制是非常依赖于机器的,而且必须用汇编代码表达,所以,通过提供过程库使C程序中能够使用系统调用,当然也包括其他语言。

记住下列事项是有益的。任何单CPU计算机一次只能执行一条指令。如果ー个进程正在用户态运行ー个用户程序,并且需要一个系统服务,比如从ー个文件读数据,那么它就必须执行一个陷阱或系统调用指令,将控制转移到操作系统。操作系统接着通过参数检査找出所需要的调用进程。然后,它执行系统调用,并把控制返回给在系统调用后面跟随着的指令。在某种意义上,进行系统调用就像进行ー个特殊的过程调用,但是只有系统调用可以进入内核,而过程调用则不能。

为了使系统调用机制更清晰,我们简要地考察read系统调用。如上所述,它有三个参数:第一个参数指定文件,第二个指向缓冲区,第三个说明要读出的字节数。几乎与所有的系统调用ー样,它的调用由C程序完成,方法是调用ー个与该系统调用名称相同的库过程:read。由C程序进行的调用形式如下:

```
 count = read（fd, buffer, nbytes）;
```

系统调用（以及库过程）在count中返回实际读出的字节数。这个值通常和mbytes相同,但也可能更小,例如,如果在读过程中遇到了文件尾的情形就是如此。

如果系统调用不能执行,不论是因为无效的参数还是磁盘错误,count都会被置为ー1,而在全局变量ermo中放入错误号。程序应该经常检査系统调用的结果,以了解是否出错。

系统调用是通过一系列的步骤实现的。为了更清楚地说明这个概念,考察上面的read调用。在准备调用这个实际用来进行read系统调用的read库过程时,调用程序首先把参数压进堆桟,如图1-17中步骤1~步骤3所示。

![image-20240914180948561](现代操作系统_上.assets/image-20240914180948561.png)

> 图1-17 完成系统调用read（fd,buffer,池向$）的11个步骤

由于历史的原因,C以及C++编译器使用逆序（必须把第一个参数赋给printf（格式字符串）,放在堆栈的顶部）。第一个和第三个参数是值调用,但是第二个参数通过引用传递,即传递的是缓冲区的地址（由&指示）,而不是缓冲区的内容。接着是对库过程的实际调用（第4步）。这个指令是用来调用所有过程的正常过程调用指令。

在可能是由汇编语言写成的库过程中,一般把系统调用的编号放在操作系统所期望的地方,如寄存器中（第5步）。然后执行一个TRAP指令,将用户态切换到内核态,并在内核中的ー个固定地址开始执行（第6步）。TRAP指令实际上与过程调用指令非常类似,它们后面都跟随一个来自远处位置的指令,以及供以后使用的ー个保存在栈中的返回地址。

然而,TRAP指令与过程指令存在两个方面的差别。首先,它的副作用是,切换到内核态。而过程调用指令并不改变模式。其次,不像给定过程所在的相对或绝对地址那样,TRAP指令不能跳转到任意地址上。根据机器的体系结构,或者跳转到ー个单固定地址上,或者指令中有一8位长的字段,它给定了内存中一张表格的索引,这张表格中含有跳转地址。

跟随在TRAP指令后的内核代码开始检查系统调用编号,然后分派给正确的系统调用处理器,这通常是通过ー张由系统调用编号所引用的、指向系统调用处理器的指针表来完成（第7步）。此时,系统调用处理器运行（第8步）。一旦系统调用处理器完成其工作,控制可能会在跟随TRAP指令后面的指令中返回给用户空间库过程（第9步）。这个过程接着以通常的过程调用返回的方式,返回到用户程序（第10步）。

为了完成整个工作,用户程序还必须清除堆栈,如同它在进行任何过程调用之后ー样（第11步）。假设堆栈向下增长,如经常所做的那样,编译后的代码准确地增加堆栈指针值,以便清除调用read之前压入的参数。在这之后,原来的程序就可以随意执行了。

在前面第9步中,我们提到“控制可能会在跟随TRAP指令后面的指令中返回给用户空间库过程”，这是有原因的。系统调用可能堵塞调用者,避免它继续执行。例如,如果试图读键盘,但是并没有任何键入,那么调用者就必须被阻塞。在这种情形下,操作系统会査看是否有其他可以运行的进程。稍后,当需要的输入出现时,进程会提醒系统注意,然后步骤9~步骤11会接着进行。

下面几小节中,我们将考察ー些常用的POSIX系统调用,或者用更专业的说法,考察进行这些系统调用的库过程。POSIX大约有100个过程调用,它们中最重要的过程调用列在图1-18中。为方便起见,它们被分成4类。我们用文字简要地叙述其作用。

![image-20240914180932204](现代操作系统_上.assets/image-20240914180932204.png)

> 图1-18ー些重要的POSIX系统调用。若出错则返回代码s为ー1。返回代码如下:pid是进程的id,fd是文件描述符,れ是字节数,position是在文件中的偏移量,而seconds是流逝时间。参数在正文中解释

从广义上看,由这些调用所提供的服务确定了多数操作系统应该具有的功能,而在个人计算机上,资源管理功能是较弱的（至少与多用户的大型机相比较是这样）。所包含的服务有创建与终止进程,创建、删除,读出和写入文件,目录管理以及完成输入/输出。

有必要指出,将POSIX过程映射到系统调用并不是ー对ー的。POSIX标准定义了构造系统所必须提供的ー套过程,但是并没有规定它们是系统调用、库调用还是其他的形式。如果不通过系统调用就可以执行ー个过程（即无须陷入内核）,那么从性能方面考虑,它通常会在用户空间中完成。不过,多数POSIX过程确实进行系统调用,通常是ー个过程直接映射到ー个系统调用上。在ー些情形下,特别是所需要的过程仅仅是某个调用的变体时,ー个系统调用会对应若干个库调用。

1.6.1 用于进程管理的系统调用

图1-18中的第一组调用用于进程管理。将有关fork（派生）的讨论作为本节的开始是较为合适的。在UNIX中,fork是唯一可以在POSIX中创建进程的途径。它创建一个原有进程的精确副本,包括所有的文件描述符、寄存器等内容。在fork之后,原有的进程及其副本（父与子）就分开了。在fork时,所有的变量具有一样的值,虽然父进程的数据被复制用以创建子进程,但是其中一个的后续变化并不会影响到另ー个。（由父进程和子进程共享的程序正文,是不可改变的。）fork调用返回一个值,在子进程中该值为零,并且在父进程中等于子进程的进程标识符（ProcessÏDentifier,PID）。使用返回的PID,就可以在两个进程中看出哪ー个是父进程,哪ー个是子进程。

多数情形下,在fork之后,子进程需要执行与父进程不同的代码。这里考虑shell的情形。它从终端读取命令,创建一个子进程,等待该子进程执行命令,在该子进程终止时,读入下一条命令。为了等待子进程结束,父进程执行waitpid系统调用,它只是等待,直至子进程终止（若有多个子进程的话,则直至任何ー个子进程终止）。waitpid可以等待ー个特定的子进程,或者通过将第一个参数设为ー1的方式,等待任何ー个老的子进程。在waitpid完成之后,将把第二个参数statloc所指向的地址设置为子进程的退出状态（正常或异常终止以及退出值）。有各种可使用的选项,它们由第三个参数确定。例如,如果没有已经退出的子进程则立即返回。

现在考虑shell如何使用fork。在键入一条命令后,shell调用fork创建一个新的进程。这个子进程必须执行用户的命令。通过使用execve系统调用可以实现这ー点,这个系统调用会引起其整个核心映像被ー个文件所替代,该文件由第一个参数给定。（实际上,该系统调用自身是exec系统调用,但是若干个不同的库过程使用不同的参数和稍有差别的名称调用该系统调用。在这里,我们把它们都视为系统调用。）在图1-9中,用一个高度简化的shell说明fork、waitpid以及execve的使用。

![image-20240914180829009](现代操作系统_上.assets/image-20240914180829009.png)

> 图1-19 ー个shell（在本书中,TRUE都被定义为1）

在最一般情形下,execve有三个参数:将要执行的文件名称,ー个指向变量数组的指针,以及ー个指向环境数组的指针。这里对这些参数做ー个简要的说明。各种库例程,包括execl、execv,execle以及execve,允许略掉参数或以各种不同的方式给定。在本书中,我们在所有涉及的地方使用exec描述系统调用。

下面考虑诸如

cp file1 file2

的命令,该命令将file1复制到file2。在shell创建进程之后,该子进程定位和执行文件cp,并将源文件名和目标文件名传递给它。

cp主程序（以及多数其他C程序的主程序）都有声明

main（argc,argv,envp）

其中argc是该命令行内有关参数数目的计数器,包括程序名称。例如,上面的例子中,arge为3。

第二个参数argv是ー个指向数组的指针。该数组的元素i是指向该命令行第i个字符串的指针。在本例中,argv[0]指向字符串“cp"，argv[1]指向字符串“file1",argv[2]指向字符串"file2"。

main的第三个参数envp是ー个指向环境的指针,该环境是ー个数组,含有name=value的赋值形式,用以将诸如终端类型以及根目录等信息传送给程序。还有供程序调用的库过程,用来取得环境变量,这些变量通常用来确定用户希望如何完成特定的任务（例如,使用默认打印机）。在图1-19中,没有环境参数传递给子进程,所以exeeve的第三个参数为0。

![image-20240914180817889](现代操作系统_上.assets/image-20240914180817889.png)

> 图1-20 进程有三段:正文段、数据段和堆栈段

如果读者认为exec过于复杂,那么也不要失望。这是在POSIX的全部系统调用中最复杂的ー个（语义上）,其他的都非常简单。作为ー个简单例子,考虑exit,这是在进程完成执行后应执行的系统调用。这个系统调用有一个参数一退出状态（0至255）,该参数通过waitpid系统调用中的statloc返回父进程。

在UNIX中的进程将其存储空间划分为三段:正文段（如程序代码）、数据段（如变量）以及堆栈段。数据向上增长而堆栈向下增长,如图し20所示。夹在中间的是未使用的地址空间。堆栈在需要时自动地向中间增长,不过数据段的扩展是显式地通过系统调用brk进行的,在数据段扩充后,该系统调用指定一个新地址。但是,这个调用不是POSIX标准中定义的,对于存储器的动态分配,鼓励程序员使用malloc库过程,而malloc的内部实现则不是ー个适合标准化的主题,因为几乎没有程序员直接使用它,我们有理由怀疑是否会有人注意到brk实际不是属于POSIX的。

### 1.6.2 用于文件管理的系统调用

许多系统调用与文件系统有关。本小节讨论在单个文件上的操作,163节将讨论与目录和整个文件系统有关的内容。

要读写ー个文件,先要使用。pen打开该文件。这个系统调用通过绝对路径名或指向工作目录的相对路径名指定要打开文件的名称,而代码〇_RDONLY、O_WRONLY或O_RDWR的含义分别是只读、只写或两者都可以。为了创建一个新文件,使用〇\_CREAT参数。然后可使用返回的文件描述符进行读写操作。接着,可以用close关闭文件,这个调用使得该文件描述符在后续的open中被再次使用。

毫无疑问,最常用的调用是read和write。我们在前面已经讨论过read。write具有与read相同的参数。

尽管多数程序频繁地读写文件,但是仍有一些应用程序需要能够随机访问ー个文件的任意部分。与每个文件相关的是ー个指向文件当前位置的指针。在顺序读（写）时,该指针通常指向要读出（写入）的下ー个字节。∣seek调用可以改变该位置指针的值,这样后续的「ead或write调用就可以在文件的任何地方开始。

∣seek有三个参数:第一个是文件的描述符,第二个是文件位置,第三个说明该文件位置是相对于文件起始位置、当前位置还是文件的结尾。在修改了指针之后,∣seek所返回的值是文件中的绝对位置。

UNIX为每个文件保存了该文件的类型（普通文件、特殊文件、目录等）、大小、最后修改时间以及其他信息。程序可以通过stat系统调用査看这些信息。第一个参数指定了要被检査的文件,第二个参数是ー个指针,该指针指向存放这些信息的结构。对于一个打开的文件而言,fstat调用完成同样的工作。

### 1.6.3 用于目录管理的系统调用

本小节我们讨论与目录或整个文件系统有关的某些系统调用,而不是162节中与一个特定文件有关的系统调用。mkdir和rmdir分别用于创建和删除空目录。下ー个调用是link。它的作用是允许同一个文件以两个或多个名称出现,多数情形下是在不同的目录中这样做。它的典型应用是,在同一个开发团队中允许若干个成员共享一个共同的文件,他们每个人都在自己的目录中有该文件,但可能采用的是不同的名称。共享一个文件,与每个团队成员都有一个私用副本并不是同一件事,因为共享文件意味着任何成员所做的修改都立即为其他成员所见一只有一个文件存在。而在复制了一个文件的多个副本之后,对其中一个副本所进行的修改并不会影响到其他的副本。

为了考察link是如何工作的,考虑图1-21a中的情形。有两个用户ast和jim,每个用户都有一些文件的目录。若ast现在执行一个含有系统调用的程序

```
link("/usr∕jim∕memo","usr∕ast∕note"）;
```

jim目录中的文件memo以文件名note进入ast的目录。之后,/usr/jim/memo和/usr/ast/note都引用相同的文件。顺便提及,用户是将目录保存在/usr、/user、/home还是其他地方,完全取决于本地系统管理员。

理解link是如何工作的也许有助于读者看清其作用。在UNIX中，每个文件都有唯一的编号，即i-编号，用以标识文件。该i-编号是对i-节点表格的一个引用，它们一一对应，说明该文件的拥有者、磁盘块的位置等。目录就是一个包含了(i-编号，ASCII名称)对集合的文件。在UNIX的第一个版本中，每个目录项有16字节--2字节用于i-编号，14字节用于名称。现在为了支持长文件名，采用了更复杂的结构，但是，在概念上，目录仍然是(i-编号，ASCII名称)对的一个集合。在图1-21中，mail为i-编号16等等。link所做的只是利用某个已有文件的i-编号，创建一个新目录项(也许用一个新名称)。在图1-21b中两个目录项有相同的i-编号(70)，从而指向同一个文件。如果使用unlink系统调用将其中一个文件移走了，可以保留另一个。如果两个都被移走了，UNIX00看到尚且存在的文件没有目录项(i-节点中的一个域记录着指向该文件的目录项)，就会把该文件从磁盘中移去。

![image-20240914180804560](现代操作系统_上.assets/image-20240914180804560.png)

> 图1-21a)将/usr/jim/memo链接到ast日录之前的两个目录;b)链接之后的两个目录

正如我们已经叙述过的，mount系统调用允许将两个文件系统合并成为一个。通常的情形是，在硬盘某个分区中的根文件系统含有常用命令的二进制(可执行)版和其他常用的文件，用户文件在另一个分区。并且，用户可插入包含需要读入的文件的U盘。通过执行mount系统调用，可以将一个USB文件系统添加到根文件系统中，如图1-22所示。完成安装操作的典型C语句为

```
mount("/dev/sdb0","/mnt",0);
```

这里，第一个参数是USB驱动器0的块特殊文件名称，第二个参数是要被安装在树中的位置，第三个参数说明将要安装的文件系统是可读写的还是只读的。

![image-20240914181117158](现代操作系统_上.assets/image-20240914181117158.png)

> 图1-22a)安装前的文件系统;b)安装后的文件系统

在mount调用之后，驱动器0上的文件可以使用从根目录开始的路径或工作目录路径，而不用考虑文件在哪个驱动器上。事实上，第二个、第三个以及第四个驱动器也可安装在树上的任何地方。mount调用使得把可移动介质都集中到一个文件层次中成为可能，而不用考虑文件在哪个驱动器上。尽管这是个CD-ROM的例子，但是也可以用同样的方法安装硬盘或者硬盘的一部分(常称为分区或次级设备)，外部硬盘和USB盘也一样。当不再需要一个文件系统时，可以用umount系统调用卸载之。

### 1.6.4 各种系统调用

有各种的系统调用。这里介绍系统调用中的一部分。chdir调用改变当前的工作目录。在调用

```
chdir("/usr/ast/test");
```

之后，打开xyz文件，会打开/usr/asttestxyz。工作目录的概念消除了总是键入(长)绝对路径名的需要。在UNIX中，每个文件有一个保护模式。该模式包括针对所有者、组和其他用户的读一写-执行位。chmod系统调用可以改变文件的模式。例如，要使一个文件对除了所有者之外的用户只读，可以执行

```
chmod("file",0644);
```

kill系统调用供用户或用户进程发送信号用。若一个进程准备好捕捉一个特定的信号，那么，在信号到来时，运行一个信号处理程序。如果该进程没有准备好，那么信号的到来会杀掉该进程(此调用名称的由来)。

POSIX定义了若干处理时间的过程。例如，time以秒为单位返回当前时间，0对应着1970年1月1日午夜(从此日开始，没有结束)。在一台32位字的计算机中，time的最大值是2{32}-1秒(假设是无符号整数)。这个数字对应136年多一点。所以在2106年，32位的UNIX系统会发狂，与2000年对世界计算机造成严重破坏的知名Y2K问题是类似的。如果读者现在有32位UNIX系统，建议在2106年之前的某时刻更换为64位的系统。

1.6.5 Windows Win32 API

到目前为止，我们主要讨论的是UNIX系统。现在简要地考察Windows。Windows和UNIX的主要差别在于编程方式。UNIX程序包括做各种处理的代码以及完成特定服务的系统调用。相反，Windows程序通常是事件驱动程序。其中主程序等待某些事件发生，然后调用一个过程处理该事件。典型的事件包括被敲击的键、移动的鼠标、被按下的鼠标或插入的U盘。调用事件处理程序处理事件，刷新屏幕，并更新内部程序状态。总之，这是与UNIX不同的程序设计风格，由于本书专注于操作系统的功能和结构，这些程序设计方式上的差异就不过多涉及了。

当然，在Windows中也有系统调用。在UNIX中，系统调用(如read)和系统调用所使用的库过程如read)之间几乎是一一对应的关系。换句话说，对于每个系统调用，差不多就涉及一个被调用的库过程，如图1-17所示。此外，POSIX有约100个过程调用。

在Windows中，情况就大不相同了。首先，库调用和实际的系统调用几乎是不对应的。微软定义了一套过程，称为Win32应用编程接口(ApplicationProgramInterface，API)，程序员用这套过程获得操作系统的服务。从Windows95开始的所有Windows版本都(或部分)支持这个接口。由于接口与实际的系统调用不对应，微软保留了随着时间(甚至随着版本到版本)改变实际系统调用的能力，防止已有的程序失效。由于最新几版Windows中有许多过去没有的新调用，所以究竟Win32是由什么构成的，这个问题的答案仍然是含混不清的。在本小节中，Win32表示所有Windows版本都支持的接口。Win32提供各Windows版本的兼容性。

Win32API调用的数量是非常大的，有数千个。此外，尽管其中许多确实涉及系统调用，但有一大批Win32API完全是在用户空间进行的。结果，在Windows中，不可能了解哪一个是系统调用(如由内核完成)，哪一个只是用户空间中的库调用。事实上，某个版本中的一个系统调用，会在另一个不同版本的用户空间中执行，或者相反。当我们在本书中讨论Windows的系统调用时，将使用Win32过程(在合适之处)，这是因为微软保证:随着时间流逝，Win32过程将保持稳定。但是读者有必要记住，它们并不全都是系统调用(即陷入内核中)。

Win32API中有大量的调用，用来管理视窗、几何图形、文本、字体、滚动条、对话框、菜单以及GUI的其他功能。为了使图形子系统在内核中运行(某些Windows版本中确实是这样，但不是所有的版本)，需要系统调用，否则只有库调用。在本书中是否应该讨论这些调用呢?由于它们与操作系统的功能并不相关，我们还是决定不讨论它们，尽管它们会在内核中运行。对Win32API有兴趣的读者应该参阅一些书籍中的有关内容(例如，Hart，1997;Rector和Newcomer，1997;Simon，1997)。我们在这里介绍所有的Win32API，不过这不是我们关心的主要问题，所以做了一些限制，只将那些与图1-18中UNIX系统调用大致对应的Windows调用列在图1-23中。

![image-20240914181445234](现代操作系统_上.assets/image-20240914181445234.png)

下面简要地说明一下图1-23中的内容。CreateProcess用于创建一个新进程，它把UNIX中的fork和execve结合起来。它有许多参数用来指定新创建进程的性质。Windows中没有类似UNIX中的进程层次，所以不存在父进程和子进程的概念。在进程创建之后，创建者和被创建者是平等的。WaitForSingleObject用于等待一个事件，等待的事件可以是多种可能的事件。如果有参数指定了某个进程，那么调用者等待所指定的进程退出，这通过使用ExitProcess完成。

接下来的6个调用进行文件操作，在功能上和UNIX的对应调用类似，而在参数和细节上是不同的。和UNIX中一样，文件可被打开、关闭和写人。SetFilePointer以及GetFileAttributesEx调用设置文件的位置并取得文件的属性。

Windows中有目录，目录分别用CreateDirectory以及RemoveDirectoryAPI调用创建和删除。也有对当前目录的标记，这可以通过SetCurrentDirectory来设置。使用GetLocalTime可获得当前时间。

Win32接口中没有文件的链接、文件系统的安装、安全属性或信号，所以对应于UNIX中的这些调用就不存在了。当然，Win32中也有大量UNIX中不存在的其他调用，特别是管理GUI的各种调用。在WindowsVista中有了精心设计的安全系统，而且支持文件的链接。Windows7和Windows8也加入了更多特性和系统调用。

也许有必要对Win32做最后的说明。Win32并不是一个非常统一的或一致的接口。其主要原因是Win32需要与早期的在Windows3.x中使用的16位接口向后兼容。

## 1.7 操作系统结构

我们已经分析了操作系统的外部(如程序员接口)，现在是分析其内部的时候了。在下面的小节中，为了对各种可能的方式有所了解，我们将考察已经尝试过的六种不同的结构设计。这样做并没有涵盖各种结构方式，但是至少给出了在实践中已经试验过的一些设计思想。我们将讨论的这六种设计包括单体系统、层次式系统、微内核、客户端一服务器模式、虚拟机和外核等。

### 1.7.1 单体系统

到目前为止，在大多数常见的组织中，整个操作系统在内核态以单一程序的方式运行。整个操作系统以过程集合的方式编写，链接成一个大型可执行二进制程序。使用这种技术，系统中每个过程可以自由调用其他过程，只要后者提供了前者所需要的一些有用的计算工作。调用任何一个你所需要的过程或许会非常高效，但上千个可以不受限制地彼此调用的过程常常导致系统笨拙且难于理解。并且，任何个过程的崩溃都会连累整个系统。

在使用这种处理方式构造实际的目标程序时，首先编译所有单个的过程，或者编译包含过程的文件然后通过系统链接程序将它们链接成单一的目标文件。依靠对信息的隐藏处理，不过在这里实际上是不存在的，每个过程对其他过程都是可见的(相反，构造中有模块或包，其中多数信息隐藏在模块之中而且只能通过正式设计的入口点实现模块的外部调用)。

但是，即使在单体系统中，也可能有一些结构存在。可以将参数放置在良好定义的位置(如)通过这种方式，向操作系统请求所能提供的服务(系统调用)，然后执行一个陷阱指令。这个指令将机器从用户态切换到内核态并把控制传递给操作系统，如图1-17中第6步所示。然后，操作系统取出参数并且确定应该执行哪一个系统调用。随后，它在一个表格中检索，在该表格的k槽中存放着指向执行系统调用k过程的指针(图1-17中第7步)。

对于这类操作系统的基本结构，有着如下结构上的建议:

1)需要一个主程序，用来处理服务过程请求。

2)需要一套服务过程，用来执行系统调用。

3)需要一套实用过程，用来辅助服务过程。

在该模型中，每一个系统调用都通过一个服务过程为其工作并运行之。要有一组实用程序来完成一些服务过程所需要用到的功能，如从用户程序取数据等。可将各种过程划分为一个三层的模型，如图1-24所示。

![image-20240914181912642](现代操作系统_上.assets/image-20240914181912642.png)

除了在计算机初启时所装载的核心操作系统外，许多操作系统支持可装载的扩展，诸如I/O设备驱动和文件系统。这些部件可以按照需要载入。在UNIX中它们被叫作共享库(sharedlibrary)，在Windows中则被称为动态链接库(DynamicLinkLibrary，DLL)。它们的扩展类型为.dll，在C:\Windows\system32目录下存在1000多个DDL文件。

### 1.7.2 层次式系统

把图1-24中的系统进一步通用化，就变成一个层次式结构的操作系统，它的上层软件都是在下一层软件的基础之上构建的。E.W.Dikstra和他的学生在荷兰的Eindhoven技术学院所开发的THE系统(1968).是按此模型构造的第一个操作系统。THE系统是为荷兰的一种计算机ElectrologicaX8配备的一个简单的批处理系统，其内存只有32K个字，每字27位(那时二进制位是很昂贵的)。

![image-20240914181928963](现代操作系统_上.assets/image-20240914181928963.png)

该系统共分为六层，如图1-25所示。处理器分配在第0层中进行，当中断发生或定时器到期时，由该层进行进程切换。在第0层之上，系统由一些连续的进程所组成，编写这些进程时不用再考虑在单处理器上多进程运行的细节。也就是说，在第0层中提供了基本的CPU多道程序设计功能。

内存管理在第1层中进行，它分配进程的主存空间，当内存用完时则在一个512K字的磁鼓上保留进程的一部分(页面)。在第1层上，进程不用考虑它是在磁鼓上还是在内存中运行。第1层软件保证一旦需要访问某一页面，该页面必定已在内存中，并在页面不再需要时将其移出。

第2层处理进程与操作员控制台(即用户)之间的通信。在这层的上部，可以认为每个进程都有自己的操作员控制台。第3层管理IO设备和相关的信息流缓冲区。在第3层上，每个进程都与有良好特性的抽象I/O设备打交道，而不必考虑外部设备的物理细节。第4层是用户程序层。用户程序不用考虑进程内存、控制台或I/O设备管理等细节。系统操作员进程位于第5层中。

在MULTICS系统中采用了更进一步的通用层次化概念。MULTICS由许多的同心环构造而成，而不是采用层次化构造，内环比外环有更高的级别(它们实际上是一样的)。当外环的过程欲调用内环的过程时，它必须执行一条等价于系统调用的TRAP指令。在执行该TRAP指令前，要进行严格的参数合法性检查。在MULTICS中，尽管整个操作系统是各个用户进程的地址空间的一部分，但是硬件仍能对单个过程(实际是内存中的一个段)的读、写和执行进行保护。

实际上，THE分层方案只是为设计提供了一些方便，因为该系统的各个部分最终仍然被链接成了完整的单个目标程序。而在MULTICS里，环形机制在运行中是实际存在的，而且是由硬件实现的。环形机制的一个优点是很容易扩展，可用以构造用户子系统。例如，在一个MULTICS系统中，教授可以写一个程序检查学生编写的程序并给他们打分，在第n个环中运行教授的程序，而在第n+1个环中运行学生的程序，这样学生就无法篡改教授所给出的成绩。

### 1.7.3 微内核

在分层方式中，设计者要确定在哪里划分内核一用户的边界。传统上，所有的层都在内核中，但是这样做没有必要。事实上，尽可能减少内核态中功能的做法更好，因为内核中的错误会快速拖累系统。相反，可以把用户进程设置为具有较小的权限，这样，某个错误的后果就不会是致命的。

有不少研究人员对每千行代码中错误的数量进行了分析(例如，Basili和Perricone，1984;Ostrand和Weyuker，2002)。代码错误的密度取决于模块大小、模块寿命等，不过对一个实际工业系统而言，每千行代码中会有2~10个错误。这意味着在有500万行代码的单体操作系统中，大约有10000~50000个内核错误。当然，并不是所有的错误都是致命的，诸如给出了不正确的故障信息之类的某些错误，实际是很少发生的。无论怎样看，操作系统中充满了错误，所以计算机制造商设置了复位按钮(通常在前面板上)，而电视机、立体音响以及汽车的制造商则不这样做，尽管在这些装置中也有大量的软件。

在微内核设计背后的思想是，为了实现高可靠性，将操作系统划分成小的、良好定义的模块，只有其中一个模块--微内核--运行在内核态,其余的模块由于功能相对弱些，则作为普通用户进程运行。特别地，由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使得整个系统死机。所以，音频驱动中的错误会使声音断续或停止，但是不会使整个计算机垮掉。相反，在单体系统中，由于所有的设备驱动都在内核中，一个有故障的音频驱动很容易引起对无效地址的引用，从而造成恼人的系统立即停机。

有许多微内核已经被实现并应用了数十年(Haertig等人，1997;Heiser等人，2006;Herder等人，2006;Hildebrand，1992;Kirsch等人，2005;Liedtke，1993，1995，1996;Pike等人，1992;Zuberi等人，1999)。除了基于Mach微内核(Accetta等人，1986)的OSX外，通常的桌面操作系统并不使用微内核。然而，微内核在实时、工业、航空以及军事应用中特别流行，这些领域都是关键任务，需要有高度的可靠性。知名的微内核有Integrity、K42、L4、PikeOS、QNX、Symbian，以及MINIX3等。这里对MINIX3做一简单的介绍，该操作系统把模块化的思想推到了极致，它将大部分操作系统分解成许多独立的用户态进程。MINIX3遵守POSIX，可在www.minix3.0rg(Giuffrida等人，2012;Giuffrida等人，2013;Herder等人，2006;Herder等人，2009;Hruby等人，2013)站点获得免费的开放源代码。

MINIX3微内核只有12000行C语言代码和1400行用于非常低层次功能的汇编语言代码，诸如捕获中断、进程切换等。C代码管理和调度进程、处理进程间通信(在进程之间传送信息)、提供大约40个内核调用，它们使得操作系统的其余部分可以完成其工作。这些调用完成诸如连接中断句柄、在地址空间中移动数据以及为新创建的进程安装新的内存映像等功能。MINIX3的进程结构如图1-26所示，其中内核调用句柄用Sys标记。时钟设备驱动也在内核中，因为这个驱动与调度器交互密切。所有的其他设备驱动都作为单独的用户进程运行。

![image-20240914182212803](现代操作系统_上.assets/image-20240914182212803.png)

在内核的外部，系统的构造有三层进程，它们都在用户态运行。最底层中包含设备驱动器。由于它们在用户态运行，所以不能物理地访问I0端口空间，也不能直接发出IO命令。相反，为了能够对I0设备编程，驱动器构建了一个结构，指明哪个参数值写到哪个I/O端口，并生成一个内核调用，通知内核完成写操作。这个处理意味着内核可以检查驱动正在对IO的读(或写)是否是得到授权使用的。这样(与单体设计不同)一个有错误的音频驱动器就不能够偶发性地在硬盘上进行写操作。

在驱动器上面是另一用户态层，包含有服务器，它们完成操作系统的多数工作。由一个或多个文件服务器管理着文件系统，进程管理器创建、销毁和管理进程等。通过给服务器发送短消息请求POSIX系统调用的方式，用户程序获得操作系统的服务。例如，一个需要调用read的进程发送一个消息给某个文件服务器，告知它需要读什么内容。

有一个有趣的服务器，称为再生服务器(reincarnationserver)，其任务是检查其他服务器和驱动器的功能是否正确。一旦检查出一个错误，它自动取代之，无须任何用户的干预。这种方式使得系统具有自修复能力，并且获得了较高的可靠性。

系统对每个进程的权限有着许多限制。正如已经提及的，设备驱动器只能与授权的I/O端口接触对内核调用的访问也是按单个进程进行控制的，这是考虑到进程具有向其他多个进程发送消息的能力。进程也可授予有限的许可，让内核的其他进程可访问其地址空间。例如，一个文件系统可以给磁盘驱动器有限的许可，让内核在该文件系统的地址空间内的特定地址上进行对盘块的读入操作。总体来说，所有这些限制是让每个驱动和服务器只拥有完成其工作所需要的权限，这样就极大地限制了故障部件可能造成的危害。

一个与小内核相关联的思想是内核中的机制与策略分离的原则。为了更清晰地说明这一点，我们考虑进程调度。一个比较简单的调度算法是，对每个进程赋予一个优先级，并让内核执行具有最高优先级的进程。这里，机制(在内核中)就是寻找最高优先级的进程并运行之。而策略(赋予进程优先级)可以由用户态中的进程完成。在这种方式中，机制和策略是分离的，从而使系统内核变得更小。

### 1.7.4 客户端一服务器模式

一个微内核思想的略微变体是将进程划分为两类:服务器，每个服务器提供某种服务;客户端，使用这些服务。这个模式就是所谓的客户端一服务器模式。通常，在系统最底层是微内核，但并不是必须这样。这个模式的本质是存在客户端进程和服务器进程。

一般来说，客户端和服务器之间的通信是消息传递。为了获得一个服务，客户端进程构造一段消息说明所需要的服务，并将其发给合适的服务器。该服务器完成工作，发送回应。如果客户端和服务器恰巧运行在同一个机器上，则有可能进行某种优化，但是从概念上看，这里讨论的是消息传递。

这个思想的一个显然的普遍方式是，客户端和服务器运行在不同的计算机上，它们通过局域网或广域网连接，如图1-27所示。由于客户端通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的:都是发送请求并得到回应。所以，客户端-服务器模式是一种可以应用在单机或者网络机器上的抽象。

越来越多的系统，包括用户家里的PC，都成为客户端，而在某地运行的大型机器则成为服务器事实上，许多Web就是以这个方式运行的。一台PC向某个服务器请求一个Web页面，而后，该Web页面回送。这就是网络中客户端一服务器的典型应用方式。

![image-20240914182412401](现代操作系统_上.assets/image-20240914182412401.png)

### 1.7.5 虚拟机

OS/360的最早版本是纯粹的批处理系统。然而，有许多360用户希望能够在终端上交互工作，于是IBM公司内外的一些研究小组决定为它编写一个分时系统。后来推出了正式的IBM分时系统TSS/360。但是它非常庞大，运行缓慢，干是在花费了约5000万美元的研制费用后，该系统最后被弃之不用(Graham，1970)。但是在位于麻省剑桥的IBM研究中心开发了另一个完全不同的系统，这个系统最终被IBM用作产品。它的直接后代，称为z/VM，目前在IBM的大型机上广泛使用，zSeries则在大型公司的数据中心广泛使用，例如，作为电子商务服务器，它们每秒可以处理成百上千个事务，并使用规模达数百万GB的数据库。

#### 1.VM/370

这个系统最初被命名为CP/CMS，后来改名为VM/370(Seawright和MacKinnon，1979)。它是源于如下机敏的观察，即分时系统应该提供这些功能:(1)多道程序，(2)一个比裸机更方便的、有扩展界面的计算机。VM/370存在的目的是将二者彻底地隔离开来。

![image-20240914182527527](现代操作系统_上.assets/image-20240914182527527.png)

这个系统的核心称为虚拟机监控程序(virtual machine monitor)，它在裸机上运行并且具备了多道程序功能。该系统向上层提供了若干台虚拟机，如图1-28所示。它不同于其他操作系统的地方是:这些虚拟机不是那种具有文件等优良特征的扩展计算机。与之相反，它们仅仅是裸机硬件的精确复制品。这个复制品包含了内核态/用户态、I/0功能、中断及其他真实硬件所应该具有的全部内容。

由于每台虚拟机都与裸机相同，所以在每台虚拟机上都可以运行一台裸机所能够运行的任何类型的操作系统。不同的虚拟机可以运行不同的操作系统，而且实际上往往就是如此。在早期的VM/370系统上，有一些系统运行OS/360或者其他大型批处理或事务处理操作系统，而另一些虚拟机运行单用户、交互式系统供分时用户使用，这个系统称为会话监控系统(ConversationalMonitorSystem，CMS)。后者在程序员中很流行。

当一个CMS程序执行系统调用时，该调用被陷入到其虚拟机的操作系统上，而不是VM370上，似平它运行在实际的机器上，而不是在虚拟机上。CMS然后发出普通的硬件IO指令读出虚拟磁盘或其他需要执行的调用。这些I/O指令由VM/370陷入，然后，作为对实际硬件模拟的一部分，VM/370完成指令通过对多道程序功能和提供扩展机器二者的完全分离，每个部分都变得非常简单、非常灵活且容易维护。

虚拟机的现代化身z/VM通常用于运行多个完整的操作系统，而不是简化成如CMS一样的单用户系例如，zSeries有能力与传统的IBM操作系统一起，运行一个或多个Linux虚拟机。

#### 2.虚拟机的再次发现

IBM拥有虚拟机产品已经有40年了，而少数公司，包括Oracle公司和Hewlett-Packard公司等，近来也在其高端企业服务器上增加对虚拟机的支持，在PC上，直到最近之前，虚拟化的思想在很大程度上被忽略了。不过近年来，新的需求、新的软件和新的技术已经使得虚拟机成为热点。

首先看需求。传统上，许多公司在不同的计算机上，有时还在不同的操作系统上，运行其邮件服务器、Web服务器、FTP服务器以及其他服务器。他们看到可以在同一台机器上实现虚拟化来运行所有的服务器，而不会由于一个服务器崩溃影响其他系统。

虚拟化在Web托管世界里也很流行。没有虚拟化，Web托管客户端只能共享托管(在Web服务器上给客户端一个账号，但是不能控制整个服务器软件)以及独占托管(提供给客户端整个机器，这样虽然很灵活，但是对于小型或中型Web站点而言，成本效益比不高)。当Web托管公司提供租用虚拟机时，一台物理机器就可以运行许多虚拟机，每个虚拟机看起来都是一台完全的机器。租用虚拟机的客户端可以运行自己想使用的操作系统和软件，但是只需支付独占一台机器的几分之一的费用(因为一台物理机器可以同时支持多台虚拟机)。

虚拟化的另外一个用途是，为希望同时运行两个或多个操作系统(比如Windows和Limnux)的最终用户服务，某个偏好的应用程序可运行在一个操作系统上，而其他的应用程序可运行在另一个操作系统上。如图129a所示，在这里术语“虚拟机监控程序”已经被重命名为第一类虚拟机管理程序(type1hypervisor)后者现在更常用，因为输入前者的英文“virtual machine monitor”超出了人们所能接受的按键次数。

![image-20240914182700343](现代操作系统_上.assets/image-20240914182700343.png)

虚拟机的吸引力是没有争议的，问题在于实现。为了在一台计算机上运行虚拟机软件，其CPU必须被虚拟化(Popek和Goldberg，1974)。简言之，存在一个问题。当运行虚拟机(在用户态)的操作系统执行某个特权指令时，比如修改PSW或进行IO操作，硬件实际上陷入到了虚拟机中，这样有关指令就可以在软件中模拟。在某些CPU上(特别是Pentium和它的后继者及其克隆版中)试图在用户态执行特权指令时，会被忽略掉。这种特性使得在这类硬件中无法实现虚拟机，这也解释了PC世界对虚拟机不感兴趣的原因。当然，对于Pentium而言，还有解释器可以运行在Pentium上，例如Bochs但是其性能丧失了1~2数量级，这样对于要求高的工作来说就没有意义了。

由于20世纪90年代和本世纪这些年来若于学术研究小组的努力，特别是斯坦福大学的Disco(Bugnion等人，1997)和剑桥大学的Xen(Barham等人，2003)实现了商业化产品(例如VMware工作站和Xen)，使得人们对虚拟机的热情得以复燃。除了VMware和Xen外，现在流行的虚拟机管理程序还有KVM(针对Linux内核)、Oracle公司的VirtualBox以及微软公司的Hyper-V。

一些早期研究项目通过即时翻译大块代码、将其存储到内部高速缓存并在其再次执行时复用的方式，提高了Bochs等翻译器的性能。这种手段大幅提高了性能，也推动了模拟器(machine simulator)的出现，如图1-29b所示。这项被称为二进制翻译(binarytranslation)的技术对性能的提升有所帮助，不过生成的系统虽然优秀到足以在学术会议上发表论文，但仍没有快到可以在极其注重性能的商业环境下使用。

改善性能的下一步在于添加分担重担的内核模块，如图1-29c所示。事实上，现在所有商业可用的虎拟机管理程序都使用这种混合策略(并且也有很多其他改进)，如VMware工作站。它们被称为第二类虚拟机管理程序，本书中我们也延续使用这个名称(虽然有些不太情愿)，即使我们更愿意用类型1.7虚拟机管理程序来反映它们并不完全是用户态程序。在第7章中，我们将详细描述VMware工作站的工作原理及其各部分的作用。

实际上，第一类和第二类虚拟机管理程序的真正区别在于，后者利用宿主操作系统(hostoperatingsystem)并通过其文件系统创建进程、存储文件等。第一类虚拟机管理程序没有底层支持，所以必须自行实现所有功能。

当第二类虚拟机管理程序启动时，它从CD-ROM安装盘中读入供选择的客户操作系统(guesoperatingsystem)，并安装在一个虚拟盘上，该盘实际上只是宿主操作系统的文件系统中的一个大文件。由于没有可以存储文件的宿主操作系统，因此第一类虚拟机管理程序不能采用这种方式。它们必须在原始的硬盘分区上自行管理存储。

在客户操作系统启动时，它完成的工作与在真实硬件上相同，如启动一些后台进程，然后是GUI对用户而言，客户操作系统与在裸机上运行时表现出相同的行为，虽然事实并非如此。

处理控制指令的一种不同方式是，修改操作系统，删掉它们。这种方式不是真正的虚拟化，而是半虚拟化(paravirtualization)。我们将在第7章具体讨论虚拟化。

#### 3.Java虚拟机

另一个使用虚拟机的领域，是为了运行Java程序，但方式有些不同。在Sun公司发明Java程序设计语言时，也同时发明了称为JVM(JavaVirtualMachine)的虚拟机(一种体系结构)。Java编译器为IVM生成代码，这些代码以后可以由一个软件IM解释器执行。这种处理方式的优点在于，IVM代码可以通过Internet传送到任何有JVM解释器的计算机上，并在该机器上执行。举例来说，如果编译器生成了SPARC或Pentium二进制代码，这种代码不可能轻易地送到任何地方并执行。(当然，Su可以生产一种生成SPARC二进制代码的编译器，并且发布一种SPARC解释器，但是IVM具有非常简单的、只需要解释的体系结构。)使用JVM的另一种优点是，如果解释器正确地完成，并不意味着就结束了，还要对所输入的IVM进行安全性检查然后在一种保护环境下执行，这样，这些程序就不能偷窃数据或进行其他任何有害的操作。

### 1.7.6 外核

与虚拟机克隆真实机器不同，另一种策略是对机器进行分区，换句话说，给每个用户整个资源的一个子集。这样，某个虚拟机可能得到磁盘的0至1023盘块，而另一台虚拟机会得到1024至2047盘块，等等。

在底层中，一种称为外核(exokernel，Engler等人，1995)的程序在内核态运行。它的任务是为虚拟机分配资源，并检查使用这些资源的企图，以确保没有机器会使用他人的资源。每个用户层的虚拟机可以运行自己的操作系统，如VM/370和Pentium虚拟8086等，但限制只能使用已经申请并且获得分配的那部分资源。

外核机制的优点是，它减少了映像层。在其他的设计中，每个虚拟机都认为它有自己的磁盘，其盘块号从0到最大编号，这样虚拟机监控程序必须维护一张表格以重映像磁盘地址(以及其他资源)。有了外核，这个重映像处理就不需要了。外核只需要记录已经分配给各个虚拟机的有关资源即可。这个方法还有一个优点，它将多道程序(在外核内)与用户操作系统代码(在用户空间内)加以分离，而且相应负载并不重，这是因为外核所做的只是保持多个虚拟机彼此不发生冲突。

## 1.8 依靠C的世界

操作系统通常是由许多程序员写成的，包括很多部分的大型C(有时是C++)程序。用于开发操作系统的环境，与个人(如学生)用于编写小型Java程序的环境是非常不同的。本节试图为那些有时编写Java或者Python程序的程序员简要地介绍编写操作系统的环境。

### 1.8.1 C语言

这里不是C语言的指南，而是简要介绍C与类Python语言特别是Java之间的关键差别。Java是基于C的，所以两者之间有许多类似之处。Python有一点不同，但仍然十分相似。为方便起见，我们将注意力放在Java上。Java、Python和C都是命令式的语言，例如，有数据类型、变量和控制语句等。在C中基本数据类型是整数(包括短整数和长整数)、字符和浮点数等。使用数组、结构体和联合，可以构造组合数据类型。C语言中的控制语句与Java类似，包括if、switch、for以及while等语句。在这两个语言中函数和参数大致相同。

一项C语言中有而Java和Python中没有的特点是显式指针(explicitpointer)。指针是一种指向(即包含对象的地址)一个变量或数据结构的变量。考虑下面的语句:

```cpp
char c1，c2,*p;
c1='C';
p=&c1;
C2=*p;
```

这些语句声明c1和c2是字符变量，而p是指向一个字符的变量(即包含字符的地址)。第一个赋值语句将字符c的ASCII代码存到变量c1中。第二个语句将c1的地址赋给指针变量p。第三个语句将由p指向变量的内容赋给变量c2，这样，在这些语句执行之后，c2也含有c的ASCII代码。在理论上，指针是输入类型所以不能将浮点数地址赋给一个字符指针，但是在实践中，编译器接受这种赋值，尽管有时给出一个警告。指针是一种非常强大的结构，但是如果不仔细使用，也会是造成大量错误的一个原因。

C语言中没有包括内建字符串、线程、包、类、对象、类型安全(typesafety)以及垃圾回收(garbage collection)等。最后一个是操作系统的“淋浴器塞子”。在C中分配的存储空间或者是静态的，或者是程序员明确分配和释放的，通常使用malloc以及free库函数。正是由于后面这个性质---由程序员控制所有内存--而且是用明确的指针，使得C语言对编写操作系统而言非常有吸引力。从一定程度上来说操作系统实际上是个实时系统，甚至通用系统也是实时系统。当中断发生时，操作系统可能只有若干微秒去完成特定的操作，否则就会丢失关键的信息。在任意时刻启动垃圾回收功能是不可接受的。

### 1.8.2 头文件

一个操作系统项目通常包括多个目录，每个目录都含有许多.c文件，这些文件中存有系统某个部分的代码，而一些上头文件则包含供一个或多个代码文件使用的声明以及定义。头文件还可以包括简单的宏，如

```
#define BUFFERSIZE 4096
```

宏允许程序员命名常数，这样代码中出现的BUFFER_SIZE在编译时就被数值4096所替代。良好的C程序设计实践是命名除了0，1和-1之外的所有常数，有时甚至也命名这三个数。宏可以附带参数，例如

```
#define max(a,b)(a>b?a:b)
```

这个宏允许程序员编写

```
i=max(j，k+1)
```

从而得到

```
i=(j>k+1?j:k+1)
```

将j与k+1之间的较大者存储在i中。头文件还可以包含条件编译，例如

```
#ifdef X86
intel_int_ack();
#endif
```

如果宏x86有定义，而不是其他，则编译进对intel_int_ack函数的调用。为了分隔与结构有关的代码，大量使用了条件编译，这样只有当系统在x86上编译时，一些特定的代码才会被插入，其他的代码仅当系统在SPARC等机器上编译时才会插入。通过使用#include指令，一个,c文件体可以含有零个或多个头文件。

### 1.8.3 大型编程项目

为了构建操作系统，每个.c被C编译器编译成一个目标文件。目标文件使用后缀.0，含有目标机器的二进制代码。随后它们可以直接在CPU上运行。在C的世界里，没有类似于Java字节代码的东西。

C编译器的第一道称为C预处理器。在它读入每个.c文件时，每当遇到一个#include指令，就取来该名称的头文件，并加以处理、扩展宏、处理条件编译(以及其他事务)，然后将结果传递给编译器的下一道，仿佛它们原先就包含在该文件中一样。

由于操作系统非常大(500万行代码是很寻常的)，每当文件修改后就重新编译是无法忍受的。另一方面，改变了用在成千上万个文件中的一个关键头文件，确实需要重新编译这些文件。没有一定的协助要想记录哪个目标文件与哪个头文件相关是完全不可行的。

幸运的是，计算机非常善于处理事物分类。在UNIX系统中，有个名为make的程序(其大量的变体如gmake、pmake等)，它读入Makefile，该Makefle说明哪个文件与哪个文件相关。make的作用是，在构建探作系统二进制码时，检查此刻需要哪个目标文件，而且对于每个文件，检查自从上次目标文件创建之后是否有任何它依赖的文件(代码和头文件)已经被修改了。如果有，目标文件需要重新编译。在make确定了哪个.0文件需要重新编译之后，它调用C编译器重新编译这些文件，这样，就把编译的次数降到最低限度在大型项目中，创建Makefle是一件容易出错的工作，所以出现了一些工具使该工作能够自动完成。

一旦所有的.o文件就绪，这些文件被传递给称为linker的程序，将其组合成一个可执行的二进制文件。此时，任何被调用的库函数都已经包含在内，函数之间的引用都已经解决，而机器地址也都按需要分配完毕。在linker完成之后，得到一个可执行程序，在UNIX中传统上称为a.out文件。这个过程中的名个部分如图1-30所示，图中的程序包含三个C文件和两个头文件。这里虽然讨论的是有关操作系统的开发，但是所有内容对开发任何大型程序而言都是适用的。

![image-20240914183410416](现代操作系统_上.assets/image-20240914183410416.png)

### 1.8.4 运行模型

在操作系统二进制代码链接完成后，计算机就可以重新启动，新的操作系统开始运行。一旦运行，系统会动态调入那些没有静态包括在二进制代码中的模块，如设备驱动和文件系统。在运行过程中，操作系统可能由若干段组成，有文本段(程序代码)、数据段和堆栈段。文本段通常是不可改变的，在运行过程中不可修改。数据段开始时有一定的大小，并用确定的值进行初始化，但是随后就被修改了，其大小随需要增长。堆栈段被初始化为空，但是随着对函数的调用和从函数返回，堆栈段时时刻刻在增长和缩小。通常文本段放置在接近内存底部的位置，数据段在其上面，这样可以向上增长。而堆栈段处于高位的虚拟地址，具有向下增长的能力，不过不同系统的工作方式各有差别。

在所有情形下，操作系统代码都是直接在硬件上执行的，不用解释器，也不是即时编译，如Java通常做的那样。

## 1.9 有关操作系统的研究

计算机科学是快速发展的领域，很难预测其下一步的发展方向。大学和产业研究实验室中的研究人员始终在思考新的思想，这些新思想中的某些内容并没有什么用处，但是有些新思想会成为未来产品的基石，并对产业界和用户产生广泛的影响。当然，事后解说要比当时说明容易得多。将小麦从稗子中分离出来是非常困难的，因为一种思想从出现到形成影响常常需要20~30年。

例如，当艾森豪威尔总统在1958年建立国防部高级研究计划署(ARPA)时，他试图通过五角大楼的研究预算来削弱海军和空军并维护陆军的地位。他并不是想要发明Internet。但是ARPA做的一件事是给予一些大学资助，用以研究模糊不清的包交换概念，这个研究很快导致了第一个实验性的包交换网的建立，即ARPANET。该网在1969年启用。没有多久，其他被ARPA资助的研究网络也连接到ARPANET上，于是Internet诞生了。Internet“愉快地”为学术研究人员互相发送了20年的电子邮件到了20世纪90年代早期，TimBerners-Lee在日内瓦的CERN研究所发明了万维网(World Wide Web)而MarcAndreesen在伊利诺伊大学为万维网写了一个图形浏览器。突然，Internet上充满了年轻人的聊天活动。

对操作系统的研究也导致了实际操作系统的戏剧性变化。正如我们较早所讨论的，第一代商用计算机系统都是批处理系统，直到20世纪60年代早期MIT发明了交互式分时系统为止。20世纪60年代后期，即在DougEngelbart于斯坦福研究院发明鼠标和图形用户接口之前，所有的计算机都是基于文本的。有谁知道下一个发明将会是什么呢?

在本节和本书的其他相关章节中，我们会简要地介绍一些在过去5~10年中操作系统的研究工作，这是为了让读者了解可能会出现什么。这个介绍当然不全面，而且主要依据在高水平的期刊和会议上已经发表的文章，因为这些文章为了得以发表至少需要经过严格的同行评估过程。值得注意的是，相对于其他科学领域，计算机科学中的大多数研究都是在会议而非期刊上公布的。在有关研究内容一节中所引用的多数文章，发表在ACM刊物、IEEE计算机协会刊物或者USENIX刊物上，并对这些组织的(学生)成员在Internet上开放。有关这些组织的更多信息以及它们的数字图书馆，可以访问:

- ACM http://www.acm.org
- IEEE计算机协会 http://www.computer.org
- USENIX http://www.usenix.org

实际上，所有的操作系统研究人员都认识到，目前的操作系统是一个不灵活、不可靠、不安全和带有错误的大系统，而且某个特定的操作系统较其他的系统有更多的错误(这里略去了名称以避免责任)。所带来的结果是，大量的研究集中于如何构造更好的操作系统。近来出版的文献有如下一些:关于错误和调试(Renzelmann等人，2012:Zhou等人，2012)，故障恢复(Correia等人，2012;Ma等人2013;0ngaro等人，2011;Yeh和Cheng，2012)，能源管理(Pathak等人，2012;Petrucci和Logues2012:Shen等人，2013)，文件和存储系统(EInably和Wang，2012:Nightingale等人，2012:Zhang等人，2013a)，高性能I/0(DeBruijn等人，2011;Li等人，2013a;Rizz0，2012)，超线程与多线程(Li等人，2011)，在线更新(Giuffrida等人，2013)，管理GPU(Rossbach等人，2011)，内存管理(Jantz等人，2013;Jeong等人，2013)，多核操作系统(Baumann等人，2009;Kapritsos，2012;Lachaize等人，2012;Wentzlaff等人，2012)，操作系统正确性(Elphinstone等人，2007;Yang等人，2006;Klein等人2009)，操作系统可靠性(Hruby等人，2012;Ryzhyk等人，2009，2011;Zheng等人，2012)，隐私与安全(Dunn等人，2012;Giuffrida等人，2012;Li等人，2013b;Lorch等人，2013;0rtolani和Crispo，2012:Slowinska等人，2012;dranath等人，2012)，虚拟化(Agesen等人，2012;Ben-Yehuda等人，2010;Colp等人，2011;Dai等人，2013;Tarasov等人，2013;Wiliams等人，2012)。

## 1.10 本书其他部分概要

我们已经叙述完毕引论，并且描绘了操作系统的图景。现在是进入具体细节的时候了。正如前面已经叙述的，从程序员的观点来看，操作系统的基本目的是提供一些关键的抽象，其中最重要的是进程和线程、地址空间以及文件。所以后面三章都是有关这些关键主题的。

第2章讨论进程与线程，包括它们的性质以及它们之间如何通信。这一章还给出了大量关于进程间如何通信的例子以及如何避免某些错误。

第3章具体讨论地址空间以及内存管理，讨论虚拟内存等重要课题，以及相关的概念，如页处理和分段等。

第4章里，我们会讨论有关文件系统的所有重要内容。在某种程度上，用户看到的是大量文件系统我们将研究文件系统接口和文件系统的实现。

输入/输出是第5章的内容。这一章介绍设备独立性和设备依赖性的概念，将以若干重要的设备(包括磁盘、键盘以及显示设备)为例进行讲解。

第6章讨论死锁。在这一章中我们概要地说明什么是死锁，还讨论避免死锁的方法。

到此，我们完成了对单CPU操作系统基本原理的学习。不过，还有更多的高级内容要叙述。在第7章里，我们将考察虚拟化，其中既会讨论原则，又将详细讨论一些现存的虚拟化方案。另一个高级课题是多处理机系统，包括多处理器、并行计算机以及分布式系统。这些内容放在第8章中讨论。

有一个非常重要的主题就是操作系统安全，它是第9章的内容。在这一章中讨论的内容涉及威胁(例如，病毒和蠕虫)、保护机制以及安全模型。

随后，我们安排了一些实际操作系统的案例。它们是:UNIX、Linux和Android(第10章)Windows8(第11章)。本书以第12章关于操作系统设计的一些思考作为结束。

## 1.11 公制单位

为了避免混乱，有必要在本书中特别指出，考虑到计算机科学的通用性，所以我们采用公制来代替传统的英制。在图1-31中列出了主要的公制前缀。前缀是英文单词前面字母的缩写，凡是单位大于1的首字母均大写。这样，一个1TB的数据库占据了10{12}字节的存储空间，而100psec(或100ps)的时钟每隔10(-10)s的时间滴答一次。由于milli和micro均以字母“m”开头，所以必须对两者做出区分。通常，用“m”表示milli，而用“μ”(希腊字母)表示micro。

![image-20240914183835952](现代操作系统_上.assets/image-20240914183835952.png)

这里需要说明的还有关于存储器容量的度量，在工业实践中，各个单位的含义稍有不同。这里Kilo表示2(-10-)(1024)而不是10(-3-)(1000)，因为存储器大小总是2的幂。这样1KB存储器就有1024个字节，而不是1000个字节。类似地，1MB存储器有22(-20-)(1048576)个字节，1GB存储器有2(-30-)(1073741824)个字节。但是，1Kb/s的通信线路每秒传送1000个位，而10Mb/s的局域网在10000000位/秒的速率上运行，因为这里的速率不是2的幂。很不幸，许多人倾向于将这两个系统混淆，特别是混淆关于磁盘容量的度量。在本书中，为了避免含糊，我们使用KB、MB和GB分别表示2(-10-)字节、22(-20-)字节和23(-30-)字节，而用符号Kb/s、Mb/s和Gb/s分别表示10(-3-)b/s、10(-6-)b/s和10(-9-)b/s。

## 1.12 小结

考察操作系统有两种观点:资源管理观点和扩展的机器观点。在资源管理观点中，操作系统的任务是有效地管理系统的各个部分。在扩展的机器观点中，系统的任务是为用户提供比实际机器更便于运用的抽象。这些抽象包括进程、地址空间以及文件。

操作系统的历史很长，从操作系统开始替代操作人员的那天开始到现代多道程序系统，主要包括早期批处理系统、多道程序系统以及个人计算机系统。

由于操作系统同硬件的交互密切，掌握一些硬件知识对于理解它们是有益的。计算机由处理器、存储器以及I/O设备组成。这些部件通过总线连接。

所有操作系统构建所依赖的基本概念是进程、存储管理、I/O管理、文件管理和安全。这些内容都将在后续用一章来讲述。

任何操作系统的核心是它可处理的系统调用集。这些系统调用真实地说明了操作系统所做的工作。对于UNIX，我们已经考察了四组系统调用。第一组系统调用同进程的创建和终止有关;第二组用于读写文件;第三组用于目录管理;第四组包括各种杂项调用。

操作系统构建方式有多种。最常见的有单体系统、层次化系统、微内核系统、客户端-服务器系统虚拟机系统和外核系统。



# 第二章 进程与线程

从本章开始，我们将深入考察操作系统是如何设计和构造的。操作系统中最核心的概念是进程:这是对正在运行程序的一个抽象。操作系统的其他所有内容都是围绕着进程的概念展开的，所以，让操作系统的设计者(及学生)尽快并透彻地理解进程是非常重要的。

进程是操作系统提供的最古老的也是最重要的抽象概念之一。即使可以使用的CPU只有一个但它们也具有支持(伪)并发操作的能力，它们将一个单独的CPU变换成多个虚拟的CPU。没有进程的抽象，现代计算将不复存在。本章会通过大量的细节去探究进程，以及它们的第一个亲戚-线程。

## 2.1 进程

所有现代的计算机经常会在同一时间做许多件事。习惯于在个人计算机上工作的人们也许不会十分注意这个事实，因此列举一些例子可以更清楚地说明这一问题。先考虑一个网络服务器，一些网页请求从各处进入。当一个请求进入时，服务器检查其需要的网页是否在缓存中。如果是，则把网页发送回去，如果不是，则启动一个磁盘请求以获取网页。然而，从CPU的角度来看，磁盘请求需要漫长的时间当等待磁盘请求完成时，其他更多的请求将会进入。如果有多个磁盘存在，可以在满足第一个请求之前就接二连三地对其他的磁盘发出部分或全部请求。很明显，需要一些方法去模拟并控制这种并发。进程(特别是线程)在这里就可以发挥作用。

现在考虑只有一个用户的PC。一般用户不知道，当启动系统时，会秘密启动许多进程。例如，启动一个进程用来等待进入的电子邮件;或者启动另一个防病毒进程周期性地检查是否有病毒库更新。另外，某个用户进程可能会在所有用户上网的时候打印文件以及刻录CD-ROM。这些活动都需要管理，于是一个支持多进程的多道程序系统在这里就显得很有用了。

在任何多道程序设计系统中，CPU由一个进程快速切换至另一个进程，使每个进程各运行几十或几百毫秒。严格地说，在某一个瞬间，CPU只能运行一个进程。但在1秒钟内，它可能运行多个进程，这样就产生并行的错觉。有时人们所说的伪并行就是指这种情形，以此来区分多处理器系统(该系统有两个或多个CPU共享同一个物理内存)的真正硬件并行。人们很难对多个并行活动进行跟踪，因此，经过多年的努力，操作系统的设计者开发了用于描述并行的一种概念模型(顺序进程)，使得并行更容易处理。有关该模型、它的使用以及它的影响正是本章的主题。

### 2.1.1 进程模型

在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干顺序进程(sequentialprocess)，简称进程(process)。一个进程就是一个正在执行程序的实例，包括程序计数器寄存器和变量的当前值。从概念上说，每个进程拥有它自己的虚拟CPU。当然，实际上真正的CPU在名进程之间来回切换。但为了理解这种系统，考虑在(伪)并行情况下运行的进程集，要比试图跟踪CPU如何在程序间来回切换简单得多。正如在第1章所看到的，这种快速的切换称作多道程序设计。

在图2-1a中可以看到，在一台多道程序计算机的内存中有4道程序。在图2-1b中，这4道程序被抽象为4个各自拥有自己控制流程(即每个程序自己的逻辑程序计数器)的进程，并且每个程序都独立地运行。当然，实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束(或暂停执行)时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中。在图2-1c中可以看到，在观察足够长的一段时间后，所有的进程都运行了，但在任何一个给定的瞬间仅有一个进程真正在运行。

![image-20240914184443971](现代操作系统_上.assets/image-20240914184443971.png)

在本章，我们假设只有一个CPU。当然，逐渐这个假设就不为真了，因为新的芯片经常是多核的，包含2个、4个或更多的CPU。第8章将会介绍多核芯片以及多处理器，但是现在，一次只考虑一个CPU会更简单一些。因此，当我们说一个CPU只能真正一次运行一个进程的时候，即使有2个核(或CPU)每一个核也只能一次运行一个进程。

由于CPU在各进程之间来回快速切换，所以每个进程执行其运算的速度是不确定的。而且当同一进程再次运行时，其运算速度通常也不可再现。所以，在对进程编程时决不能对时序做任何想当然的假设。例如，考虑一个IO进程，它用流式磁带机恢复备份的文件，它执行一个10000次的空循环以等待磁带机达到正常速度，然后发出命令读取第一个记录。如果CPÙ决定在空循环期间切换到其他进程，则磁带机进程可能在第一条记录通过磁头之后还未被再次运行。当一个进程具有此类严格的实时要求时，也就是一些特定事件一定要在所指定的若干毫秒内发生，那么必须采取特殊措施以保证它们一定在这段时间中发生。然而，通常大多数进程并不受CPU多道程序设计或其他进程相对速度的影响。

进程和程序间的区别是很微妙的，但非常重要。用一个比喻可以更容易理解这一点。想象一位有一手好厨艺的计算机科学家正在为他的女儿烘制生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原料:面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序(即用适当形式描述的算法)，计算机科学家就是处理器(CPU)，而做蛋糕的各种原料就是输入数据。进程就是厨师阅读食谱、取来各种原料以及烘制蛋糕等一系列动作的总和。

现在假设计算机科学家的儿子哭着跑了进来，说他的头被一只蜜蜂蛰了。计算机科学家就记录下他照着食谱做到哪儿了(保存进程的当前状态)，然后拿出一本急救手册，按照其中的指示处理蛰伤。

这里，处理机从一个进程(做蛋糕)切换到另一个高优先级的进程(实施医疗救治)，每个进程拥有各自的程序(食谱和急救手册)。当蜜蜂蛰伤处理完之后，这位计算机科学家又回来做蛋糕，从他离开时的那一步继续做下去。

这里的关键思想是:一个进程是某种类型的一个活动，它有程序、输入、输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另一个进程提供服务。

值得注意的是，如果一个程序运行了两遍，则算作两个进程。例如，人们可能经常两次启动同一个字处理软件，或在有两个可用的打印机的情况下同时打印两个文件。像“两个进程恰好运行同一个程序”这样的事实其实无关紧要，因为它们是不同的进程。操作系统能够使它们共享代码，因此只有一个副本放在内存中，但那只是一个技术性的细节，不会改变有两个进程正在运行的概念。

### 2.1.2 进程的创建

操作系统需要有一种方式来创建进程。一些非常简单的系统，即那种只为运行一个应用程序设计的系统(例如，微波炉中的控制器)，可能在系统启动之时，以后所需要的所有进程都已存在。然而，在通用系统中，需要有某种方法在运行时按需要创建或撤销进程，现在开始考察这个问题。

4种主要事件会导致进程的创建:

1)系统初始化。

2)正在运行的程序执行了创建进程的系统调用

3)用户请求创建一个新进程。

4)一个批处理作业的初始化。

启动操作系统时，通常会创建若干个进程。其中有些是前台进程，也就是同用户（人类）交互并且替他们完成工作的那些进程。其他的是后台进程，这些进程与特定的用户没有关系，相反，却具有某些专门的功能。例如，设计一个后台进程来接收发来的电子邮件，这个进程在一天的大部分时间都在睡眠，但是当电子邮件到达时就突然被唤醒了。也可以设计另一个后台进程来接收对该机器中Web页面的访问请求，在请求到达时唤醒该进程以便服务该请求。停留在后台处理诸如电子邮件、Web页面、新闻、打印之类活动的进程称为守护进程（daemon）。在大型系统中通常有很多守护进程。在UNIX中，可以用ps程序列出正在运行的进程，在Windows中，可使用任务管理器。

除了在启动阶段创建进程之外，新的进程也可以以后创建。一个正在运行的进程经常发出系统调用，以便创建一个或多个新进程协助其工作。在所要从事的工作可以容易地划分成若干相关的但没有相互作用的进程时，创建新的进程就特别有效果。例如，如果有大量的数据要通过网络调取并进行顺序处理，那么创建一个进程取数据，并把数据放入共享缓冲区中，而让第二个进程取走数据项并处理之，应该比较容易。在多处理机中，让每个进程在不同的CPU上运行会使整个作业运行得更快。

在交互式系统中，键人一个命令或者点（双）击一个图标就可以启动一个程序。这两个动作中的任何一个都会开始一个新的进程，并在其中运行所选择的程序。在基于命令行的UNIX系统中运行程序X，新的进程会从该进程接管开启它的窗口。在MicrosoftWindows中，多数情形都是这样的，在一个进程开始时，它并没有窗口，但是它可以创建一个（或多个）窗口。在UNIX和Windows系统中，用户可以同时打开多个窗口，每个窗口都运行一个进程。通过鼠标用户可以选择一个窗口并且与该进程交互，例如，在需要时提供输入。

最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中（可能是远程地）提交批处理作业。在操作系统认为有资源可运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。

从技术上看，在所有这些情形中，新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的。这个进程可以是一个运行的用户进程、一个由键盘或鼠标启动的系统进程或者一个批处理管理进程。这个进程所做的工作是，执行一个用来创建新进程的系统调用。这个系统调用通知操作系统创建一个新进程，并且直接或间接地指定在该进程中运行的程序。

在UNIX系统中，只有一个系统调用可以用来创建新进程：fork。这个系统调用会创建一个与调用进程相同的副本。在调用了fork后，这两个进程（父进程和子进程）拥有相同的内存映像、同样的环境字符串和同样的打开文件。这就是全部情形。通常，子进程接着执行execve或一个类似的系统调用，以修改其内存映像并运行一个新的程序。例如，当一个用户在shell中键入命令sort时，shell就创建一个子进程，然后，这个子进程执行sort。之所以要安排两步建立进程，是为了在fork之后但在execve之前允许该子进程处理其文件描述符，这样可以完成对标准输人文件、标准输出文件和标准错误文件的重定向。

在Windows中，情形正相反，一个Win32函数调用CreateProcess既处理进程的创建，也负责把正确的程序装入新的进程。该调用有10个参数，其中包括要执行的程序、输入给该程序的命令行参数、各种安全属性、有关打开的文件是否继承的控制位、优先级信息、该进程（若有的话）所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了CreateProcess，Win32中有大约100个其他的函数用于处理进程的管理、同步以及相关的事务。

在UNIX和Windows中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个字，这个修改对其他进程而言是不可见的。在UNIX中，子进程的初始地址空间是父进程的一个副本，但是这里涉及两个不同的地址空间，不可写的内存区是共享的。某些UNIX的实现使程序正文在两者间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但这种情况下内存通过写时复制（copy-on-write）共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确地复制，以确保修改发生在私有内存区域。再次强调，可写的内存是不可以共享的。但是，对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，诸如打开的文件等。在Windows中，从一开始父进程的地址空间和子进程的地址空间就是不同的。

### 2.1.3 进程的终止

进程在创建之后，它开始运行，完成其工作。但永恒是不存在的，进程也一样。迟早这个新的进程会终止，通常由下列条件引起：

1）正常退出（自愿的）。

2）出错退出（自愿的）。

3）严重错误（非自愿）。

4）被其他进程杀死（非自愿）。

多数进程是由于完成了它们的工作而终止。当编译器完成了所给定程序的编译之后，编译器执行一个系统调用，通知操作系统它的工作已经完成。在UNIX中该调用是exit，而在Windows中，相关的调用是ExitProcess。面向屏幕的程序也支持自愿终止。字处理软件、Internet浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。

进程终止的第二个原因是进程发现了严重错误。例如，如果用户键入命令

cc foo.c

要编译程序foo.c，但是该文件并不存在，于是编译器就会退出。在给出了错误参数时，面向屏幕的交互式进程通常并不退出。相反，这些程序会弹出一个对话框，并要求用户再试一次。

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所致。例如，执行了一条非法指令、引I用不存在的内存，或除数是零等。有些系统中（如UNIX），进程可以通知操作系统，它希望自行处理某些类型的错误，在这类错误中，进程会收到信号（被中断），而不是在这类错误出现时终止。

第四种终止进程的原因是，某个进程执行一个系统调用通知操作系统杀死某个其他进程。在UNIX中，这个系统调用是kill。在Win32中对应的函数是Terminate Process。在这两种情形中，“杀手”都必须获得确定的授权以便进行动作。在有些系统中，当一个进程终止时，不论是自愿的还是其他原因，由该进程所创建的所有进程也一律立即被杀死。不过，UNIX和Windows都不是这种工作方式。

### 2.1.4 进程的层次结构

某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自身可以创建更多的进程，组成一个进程的层次结构。请注意，这与植物和动物的有性繁殖不同，进程只有一个父进程(但是可以有零个、一个、两个或多个子进程)。

在UNIX中，进程和它的所有子进程以及后裔共同组成一个进程组。当用户从键盘发出一个信号时该信号被送给当前与键盘相关的进程组中的所有成员(它们通常是在当前窗口创建的所有活动进程)每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号杀死。

这里有另一个例子，可以用来说明进程层次的作用，考虑UNIX在启动时如何初始化自己。一个称为init的特殊进程出现在启动映像中。当它开始运行时，读入一个说明终端数量的文件。接着，为每个终端创建一个新进程。这些进程等待用户登录。如果有一个用户登录成功，该登录进程就执行一个shel准备接收命令。所接收的这些命令会启动更多的进程，以此类推。这样，在整个系统中，所有的进程都属于以init为根的一棵树。

相反，Windows中没有进程层次的概念，所有的进程都是地位相同的。唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌(称为句柄)，该句柄可以用来控制子进程。但是它有权把这个令牌传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子继承的“继承权”。

### 2.1.5 进程的状态

尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间经常需要相互作用。一个进程的输出结果可能作为另一个进程的输入。在shell命令

```
cat chapter1 chapter2 chapter3 | grep tree
```

中，第一个进程运行cat，将三个文件连接并输出。第二个进程运行grep，它从输入中选择所有包含单词“tree”的那些行。根据这两个进程的相对速度(这取决于这两个程序的相对复杂度和各自所分配到的CPU时间），可能发生这种情况：grep准备就绪可以运行，但输入还没有完成。于是必须阻塞grep，直到输人到来。

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输人。还可能有这样的情况：一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了CPU。这两种情况是完全不同的。在第一种情况下，进程挂起是程序自身固有的原因（在键入用户命令行之前，无法执行命令）。第二种情况则是由系统技术上的原因引起的（由于没有足够的CPU，所以不能使每个进程都有一台私用的处理器）。在图2-2中可以看到显示进程的三种状态的状态图，这三种状态是：

![image-20240915072404888](现代操作系统_上.assets/image-20240915072404888.png)

1）运行态（该时刻进程实际占用CPU）。

2）就绪态（可运行，但因为其他进程正在运行而暂时停止）。

3）阻塞态（除非某种外部事件发生，否则进程不能运行）。

前两种状态在逻辑上是类似的。处于这两种状态的进程都可以运行，只是对于第二种状态暂时没有CPU分配给它。第三种状态与前两种状态不同，处于该状态的进程不能运行，即使CPU空闲也不行。

进程的三种状态之间有四种可能的转换关系，如图2-2所示。在操作系统发现进程不能继续运行下去时，发生转换1。在某些系统中，进程可以执行一个诸如pause的系统调用来进入阻塞状态。在其他系统中，包括UNIX，当一个进程从管道或设备文件（例如终端）读取数据时，如果没有有效的输入存在，则进程会被自动阻塞。

转换2和3是由进程调度程序引起的，进程调度程序是操作系统的一部分，进程甚至感觉不到调度程序的存在。系统认为一个运行进程占用处理器的时间已经过长，决定让其他进程使用CPU时间时，会发生转换2。在系统已经让所有其他进程享有了它们应有的公平待遇而重新轮到第一个进程再次占用CPU运行时，会发生转换3。调度程序的主要工作就是决定应当运行哪个进程、何时运行及它应该运行多长时间，这是很重要的一点，我们将在本章的后面部分进行讨论。目前已经提出了许多算法，这些算法力图在整体效率和进程的竞争公平性之间取得平衡。我们将在本章稍后部分研究其中的一些问题。

当进程等待的一个外部事件发生时（如一些输入到达），则发生转换4。如果此时没有其他进程运行，则立即触发转换3，该进程便开始运行。否则该进程将处于就绪态，等待CPU空闲并且轮到它运行。

使用进程模型使得我们易于想象系统内部的操作状况。一些进程正在运行执行用户键入命令所对应的程序。另一些进程是系统的一部分，它们的任务是完成下列一些工作：比如，执行文件服务请求、管理磁盘驱动器和磁带机的运行细节等。当发生一个磁盘中断时，系统会做出决定，停止运行当前进程，转而运行磁盘进程，该进程在此之前因等待中断而处于阻塞态。这样就可以不再考虑中断，而只是考虑用户进程、磁盘进程、终端进程等。这些进程在等待时总是处于阻塞状态。在已经读入磁盘或键人字符后，等待它们的进程就被解除阻塞，并成为可调度运行的进程。

![image-20240915072551922](现代操作系统_上.assets/image-20240915072551922.png)

从这个观点引出了图2-3所示的模型。在图2-3中，操作系统的最底层是调度程序，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。实际上，调度程序是一段非常短小的程序。操作系统的其他部分被简单地组织成进程的形式。不过，很少有真实的系统是以这样的理想方式构造的。

### 2.1.6 进程的实现

为了实现进程模型，操作系统维护着一张表格（一个结构数组），即进程表（processtable）。每个进程占用一个进程表项。（有些作者称这些表项为进程控制块。）该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。

图2-4中展示了在一个典型系统中的关键字段。第一列中的字段与进程管理有关。其他两列分别与存储管理和文件管理有关。应该注意到进程表中的字段是与系统密切相关的，不过该图给出了所需要信息的大致介绍。

![image-20240915072630399](现代操作系统_上.assets/image-20240915072630399.png)

在了解进程表后，就可以对在单个（或每一个）CPU上如何维持多个顺序进程的错觉做更多的阐述。与每一I/O类关联的是一个称作中断向量（interruptvector）的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程3正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这些是硬件完成的所有操作，然后软件，特别是中断服务例程就接管一切剩余的工作。

所有的中断都从保存寄存器开始，对于当前进程而言，通常是保存在进程表项中。随后，会从堆栈中删除由中断硬件机制存入堆栈的那部分信息，并将堆栈指针指向一个由进程处理程序所使用的临时堆栈。一些诸如保存寄存器值和设置堆栈指针等操作，无法用C语言这一类高级语言描述，所以这些操作通过一个短小的汇编语言例程来完成，通常该例程可以供所有的中断使用，因为无论中断是怎样引起的，有关保存寄存器的工作则是完全一样的。

当该例程结束后，它调用一个C过程处理某个特定的中断类型剩下的工作。（假定操作系统由C语言编写，通常这是所有真实操作系统的选择）。在完成有关工作之后，大概就会使某些进程就绪，接着调用调度程序，决定随后该运行哪个进程。随后将控制转给一段汇编语言代码，为当前的进程装人寄存器值以及内存映射并启动该进程运行。图2-5中总结了中断处理和调度的过程。值得注意的是，各种系统之间某些细节会有所不同。

![image-20240915072753987](现代操作系统_上.assets/image-20240915072753987.png)

一个进程在执行过程中可能被中断数千次，但关键是每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。

### 2.1.7 多道程序设计模型

采用多道程序设计可以提高CPU的利用率。严格地说，如果进程用于计算的平均时间是进程在内存中停留时间的20%，且内存中同时有5个进程，则CPU将一直满负载运行。然而，这个模型在现实中过于乐观，因为它假设这5个进程不会同时等待I/O。

更好的模型是从概率的角度来看CPU的利用率。假设一个进程等待I/O操作的时间与其停留在内存中时间的比为P。当内存中同时有n个进程时，则所有n个进程都在等待I/O（此时CPU空转）的概率是P（-n-）。CPU的利用率由下面的公式给出：

CPU利用率=1-p（-n-）

![image-20240915072924360](现代操作系统_上.assets/image-20240915072924360.png)

图2-6以n为变量的函数表示了CPU的利用率，n称为多道程序设计的道数（degree of multiprogramming)。

从图2-6中可以清楚地看到，如果进程花费80%的时间等待I/O，为使CPU的浪费低于10%，至少要有10个进程同时在内存中。当读者认识到一个等待用户从终端输入的交互式进程是处于1/0等待状态时，那么很明显，80%甚至更多的I/O等待时间是普遍的。即使是在服务器中，做大量磁盘I/O操作的进程也会花费同样或更多的等待时间。

从完全精确的角度考虑，应该指出此概率模型只是描述了一个大致的状况。它假设所有n个进程是独立的，即内存中的5个进程中，3个运行，2个等待，是完全可接受的。但在单CPU中，不能同时运行3个进程，所以当CPU忙时，已就绪的进程也必须等待CPU。因而，进程不是独立的。更精确的模型应该用排队论构建，但我们的模型（当进程就绪时，给进程分配CPU，否则让CPU空转）仍然是有效的，即使真实曲线会与图2-6中所画的略有不同。

虽然图2-6的模型很简单、很粗略，它依然对预测CPU的性能很有效。例如，假设计算机有8GB内存，操作系统及相关表格占用2GB，每个用户程序也占用2GB。这些内存空间允许3个用户程序同时驻留在内存中。若80%的时间用于I/O等待，则CPU的利用率（忽略操作系统开销）大约是1-0.8，即大约49%。在增加8GB字节的内存后，可从3道程序设计提高到7道程序设计，因而CPU利用率提高到79%。换言之，第二个8GB内存提高了30%的吞吐量。

而增加第三个8GB内存只能将CPU利用率从79%提高到91%，吞吐量的提高仅为12%。通过这一模型，计算机用户可以确定，第一次增加内存是一个划算的投资，而第二个则不是。

## 2.2 线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在在同一个地址空间中准并行运行多个控制线程的情形，这些线程就像（差不多）分离的进程(共享地址空间除外)。在下面各节中，我们将讨论这些情形及其实现。

### 2.2.1 线程的使用

为什么人们需要在一个进程中再有一类进程？有若干理由说明产生这些迷你进程（称为线程）的必要性。下面我们来讨论其中一些理由。人们需要多线程的主要原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单。

前面已经进行了有关讨论。准确地说，这正是之前关于进程模型的讨论。有了这样的抽象，我们才不必考虑中断、定时器和上下文切换，而只需考察并行进程。类似地，只是在有了多线程概念之后，我们才加入了一种新的元素：并行实体拥有共享同一个地址空间和所有可用数据的能力。对于某些应用而言，这种能力是必需的，而这正是多进程模型（它们具有不同的地址空间）所无法表达的。

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易（即更快）创建，也更容易撤销。在许多系统中，创建一个线程较创建一个进程要快10~100倍。在有大量线程需要动态和快速修改时，具有这一特性是很有用的。

需要多线程的第三个原因涉及性能方面的讨论。若多个线程都是CPU密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的I/O处理，拥有多个线程允许这些活动彼此重叠进行，从而会加快应用程序执行的速度。

最后，在多CPU系统中，多线程是有益的，在这样的系统中，真正的并行有了实现的可能，第8章将讨论这个主题。

通过考察一些典型例子，我们可以更清楚地看出引入多线程的好处。作为第一个例子，考虑一个字处理软件。字处理软件通常按照出现在打印页上的格式在屏幕上精确显示文档。特别地，所有的行分隔符和页分隔符都在正确的最终位置上，这样在需要时用户可以检查和修改文档（比如，消除孤行一一在一页上不完整的顶部行和底部行，因为这些行不甚美观）。

假设用户正在写一本书。从作者的观点来看，最容易的方法是把整本书作为一个文件，这样一来，查询内容、完成全局替换等都非常容易。另一种方法是，把每一章都处理成单独一个文件。但是，在把每个小节和子小节都分成单个的文件之后，若必须对全书进行全局的修改时，那就真是麻烦了，因为有成百个文件必须一个个地编辑。例如，如果所建议的某个标准××××正好在书付印之前被批准了，于是“标准草案××××”一类的字眼就必须改为“标准××××”。如果整本书是一个文件，那么只要一个命令就可以完成全部的替换处理。相反，如果一本书分成了300个文件，那么就必须分别对每个文件进行编辑。

现在考虑，如果有一个用户突然在一个有800页的文件的第一页上删掉了一个语句之后，会发生什么情形。在检查了所修改的页面并确认正确后，这个用户现在打算接着在第600页上进行另一个修改，并键人一条命令通知字处理软件转到该页面（可能要查阅只在那里出现的一个短语）。于是字处理软件被强制对整本书的前600页重新进行格式处理，这是因为在排列该页前面的所有页面之前，字处理软件并不知道第600页的第一行应该在哪里。而在第600页的页面可以真正在屏幕上显示出来之前，计算机可能要拖延相当一段时间，从而令用户不甚满意。

多线程在这里可以发挥作用。假设字处理软件被编写成含有两个线程的程序。一个线程与用户交互，而另一个在后台重新进行格式处理。一旦在第1页中的语句被删除掉，交互线程就立即通知格式化线程对整本书重新进行处理。同时，交互线程继续监控键盘和鼠标，并响应诸如滚动第1页之类的简单命令，此刻，另一个线程正在后台疯狂地运算。如果有点运气的话，重新格式化会在用户请求查看第600页之前完成，这样，第600页页面就立即可以在屏幕上显示出来。

如果已经做到了这一步，那么为什么不再进一步增加一个线程呢？许多字处理软件都有每隔若干分钟自动在磁盘上保存整个文件的特点，用于避免由于程序崩溃、系统崩溃或电源故障而造成用户一整天的工作丢失的情况。第三个线程可以处理磁盘备份，而不必干扰其他两个线程。拥有三个线程的情形，如图2-7所示。

![image-20240915073216834](现代操作系统_上.assets/image-20240915073216834.png)

如果程序是单线程的，那么在进行磁盘备份时，来自键盘和鼠标的命令就会被忽略，直到备份工作完成为止。用户当然会认为性能很差。另一个方法是，为了获得好的性能，可以让键盘和鼠标事件中断磁盘备份，但这样却引入了复杂的中断驱动程序设计模型。如果使用三个线程，程序设计模型就很简单了。第一个线程只是和用户交互；第二个线程在得到通知时进行文档的重新格式化，第三个线程周期性地将RAM中的内容写到磁盘上。

很显然，在这里用三个不同的进程是不能工作的，这是因为三个线程都需要对同一个文件进行操作。由于多个线程可以共享公共内存，所以通过用三个线程替换三个进程，使得它们可以访问同一个正在编辑的文件，而三个进程是做不到的。

许多其他的交互式程序中也存在类似的情形。例如，电子表格是允许用户维护矩阵的一种程序，矩阵中的一些元素是用户提供的数据，另一些元素是通过所输入的数据运用可能比较复杂的公式而得出的计算结果。当用户改变一个元素时，许多其他元素就必须重新计算。通过一个后台线程进行重新计算的方式，交互式线程就能够在进行计算的时候，让用户从事更多的工作。类似地，第三个线程可以在磁盘上进行周期性的备份工作。

现在考虑另一个多线程发挥作用的例子：一个万维网服务器。对页面的请求发给服务器，而所请求的页面发回给客户机。在多数Web站点上，某些页面较其他页面相比，有更多的访问。例如，对Sony主页的访问就远远超过对深藏在页面树里的任何特定摄像机的技术说明书页面的访问。利用这一事实，Web服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这样的一种页面集合称为高速缓存（cache），高速缓存也运用在其他许多场合中。例如在第1章中介绍的CPU缓存。一种组织Web服务器的方式如图2-8所示。

![image-20240915073422460](现代操作系统_上.assets/image-20240915073422460.png)

在这里，一个称为分派程序（dispatcher）的线程从网络中读入工作请求。在检查请求之后，分派线程挑选一个空转的（即被阻塞的）工作线程（workerthread），提交该请求，通常是在每个线程所配有的某个专门字中写人一个消息指针。接着分派线程唤醒睡眠的工作线程，将它从阻塞状态转为就绪状态。

在工作线程被唤醒之后，它检查有关的请求是否在Web页面高速缓存之中，这个高速缓存是所有线程都可以访问的。如果没有，该线程开始一个从磁盘调入页面的read操作，并且阻塞直到该磁盘操作完成。当上述线程阻塞在磁盘操作上时，为了完成更多的工作，分派线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投人运行。

这种模型允许把服务器编写为顺序线程的一个集合。在分派线程的程序中包含一个无限循环，该循环用来获得工作请求并且把工作请求派给工作线程。每个工作线程的代码包含一个从分派线程接收的请求，并且检查Web高速缓存中是否存在所需页面的无限循环。如果存在，就将该页面返回给客户机，接着该工作线程阻塞，等待一个新的请求。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后该工作线程阻塞，等待一个新的请求。

图2-9给出了有关代码的大致框架。如同本书的其他部分一样，这里假设TRUE为常数1。另外，buf和page分别是保存工作请求和Web页面的相应结构。

![image-20240915073503321](现代操作系统_上.assets/image-20240915073503321.png)

现在考虑在没有多线程的情形下，如何编写Web服务器。一种可能的方式是，使其像一个线程一样运行。Web服务器的主循环获得请求，检查请求，并且在取下一个请求之前完成整个工作。在等待磁盘操作时，服务器就空转，并且不处理任何到来的其他请求。如果该Web服务器运行在唯一的机器上，通常情形都是这样，那么在等待磁盘操作时CPU只能空转。结果导致每秒钟只有很少的请求被处理。可见线程较好地改善了Web服务器的性能，而且每个线程是按通常方式顺序编程的。

到现在为止，我们有了两个可能的设计方案：多线程Web服务器和单线程Web服务器。假设没有多线程可用，而系统设计者又认为由于单线程所造成的性能降低是不能接受的，那么如果可以使用read系统调用的非阻塞版本，还存在第三种可能的设计。在请求到来时，这个唯一的线程对请求进行考察。如果该请求能够在高速缓存中得到满足，那么一切都好，如果不能，则启动一个非阻塞的磁盘操作。

服务器在表格中记录当前请求的状态，然后去处理下一个事件。下一个事件可能是一个新工作的请求，或是磁盘对先前操作的回答。如果是新工作的请求，就开始该工作。如果是磁盘的回答，就从表格中取出对应的信息，并处理该回答。对于非阻塞磁盘I/O而言，这种回答多数会以信号或中断的形式出现。

在这一设计中，前面两个例子中的“顺序进程”模型消失了。每次服务器从为某个请求工作的状态切换到另一个状态时，都必须显式地保存或重新装人相应的计算状态。事实上，我们以一种困难的方式模拟了线程及其堆栈。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为有限状态机（finite-statemachine）。有限状态机这一概念广泛地应用在计算机科学中。

现在很清楚多线程必须提供的是什么了。多线程使得顺序进程的思想得以保留下来，这种顺序进程阻塞了系统调用（如磁盘I/O），但是仍旧实现了并行性。对系统调用进行阻塞使程序设计变的较为简单，而且并行性改善了性能。单线程服务器虽然保留了阻塞系统调用的简易性，但是却放弃了性能。第三种处理方法运用了非阻塞调用和中断，通过并行性实现了高性能，但是给编程增加了困难。在图2-10中给出了上述模式的总结。

![image-20240915073539198](现代操作系统_上.assets/image-20240915073539198.png)

有关多线程作用的第三个例子是那些必须处理极大量数据的应用。通常的处理方式是，读进一块数据，对其处理，然后再写出数据。这里的问题是，如果只能使用阻塞系统调用，那么在数据进入和数据输出时，会阻塞进程。在有大量计算需要处理的时候，让CPU空转显然是浪费，应该尽可能避免。多线程提供了一种解决方案，有关的进程可以用一个输人线程、一个处理线程和一个输出线程构造。输入线程把数据读入到输入缓冲区中，处理线程从输入缓冲区中取出数据，处理数据，并把结果放到输出缓冲区中，输出线程把这些结果写到磁盘上。按照这种工作方式，输入、处理和输出可以全部同时进行。当然，这种模型只有当系统调用只阻塞调用线程而不是阻塞整个进程时，才能正常工作。

### 2.2.2 经典的线程模型

既然已经清楚为什么线程会有用以及如何使用它们，不如让我们用更进一步的眼光来审查一下上面的想法。进程模型基于两种独立的概念：资源分组处理与执行。有时，将这两种概念分开会更好，这就引入了“线程”这一概念。下面先介绍经典的线程模型；之后我们会来研究“模糊进程与线程分界线”的Linux线程模型。

理解进程的一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们都放到进程中可以更容易管理。

另一个概念是，进程拥有一个执行的线程，通常简写为线程（thread）。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存线程当前的工作变量。线程还拥有一个堆栈，用来记录执行历史，其中每一顿保存了一个已调用的但是还没有从中返回的过程。尽管线程必须在某个进程中执行，但是线程和它的进程是不同的概念，并且可以分别处理。进程用于把资源集中到一起，而线程则是在CPU上被调度执行的实体。

线程给进程模型增加了一项内容，即在同一个进程环境中，允许彼此之间有较大独立性的多个线程执行。在同一个进程中并行运行多个线程，是对在同一台计算机上并行运行多个进程的模拟。在前一种情形下，多个线程共享同一个地址空间和其他资源。而在后一种情形中，多个进程共享物理内存、磁盘、打印机和其他资源。由于线程具有进程的某些性质，所以有时被称为轻量级进程（lightweightprocess）。多线程这个术语，也用来描述在同一个进程中允许多个线程的情形。正如在第1章中看到的，一些CPU已经有直接硬件支持多线程，并允许线程切换在纳秒级完成。

在图2-11a中，可以看到三个传统的进程。每个进程有自己的地址空间和单个控制线程。相反，在图2-11b中，可以看到一个进程带有三个控制线程。尽管在两种情形中都有三个线程，但是在图2-11a中，每一个线程都在不同的地址空间中运行，而在图2-11b中，这三个线程全部在相同的地址空间中运行。

当多线程进程在单CPU系统中运行时，线程轮流运行。从图2-1中，我们已经看到了进程的多道程序设计是如何工作的。通过在多个进程之间来回切换，系统制造了不同的顺序进程并行运行的假象。多线程的工作方式也是类似的。CPU在线程之间的快速切换，制造了线程并行运行的假象，好似它们在一个比实际CPU慢一些的CPU上同时运行。在一个有三个计算密集型线程的进程中，线程以并行方式运行，每个线程在一个CPU上得到了真实CPU速度的三分之一。

![image-20240915073639265](现代操作系统_上.assets/image-20240915073639265.png)

进程中的不同线程不像不同进程之间那样存在很大的独立性。所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。线程之间是没有保护的，原因是：1）不可能，2）也没有必要。这与不同进程是有差别的。不同的进程会来自不同的用户，它们彼此之间可能有敌意，一个进程总是由某个用户所拥有，该用户创建多个线程应该是为了它们之间的合作而不是彼此间争斗。除了共享地址空间之外，所有线程还共享同一个打开文件集、子进程、定时器以及相关信号等，如图212所示。这样，对于三个没有关系的线程而言，应该使用图2-11a的结构，而在三个线程实际完成同一个作业，并彼此积极密切合作的情形中，图2-11b则比较合适。

![image-20240915073706819](现代操作系统_上.assets/image-20240915073706819.png)

图2-12中，第一列表项是进程的属性，而不是线程的属性。例如，如果一个线程打开了一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程，所以这种情形是合理的。如果每个线程有其自已的地址空间、打开文件、即将发生的定时器等，那么它们就应该是不同的进程了。线程概念试图实现的是，共享一组资源的多个线程的执行能力，以便这些线程可以为完成某一任务而共同工作。

和传统进程一样（即只有一个线程的进程），线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。正在运行的线程拥有CPU并且是活跃的。被阻塞的线程正在等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到键人了输入为止。线程可以被阻塞，以便等待某个外部事件的发生或者等待其他线程来释放它。就绪线程可被调度运行，并且只要轮到它就很快可以运行。线程状态之间的转换和进程状态之间的转换是一样的，如图2-2所示。

![image-20240915073809681](现代操作系统_上.assets/image-20240915073809681.png)

认识到每个线程有其自己的堆栈很重要，如图2-13所示。每个线程的堆栈有一帧，供各个被调用但是还没有从中返回的过程使用。在该栈帧中存放了相应过程的局部变量以及过程调用完成之后使用的返回地址。例如，如果过程X调用过程Y，而Y又调用Z，那么当Z执行时，供X、Y和Z使用的栈帧会全部存在堆栈中。通常每个线程会调用不同的过程，从而有一个各自不同的执行历史，这就是为什么每个线程需要有自己的堆栈的原因。

在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如thread_create）创建新的线程。thread_create的参数专门指定了新线程要运行的过程名。这里，没有必要对新线程的地址空间加以规定，因为新线程会自动在创建线程的地址空间中运行。有时，线程是有层次的，它们具有一种父子关系，但是，通常不存在这样一种关系，所有的线程都是平等的。不论有无层次关系，创建线程通常都返回一个线程标识符，该标识符就是新线程的名字。

当一个线程完成工作后，可以通过调用一个库过程（如thread_exit）退出。该线程接着消失，不再可调度。在某些线程系统中，通过调用一个过程，例如thread_join，一个线程可以等待一个（特定）线程退出。这个过程阻塞调用线程直到那个（特定）线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止，并且也有着同样的选项。

另一个常见的线程调用是thread_yield，它允许线程自动放弃CPU从而让另一个线程运行。这样一个调用是很重要的，因为不同于进程，（线程库）无法利用时钟中断强制线程让出CPU。所以设法使线程行为“高尚”起来，并且随着时间的推移自动交出CPU，以便让其他线程有机会运行，就变得非常重要。有的调用允许某个线程等待另一个线程完成某些任务，或等待一个线程宣称它已经完成了有关的工作等。

通常而言，线程是有益的，但是线程也在程序设计模式中引入了某种程度的复杂性。考虑一下UNIX中的fork系统调用。如果父进程有多个线程，那么它的子进程也应该拥有这些线程吗？如果不是，则该子进程可能会工作不正常，因为在该子进程中的线程都是绝对必要的。

然而，如果子进程拥有了与父进程一样的多个线程，如果父进程在read系统调用（比如键盘）上被阻塞了会发生什么情况？是两个线程被阻塞在键盘上（一个属于父进程，另一个属于子进程）吗？在键人一行输入之后，这两个线程都得到该输入的副本吗？还是仅有父进程得到该输人的副本？或是仅有子进程得到？类似的问题在进行网络连接时也会出现。

另一类问题和线程共享许多数据结构的事实有关。如果一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样？假设有一个线程注意到几乎没有内存了，并开始分配更多的内存。在工作一半的时候，发生线程切换，新线程也注意到几乎没有内存了，并且也开始分配更多的内存。这样，内存可能会被分配两次。不过这些问题通过努力是可以解决的。总之，要使多线程的程序正确工作，就需要仔细思考和设计。

### 2.2.3 POSIX线程

为实现可移植的线程程序，IEEE在IEEE标准1003.1c中定义了线程的标准。它定义的线程包叫作pthread。大部分UNIX系统都支持该标准。这个标准定义了超过60个函数调用，如果在这里列举一遍就太多了。这里仅描述一些主要的函数，以说明它是如何工作的。图2-14中列举了这些函数调用。

所有pthread线程都有某些特性。每一个都含有一个标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这些属性包括堆栈大小、调度参数以及其他线程需要的项目。

![image-20240915073946930](现代操作系统_上.assets/image-20240915073946930.png)

创建一个新线程需要使用pthread_create调用。新创建的线程的线程标识符会作为函数值返回。这种调用有意看起来很像fork系统调用，其中线程标识符起着PID的作用，而这么做的目的主要是为了标识在其他调用中引用的线程。

当一个线程完成分配给它的工作时，可以通过调用pthread_exit来终止。这个调用终止该线程并释放它的栈。

一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过pthread_join线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。

有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长时间并且希望给另外一个线程机会去运行。这时可以通过调用pthread_yield完成这一目标。而进程中没有这种调用，因为假设进程间会有激烈的竞争性，并且每一个进程都希望获得它所能得到的所有的CPU时间。但是，由于同一进程中的线程可以同时工作，并且它们的代码总是由同一个程序员编写的，因此，有时程序员希望它们能互相给对方一些机会去运行。

下面两个线程调用是处理属性的。pthread_attr_init建立关联一个线程的属性结构并初始化成默认值。这些值（例如优先级）可以通过修改属性结构中的域值来改变。

最后，pthread_attr_destroy删除一个线程的属性结构，释放它占用的内存。它不会影响调用它的线程。这些线程会继续存在。

为了更好地了解pthread是如何工作的，考虑图2-15提供的简单例子。这里主程序在宣布它的意图之后，循环NUMBER_OF_THREADS次，每次创建一个新的线程。如果线程创建失败，会打印出一条错误信息然后退出。在创建完所有线程之后，主程序退出。

当创建一个线程时，它打印一条一行的发布信息，然后退出。这些不同信息交错的顺序是不确定的，并且可能在连续运行程序的情况下发生变化。

pthread调用不只是前面介绍的这几个，还有许多的pthread调用会在讨论“进程与线程同步”之后再介绍。

### 2.2.4 在用户空间中实现线程

车个医人计有两种主要的方法实现线程包：在用户空间中和在内核中。这两种方法互有利，不过混合实现方式也是可能的。我们现在介绍这些方法，并分析它们的优点和缺点。

第一种方法是把整个线程包放在用户空间中，内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程。这种方法第一个也是最明显的优点是，用户级线程包可以在不支持线程的操作系统上实现。过去所有的操作系统都属于这个范围，即使现在也有一些操作系统还是不支持线程。通过这一方法，可以用函数库实现线程。

![image-20240915074109971](现代操作系统_上.assets/image-20240915074109971.png)

所有的这类实现都有同样的通用结构，如图2-16a所示。线程在一个运行时系统的上层运行，该运行时系统是一个管理线程的过程的集合。前面已经介绍过其中的四个过程：pthread_create，pthread_exit，pthread_join和pthread_yield。不过，一般还会有更多的过程。

![image-20240915074132490](现代操作系统_上.assets/image-20240915074132490.png)

在用户空间管理线程时，每个进程需要有其专用的线程表（threadtable），用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。该线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放进程的信息完全一样。

当某个线程做了一些会引起在本地阻塞的事情之后，例如，等待进程中另一个线程完成某项工作，它调用一个运行时系统的过程，这个过程检查该线程是否必须进入阻塞状态。如果是，它在线程表中保存该线程的寄存器（即它本身的），查看表中可运行的就绪线程，并把新线程的保存值重新装入机器的寄存器中。只要堆栈指针和程序计数器一被切换，新的线程就又自动投入运行。如果机器有一条保存所有寄存器的指令和另一条装入全部寄存器的指令，那么整个线程的切换可以在几条指令内完成。进行类似于这样的线程切换至少比陷入内核要快一个数量级（或许更多），这是使用用户级线程包的极大的优点。

不过，线程与进程有一个关键的差别。在线程完成运行时，例如，在它调用thread_yield时，pthread_yield代码可以把该线程的信息保存在线程表中，进而，它可以调用线程调度程序来选择另一个要运行的线程。保存该线程状态的过程和调度程序都只是本地过程，所以启动它们比进行内核调用效率更高。另一方面，不需要陷入内核，不需要上下文切换，也不需要对内存高速缓存进行刷新，这就使得线程调度非常快捷。

用户级线程还有另一个优点。它允许每个进程有自己定制的调度算法。例如，在某些应用程序中，那些有垃圾收集线程的应用程序就不用担心线程会在不合适的时刻停止，这是一个长处。用户级线程还具有较好的可扩展性，这是因为在内核空间中内核线程需要一些固定表格空间和堆栈空间，如果内核线程的数量非常大，就会出现问题。

尽管用户级线程包有更好的性能，但它也存在一些明显的问题。其中第一个问题是如何实现阻塞系统调用。假设在还没有任何击键之前，一个线程读取键盘。让该线程实际进行该系统调用是不可接受的，因为这会停止所有的线程。使用线程的一个主要目标是，首先要允许每个线程使用阻塞调用，但是还要避免被阻塞的线程影响其他的线程。有了阻塞系统调用，这个目标不是轻易地能够实现的。

系统调用可以全部改成非阻塞的（例如，如果没有被缓冲的字符，对键盘的read操作可以只返回0字节），但是这需要修改操作系统，所以这个办法也不吸引人。而且，用户级线程的一个长处就是它可以在现有的操作系统上运行。另外，改变read操作的语义需要修改许多用户程序。

在这个过程中，还有一种可能的替代方案，就是如果某个调用会阻塞，就提前通知。在某些UNIX版本中，有一个系统调用select可以允许调用者通知预期的read是否会阻塞。若有这个调用，那么库过程read就可以被新的操作替代，首先进行select调用，然后只有在安全的情形下（即不会阻塞）才进行read调用。如果read调用会被阻塞，有关的调用就不进行，代之以运行另一个线程。到了下次有关的运行系统取得控制权之后，就可以再次检查看看现在进行read调用是否安全。这个处理方法需要重写部分系统调用库，所以效率不高也不优雅，不过没有其他的可选方案了。在系统调用周围从事检查的这类代码称为包装器（jacket或wrapper）。

与阻塞系统调用问题有些类似的是缺页中断问题，我们将在第3章讨论这些问题。此刻可以认为，把计算机设置成这样一种工作方式，即并不是所有的程序都一次性放在内存中。如果某个程序调用或者跳转到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令（和该指令的“邻居们”），这就称为页面故障。在对所需的指令进行定位和读入时，相关的进程就被阻塞。如果有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘I/O完成为止，尽管其他的线程是可以运行的。

用户级线程包的另一个问题是，如果一个线程开始运行，那么在该进程中的其他线程就不能运行，除非第一个线程自动放弃CPU。在一个单独的进程内部，没有时钟中断，所以不可能用轮转调度（轮流）的方式调度线程。除非某个线程能够按照自己的意志进入运行时系统，否则调度程序就没有任何机会。

对线程永久运行问题的一个可能的解决方案是让运行时系统请求每秒一次的时钟信号（中断），但是这样对程序也是生硬和无序的。不可能总是高频率地发生周期性的时钟中断，即使可能，总的开销也是可观的。而且，线程可能也需要时钟中断，这就会扰乱运行时系统使用的时钟。

再者，也许针对用户级线程的最大负面争论意见是，程序员通常在经常发生线程阻塞的应用中才希望使用多个线程。例如，在多线程Web服务器里。这些线程持续地进行系统调用，而一旦发生内核陷阱进行系统调用，如果原有的线程已经阻塞，就很难让内核进行线程的切换，如果要让内核消除这种情形，就要持续进行select系统调用，以便检查read系统调用是否安全。对于那些基本上是CPU密集型而且极少有阻塞的应用程序而言，使用多线程的目的又何在呢？由于这样的做法并不能得到任何益处，所以没有人会真正提出使用多线程来计算前n个素数或者下象棋等一类工作。

### 2.2.5 在内核中实现线程

现在考虑内核支持和管理线程的情形。如图2-16b所示，此时不再需要运行时系统了。另外，每个进程中也没有线程表。相反，在内核中有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用，这个系统调用通过对线程表的更新完成线程创建或撤销工作。

内核的线程表保存了每个线程的寄存器、状态和其他信息。这些信息和在用户空间中（在运行时系统中）的线程是一样的，但是现在保存在内核中。这些信息是传统内核所维护的每个单线程进程信息（即进程状态）的子集。另外，内核还维护了传统的进程表，以便跟踪进程的状态。

所有能够阻塞线程的调用都以系统调用的形式实现，这与运行时系统过程相比，代价是相当可观的。当一个线程阻塞时，内核根据其选择，可以运行同一个进程中的另一个线程（若有一个就绪线程）或者运行另一个进程中的线程。而在用户级线程中，运行时系统始终运行自己进程中的线程，直到内核剥夺它的CPU（或者没有可运行的线程存在了）为止。

由于在内核中创建或撤销线程的代价比较大，某些系统采取“环保”的处理方式，回收其线程。当某个线程被撤销时，就把它标志为不可运行的，但是其内核数据结构没有受到影响。稍后，在必须创建一个新线程时，就重新启动某个旧线程，从而节省了一些开销。在用户级线程中线程回收也是可能的，但是由于其线程管理的代价很小，所以没有必要进行这项工作。

内核线程不需要任何新的、非阻塞系统调用。另外，如果某个进程中的线程引起了页面故障，内核可以很方便地检查该进程是否有任何其他可运行的线程，如果有，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的主要缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止等）比较多，就会带来很大的开销。

虽然使用内核线程可以解决很多问题，但是也不会解决所有的问题。例如，当一个多线程进程创建新的进程时，会发生什么？新进程是拥有与原进程相同数量的线程，还是只有一个线程？在很多情况下，最好的选择取决于进程计划下一步做什么。如果它要调用exec来启动一个新的程序，或许一个线程是正确的选择；但是如果它继续执行，则最好复制所有的线程。

另一个话题是信号。回忆一下，信号是发给进程而不是线程的，至少在经典模型中是这样的。当一个信号到达时，应该由哪一个线程处理它？线程可以“注册”它们感兴趣的某些信号，因此当一个信号到达的时候，可把它交给需要它的线程。但是如果两个或更多的线程注册了相同的信号，会发生什么？这只是线程引起的问题中的两个，但是还有更多的问题。

### 2.2.6 混合实现

人们已经研究了各种试图将用户级线程的优点和内核级线程的优点结合起来的方法。一种方法是使用内核级线程，然后将用户级线程与某些或者全部内核线程多路复用起来，如图2-17所示。如果采用这种方法，编程人员可以决定有多少个内核级线程和多少个用户级线程彼此多路复用。这一模型带来最大的灵活度。

![image-20240915074454379](现代操作系统_上.assets/image-20240915074454379.png)

采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。如同在没有多线程能力操作系统中某个进程中的用户级线程一样，可以创建、撤销和调度这些用户级线程。在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合。

### 2.2.7 调度程序激活机制

尽管内核级线程在一些关键点上优于用户级线程，但无可争议的是内核级线程的速度慢。因此，研究人员一直在寻找在保持其优良特性的前提下改进其速度的方法。下面将介绍Anderson等人（1992）设计的一种方法，称为调度程序激活（scheduleractivation）机制。Edler等人（1988）以及Scott等人（1990）就相关的工作进行了深人讨论。

调度程序激活工作的目标是模拟内核线程的功能，但是为线程包提供通常在用户空间中才能实现的更好的性能和更大的灵活性。特别地，如果用户线程从事某种系统调用时是安全的，那就不应该进行专门的非阻塞调用或者进行提前检查。无论如何，如果线程阻塞在某个系统调用或页面故障上，只要在同一个进程中有任何就绪的线程，就应该有可能运行其他的线程。

由于避免了在用户空间和内核空间之间的不必要转换，从而提高了效率。例如，如果某个线程由于等待另一个线程的工作而阻塞，此时没有理由请求内核，这样就减少了内核一用户转换的开销。用户空间的运行时系统可以阻塞同步的线程而另外调度一个新线程。

当使用调度程序激活机制时，内核给每个进程安排一定数量的虚拟处理器，并且让（用户空间）运行时系统将线程分配到处理器上。这一机制也可以用在多处理器中，此时虚拟处理器可能成为真实的CPU。分配给一个进程的虚拟处理器的初始数量是一个，但是该进程可以申请更多的处理器并且在不用时退回。内核也可以取回已经分配出去的虚拟处理器，以便把它们分给需要更多处理器的进程。

使该机制工作的基本思路是，当内核了解到一个线程被阻塞之后（例如，由于执行了一个阻塞系统调用或者产生了一个页面故障），内核通知该进程的运行时系统，并且在堆栈中以参数形式传递有问题的线程编号和所发生事件的一个描述。内核通过在一个已知的起始地址启动运行时系统，从而发出了通知，这是对UNIX中信号的一种粗略模拟。这个机制称为上行调用（upcall）。

一旦如此激活，运行时系统就重新调度其线程，这个过程通常是这样的：把当前线程标记为阻塞并从就绪表中取出另一个线程，设置其寄存器，然后再启动之。稍后，当内核知道原来的线程又可运行时（例如，原先试图读取的管道中有了数据，或者已经从磁盘中读入了故障的页面），内核就又一次上行调用运行时系统，通知它这一事件。此时该运行时系统按照自己的判断，或者立即重启动被阻塞的线程，或者把它放入就绪表中稍后运行。

在某个用户线程运行的同时发生一个硬件中断时，被中断的CPU切换进内核态。如果被中断的进程对引起该中断的事件不感兴趣，比如，是另一个进程的I/O完成了，那么在中断处理程序结束之后，就把被中断的线程恢复到中断之前的状态。不过，如果该进程对中断感兴趣，比如，是该进程中的某个线程所需要的页面到达了，那么被中断的线程就不再启动，代之为挂起被中断的线程。而运行时系统则启动对应的虚拟CPU，此时被中断线程的状态保存在堆栈中。随后，运行时系统决定在该CPU上调度哪个线程：被中断的线程、新就绪的线程还是某个第三种选择。

调度程序激活机制的一个目标是作为上行调用的信赖基础，这是一种违反分层次系统内在结构的概念。通常，n层提供n+1层可调用的特定服务，但是n层不能调用n+1层中的过程。上行调用并不遵守这个基本原理。

### 2.2.8 弹出式线程

在分布式系统中经常使用线程。一个有意义的例子是如何处理到来的消息，例如服务请求。传统的方法是将进程或线程阻塞在一个receive系统调用上，等待消息到来。当消息到达时，该系统调用接收消息，并打开消息检查其内容，然后进行处理。

不过，也可能有另一种完全不同的处理方式，在该处理方式中，一个消息的到达导致系统创建一个处理该消息的线程，这种线程称为弹出式线程，如图2-18所示。弹出式线程的关键好处是，由于这种线程相当新，没有历史一一没有必须存储的寄存器、堆栈诸如此类的内容，每个线程从全新开始，每一个线程彼此之间都完全一样。这样，就有可能快速创建这类线程。对该新线程指定所要处理的消息。使用弹出式线程的结果是，消息到达与处理开始之间的时间非常短。

![image-20240915074733645](现代操作系统_上.assets/image-20240915074733645.png)

在使用弹出式线程之前，需要提前进行计划。例如，哪个进程中的线程先运行？如果系统支持在内核上下文中运行线程，线程就有可能在那里运行（这是图2-18中没有画出内核的原因）。在内核空间中运行弹出式线程通常比在用户空间中容易且快捷，而且内核空间中的弹出式线程可以很容易访问所有的表格和I/O设备，这些也许在中断处理时有用。而另一方面，出错的内核线程会比出错的用户线程造成更大的损害。例如，如果某个线程运行时间太长，又没有办法抢占它，就可能造成进来的信息丢失。

### 2.2.9 使单线程代码多线程化

许多已有的程序是为单线程进程编写的。把这些程序改写成多线程需要比直接写多线程程序更高的技巧。下面考察一些其中易犯的错误。

先考察代码，一个线程的代码就像进程一样，通常包含多个过程，会有局部变量、全局变量和过程参数。局部变量和参数不会引起任何问题，但是有一个问题是，对线程而言是全局变量，并不是对整个程序也是全局的。有许多变量之所以是全局的，是因为线程中的许多过程都使用它们（如同它们也可能使用任何全局变量一样），但是其他线程在逻辑上和这些变量无关。

作为一个例子，考虑由UNIX维护的errno变量。当进程（或线程）进行系统调用失败时，错误码会放入errno。在图2-19中，线程1执行系统调用access以确定是否允许它访问某个特定文件。操作系统把返回值放到全局变量errno里。当控制权返回到线程1之后，并在线程1读取errno之前，调度程序确认线程1此刻已用完CPU时间，并决定切换到线程2。线程2执行一个open调用，结果失败，导致重写errno，于是给线程1的返回值会永远丢失。随后在线程1执行时，它将读取错误的返回值并导致错误操作。

对于这个问题有各种解决方案。一种解决方案是全面禁止全局变量。不过这个想法不一定合适，因为它同许多已有的软件冲突。另一种解决方案是为每个线程赋予其私有的全局变量，如图2-20所示。在这个方案中，每个线程有自己的errno以及其他全局变量的私有副本，这样就避免了冲突。在效果上，这个方案创建了新的作用域层，这些变量对一个线程中所有过程都是可见的。而在原先的作用域层里，变量只对一个过程可见，并在程序中处处可见。

![image-20240915074818095](现代操作系统_上.assets/image-20240915074818095.png)

访问私有的全局变量需要有些技巧，不过，多数程序设计语言具有表示局部变量和全局变量的方式，而没有中间的形式。有可能为全局变量分配一块内存，并将它转送给线程中的每个过程作为额外的参数。尽管这不是一个漂亮的方案，但却是一个可用的方案。

还有另一种方案，可以引入新的库过程，以便创建、设置和读取这些线程范围的全局变量。首先一个调用也许是这样的：

```
create_global("bufptr");
```

该调用在堆上或在专门为调用线程所保留的特殊存储区上替一个名为bufptr的指针分配存储空间。无论该存储空间分配在何处，只有调用线程才可访问其全局变量。如果另一个线程创建了同名的全局变量，由于它在不同的存储单元上，所以不会与已有的那个变量产生冲突。

访问全局变量需要两个调用：一个用于写入全局变量，另一个用于读取全局变量。对于写入，类似有

```
set_global("bufptr",&buf);
```

它把指针的值保存在先前通过调用create_global创建的存储单元中。如果要读出一个全局变量，调用的形式类似于

```
bufptr=read_global("bufptr");
```

这个调用返回一个存储在全局变量中的地址，这样就可以访问其中的数据了。

试图将单一线程程序转为多线程程序的另一个问题是，有许多库过程并不是可重入的。也就是说，它们不是被设计成下列工作方式的：对于任何给定的过程，当前面的调用尚没有结束之前，可以进行第二次调用。例如，可以将通过网络发送消息恰当地设计为，在库内部的一个固定缓冲区中进行消息组合，然后陷入内核将其发送。但是，如果一个线程在缓冲区中编好了消息，然后被时钟中断强迫切换到第二个线程，而第二个线程立即用它自已的消息重写了该缓冲区，那会怎样呢？

类似的还有内存分配过程，例如UNIX中的malloc，它维护着内存使用情况的关键表格，如可用内存块链表。在malloc忙于更新表格时，有可能暂时处于一种不一致的状态，指针的指向不定。如果在表格处于一种不一致的状态时发生了线程切换，并且从一个不同的线程中来了一个新的调用，就可能会由于使用了一个无效指针从而导致程序崩溃。要有效解决这些问题意味着重写整个库，而这有可能引人一些微妙的错误，所以这么做是一件很复杂的事情。

另一种解决方案是，为每个过程提供一个包装器，该包装器设置一个二进制位从而标志某个库处于使用中。在先前的调用还没有完成之前，任何试图使用该库的其他线程都会被阻塞。尽管这个方式可以工作，但是它会极大地降低系统潜在的并行性。

接着考虑信号。有些信号逻辑上是线程专用的，但是另一些却不是。例如，如果某个线程调用alarm，信号送往进行该调用的线程是有意义的。但是，当线程完全在用户空间实现时，内核根本不知道有线程存在，因此很难将信号发送给正确的线程。如果一个进程一次仅有一个警报信号等待处理，而其中的多个线程又独立地调用alarm，那么情况就更加复杂了。

有些信号，如键盘中断，则不是线程专用的。谁应该捕捉它们？一个指定的线程？所有的线程？还是新创建的弹出式线程？进而，如果某个线程修改了信号处理程序，而没有通知其他线程，会出现什么情况？如果某个线程想捕捉一个特定的信号（比如，用户击键CTRL+C），而另一个线程却想用这个信号终止进程，又会发生什么情况？如果有一个或多个线程运行标准的库过程以及其他用户编写的过程，那么情况还会更复杂。很显然，这些想法是不兼容的。一般而言，在单线程环境中信号已经是很难管理的了，到了多线程环境中并不会使这一情况变得容易处理。

由多线程引入的最后一个问题是堆栈的管理。在很多系统中，当一个进程的堆栈溢出时，内核只是自动为该进程提供更多的堆栈。当一个进程有多个线程时，就必须有多个堆栈。如果内核不了解所有的堆栈，就不能使它们自动增长，直到造成堆栈出错。事实上，内核有可能还没有意识到内存错误是和某个线程栈的增长有关系的。

这些问题当然不是不可克服的，但是却说明了给已有的系统引入线程而不进行实质性的重新设计系统是根本不行的。至少可能需要重新定义系统调用的语义，并且不得不重写库。而且所有这些工作必须与在一个进程中有一个线程的原有程序向后兼容。有关线程的其他信息，可以参阅Hauser等人（1993）和Marsh等人（1991）。

## 2.3 进程间通信

进程经常需要与其他进程通信。例如，在一个shell管道中，第一个进程的输出必须传送给第二个进程，这样沿着管道传递下去。因此在进程之间需要通信，而且最好使用一种结构良好的方式而不要使用中断。在下面几节中，我们就来讨论一些有关进程间通信（InterProcessCommunication，IPC）的问题。

简要地说，有三个问题。第一个问题与上面的叙述有关，即一个进程如何把信息传递给另一个。第二个要处理的问题是，确保两个或更多的进程在关键活动中不会出现交叉，例如，在飞机订票系统中的两个进程为不同的客户试图争夺飞机上的最后一个座位。第三个问题与正确的顺序有关（如果该顺序是有关联的话），比如，如果进程A产生数据而进程B打印数据，那么B在打印之前必须等待，直到A已经产生一些数据。我们将从下一节开始考察所有这三个问题。

有必要说明，这三个问题中的两个问题对于线程来说是同样适用的。第一个问题（即传递信息）对线程而言比较容易，因为它们共享一个地址空间（在不同地址空间需要通信的线程属于不同进程之间通信的情形）。但是另外两个问题（需要梳理清楚并保持恰当的顺序）同样适用于线程。同样的问题可用同样的方法解决。下面开始讨论进程间通信问题，不过请记住，同样的问题和解决方法也适用于线程。

### 2.3.1 竞争条件

在一些操作系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中（可能是在内核数据结构中），也可能是一个共享文件。这里共享存储区的位置并不影响通信的本质及其带来的问题。为了理解实际中进程间通信如何工作，我们考虑一个简单但很普遍的例子：一个假脱机打印程序。当一个进程需要打印一个文件时，它将文件名放在一个特殊的假脱机目录（spoolerdirectory）下。另一个进程（打印机守护进程）则周期性地检查是否有文件需要打印，若有就打印并将该文件名从目录下删掉。

设想假脱机目录中有许多槽位，编号依次为0，1，2，，每个槽位存放一个文件名。同时假设有两个共享变量：out，指向下一个要打印的文件，in，指向目录中下一个空闲槽位。可以把这两个变量保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0号至3号槽位空（其中的文件已经打印完毕），4号至6号槽位被占用（其中存有排好队列的要打印的文件名）。几乎在同一时刻，进程A和进程B都决定将一个文件排队打印，这种情况如图2-21所示。

![image-20240915075149987](现代操作系统_上.assets/image-20240915075149987.png)

在Murphy法则（任何可能出错的地方终将出错）生效时，可能发生以下的情况。进程A读到in的值为7，将7存在一个局部变量next_free_slot中。此时发生一次时钟中断，CPU认为进程A已运行了足够长的时间，决定切换到进程B。进程B也读取in，同样得到值为7，于是将7存在B的局部变量next_free_slot中。在这一时刻两个进程都认为下一个可用槽位是7。

进程B现在继续运行，它将其文件名存在槽位7中并将in的值更新为8。然后它离开，继续执行其他操作。

最后进程A接着从上次中断的地方再次运行。它检查变量next_free_slot，发现其值为7，于是将打印文件名存入7号槽位，这样就把进程B存在那里的文件名覆盖掉。然后它将next_free_slot加1，得到值为8，就将8存到in中。此时，假脱机目录内部是一致的，所以打印机守护进程发现不了任何错误，但进程B却永远得不到任何打印输出。类似这样的情况，即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，称为竞争条件（racecondition）。调试包含有竞争条件的程序是一件很头痛的事。大多数的测试运行结果都很好，但在极少数情况下会发生一些无法解释的奇怪现象。不幸的是，多核增长带来的并行使得竞争条件越来越普遍。

### 2.3.2 临界区

怎样避免竞争条件？实际上凡涉及共享内存、共享文件以及共享任何资源的情况都会引发与前面类似的错误，要避免这种错误，关键是要找出某种途径来阻止多个进程同时读写共享的数据。换言之，我们需要的是互斥（mutualexclusion），即以某种手段确保当一个进程在使用一个共享变量或文件时，其他进程不能做同样的操作。前述问题的症结就在于，在进程A对共享变量的使用未结束之前进程B就使用它。为实现互厅而选择适当的原语是任何操作系统的主要设计内容之一，也是后面几节中要详细讨论的主题。

避免竞争条件的问题也可以用一种抽象的方式进行描述。一个进程的一部分时间做内部计算或另外一些不会引发竞争条件的操作。在某些时候进程可能需要访问共享内存或共享文件，或执行另外一些会导致竞争的操作。我们把对共享内存进行访问的程序片段称作临界区域（criticalregion）或临界区（criticalsection）。如果我们能够适当地安排，使得两个进程不可能同时处于临界区中，就能够避免竞争条件。

尽管这样的要求避免了竞争条件，但它还不能保证使用共享数据的并发进程能够正确和高效地进行协作。对于一个好的解决方案，需要满足以下4个条件：

1）任何两个进程不能同时处于其临界区。

2）不应对CPU的速度和数量做任何假设。

3）临界区外运行的进程不得阻塞其他进程。

4）不得使进程无限期等待进入临界区。

从抽象的角度看，人们所希望的进程行为如图2-22所示。图2-22中进程A在T{1}时刻进入临界区。稍后，在T{2}时刻进程B试图进入临界区，但是失败了，因为另一个进程已经在该临界区内，而一个时刻只允许一个进程在临界区内。随后，B被暂时挂起直到T{3}时刻A离开临界区为止，从而允许B立即进入。最后，B离开（在时刻T{4}），回到了在临界区中没有进程的原始状态。

![image-20240915075357132](现代操作系统_上.assets/image-20240915075357132.png)

### 2.3.3 忙等待的互斥

本节将讨论几种实现互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入其临界区，也不会带来任何麻烦。

#### 1. 屏蔽中断

在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，并在就要离开之前再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU只有发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后CPU将不会被切换到其他进程。于是，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不必担心其他进程介人。

这个方案并不好，因为把屏蔽中断的权力交给用户进程是不明智的。设想一下，若一个进程屏蔽中断后不再打开中断，其结果将会如何？整个系统可能会因此终止。而且，如果系统是多处理器（有两个或可能更多的处理器），则屏蔽中断仅仅对执行disable指令的那个CPU有效。其他CPU仍将继续运行，并可以访问共享内存。

另一方面，对内核来说，当它在更新变量或列表的几条指令期间将中断屏蔽是很方便的。当就绪进程队列之类的数据状态不一致时发生中断，则将导致竞争条件。所以结论是：屏蔽中断对于操作系统本身而言是一项很有用的技术，但对于用户进程则不是一种合适的通用互斥机制。

由于多核芯片的数量越来越多，即使在低端PC上也是如此。因此，通过屏蔽中断来达到互斥的可能性一——甚至在内核中一—变得日益减少了。双核现在已经相当普遍，四核当前在高端机器中存在，而且离八或十六（核）也不久远了。在一个多核系统中（例如，多处理器系统），屏蔽一个CPU的中断不会阻止其他CPU干预第一个CPU所做的操作。结果是人们需要更加复杂的计划。

#### 2.锁变量

作为第二种尝试，可以寻找一种软件解决方案。设想有一个共享（锁）变量，其初始值为0。当一个进程想进人其临界区时，它首先测试这把锁。如果该锁的值为0，则该进程将其设置为1并进入临界区。若这把锁的值已经为1，则该进程将等待直到其值变为0。于是，0就表示临界区内没有进程，1表示已经有某个进程进入临界区。

但是，这种想法也包含了与假脱机目录一样的疏漏。假设一个进程读出锁变量的值并发现它为0，而恰好在它将其值设置为1之前，另一个进程被调度运行，将该锁变量设置为1。当第一个进程再次运行时，它同样也将该锁设置为1，则此时同时有两个进程进入临界区中。

可能读者会想，先读出锁变量，紧接着在改变其值之前再检查一遍它的值，这样便可以解决问题。但这实际上无济于事，如果第二个进程恰好在第一个进程完成第二次检查之后修改了锁变量的值，则同样还会发生竞争条件。

#### 3.严格轮换法

第三种互斥的方法如图2-23所示。几乎与本书中所有其他程序一样，这里的程序段用C语言编写。之所以选择C语言是由于实际的操作系统普遍用C语言编写（或偶尔用C++），而基本上不用像Java、Modula3或Pascal这样的语言。对于编写操作系统而言，C语言是强大、有效、可预知和有特性的语言。而对于Java，它就不是可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾收集程序回收内存。在C语言中，这种情形就不可能发生，因为C语言中不需要进行空间回收。有关C、C++、Java和其他四种语言的定量比较可参阅（Prechelt，2000）。

在图2-23中，整型变量turm，初始值为0，用于记录轮到哪个进程进入临界区，并检查或更新共享内存。开始时，进程0检查turn，发现其值为0，于是进入临界区。进程1也发现其值为0，所以在一个等待循环中不停地测试turn，看其值何时变为1。连续测试一个变量直到某个值出现为止，称为忙等待（busywaiting）。由于这种方式浪费CPU时间，所以通常应该避免。只有在有理由认为等待时间是非常短的情形下，才使用忙等待。用于忙等待的锁，称为自旋锁（spinlock）。

![image-20240915075543184](现代操作系统_上.assets/image-20240915075543184.png)

进程0离开临界区时，它将turn的值设置为1，以便允许进程1进入其临界区。假设进程1很快便离开了临界区，则此时两个进程都处于临界区之外，turn的值又被设置为0。现在进程0很快就执行完其整个循环，它退出临界区，并将turn的值设置为1。此时，turn的值为1，两个进程都在其临界区外执行。

突然，进程0结束了非临界区的操作并且返回到循环的开始。但是，这时它不能进入临界区，因为turn的当前值为1，而此时进程1还在忙于非临界区的操作，进程0只有继续while循环，直到进程1把turn的值改为0。这说明，在一个进程比另一个慢了很多的情况下，轮流进入临界区并不是一个好办法。

这种情况违反了前面叙述的条件3：进程0被一个临界区之外的进程阻塞。再回到前面假脱机目录的问题，如果现在将临界区与读写假脱机目录相联系，则进程0有可能因为进程1在做其他事情而被禁止打印另一个文件。

实际上，该方案要求两个进程严格地轮流进入它们的临界区，如假脱机文件等。任何一个进程都不可能在一轮中打印两个文件。尽管该算法的确避免了所有的竞争条件，但由于它违反了条件3，所以不能作为一个很好的备选方案。

#### 4.Peterson解法

荷兰数学家T.Dekker通过将锁变量与警告变量的思想相结合，最早提出了一个不需要严格轮换的软件互斥算法。关于Dekker的算法，请参阅（Dijkstra，1965）。

1981年，G.L.Peterson发现了一种简单得多的互厅算法，这使得Dekker的方法不再有任何新意。Peterson的算法如图2-24所示。该算法由两个用ANSIC编写的过程组成。ANSIC要求为所定义和使用的所有函数提供函数原型。不过，为了节省篇幅，这里和后续的例子中我们都不会给出函数原型。

![image-20240915075644642](现代操作系统_上.assets/image-20240915075644642.png)

在使用共享变量（即进入其临界区）之前，各个进程使用其进程号0或1作为参数来调用enter_region。该调用在需要时将使进程等待，直到能安全地进入临界区。在完成对共享变量的操作之后，进程将调用leave_region，表示操作已完成，若其他的进程希望进入临界区，则现在就可以进入。

现在来看看这个方案是如何工作的。一开始，没有任何进程处于临界区中，现在进程0调用enter_region。它通过设置其数组元素和将turn置为0来标识它希望进入临界区。由于进程1并不想进入临界区，所以enter_region很快便返回。如果进程1现在调用enter_region，进程1将在此处挂起直到interested[0]变成FALSE，该事件只有在进程o调用leave_region退出临界区时才会发生。

现在考虑两个进程几乎同时调用enter_region的情况。它们都将自己的进程号存入turn，但只有后被保存进去的进程号才有效，前一个因被重写而丢失。假设进程1是后存人的，则turn为1。当两个进程都运行到while语句时，进程0将循环0次并进入临界区，而进程1则将不停地循环且不能进入临界区，直到进程0退出临界区为止。

#### 5.TSL指令

现在来看需要硬件支持的一种方案。某些计算机中，特别是那些设计为多处理器的计算机，都有下面一条指令：TSLRX,LOCK

称为测试并加锁（testandsetlock），它将一个内存字lock读到寄存器RX中，然后在该内存地址上存一个非零值。读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行TSL指令的CPU将锁住内存总线，以禁止其他CPU在本指令结束之前访问内存。

着重说明一下，锁住存储总线不同于屏蔽中断。屏蔽中断，然后在读内存字之后跟着写操作并不能阻止总线上的第二个处理器在读操作和写操作之间访问该内存字。事实上，在处理器1上屏蔽中断对处理器2根本没有任何影响。让处理器2远离内存直到处理器1完成的唯一方法就是锁住总线，这需要一个特殊的硬件设施（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能用）。

为了使用TSL指令，要使用一个共享变量lock来协调对共享内存的访问。当lock为0时，任何进程都可以使用TSL指令将其设置为1，并读写共享内存。当操作结束时，进程用一条普通的move指令将lock的值重新设置为0。

这条指令如何防止两个进程同时进入临界区呢？解决方案如图2-25所示。假定（但很典型）存在如下共4条指令的汇编语言子程序。第一条指令将lock原来的值复制到寄存器中并将lock设置为1，随后这个原来的值与0相比较。如果它非零，则说明以前已被加锁，则程序将回到开始并再次测试。经过或长或短的一段时间后，该值将变为0（当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁非常简单，程序只需将0存入lock即可，不需要特殊的同步指令。

![image-20240915075833192](现代操作系统_上.assets/image-20240915075833192.png)

现在有一种很明确的解法了。进程在进入临界区之前先调用enter_region，这将导致忙等待，直到锁空闲为止，随后它获得该锁并返回。在进程从临界区返回时它调用leave_region，这将把lock设置为0。与基于临界区问题的所有解法一样，进程必须在正确的时间调用enter_region和leave_region，解法才能奏效。如果一个进程有欺诈行为，则互斥将会失败。换言之，只有进程合作，临界区才能工作。

一个可替代TSL的指令是XCHG，它原子性地交换了两个位置的内容，例如，一个寄存器与一个存储器字。代码如图2-26所示，而且就像可以看到的那样，它本质上与TSL的解决办法一样。所有的Intelx86CPU在低层同步中使用XCHG指令。

![image-20240915075856157](现代操作系统_上.assets/image-20240915075856157.png)

### 2.3.4 睡眠与唤醒

Peterson解法和TSL或XCHG解法都是正确的，但它们都有忙等待的缺点。这些解法在本质上是这样的：

当一个进程想进入临界区时，先检查是否允许进入，若不允许，则该进程将原地等待，直到允许为止。这种方法不仅浪费了CPU时间，而且还可能引起预想不到的结果。考虑一台计算机有两个进程，H优先级较高，L优先级较低。调度规则规定，只要H处于就绪态它就可以运行。在某一时刻，L处于临界区中，此时H变到就绪态，准备运行（例如，一条I/O操作结束）。现在H开始忙等待，但由于当H就绪时L不会被调度，也就无法离开临界区，所以H将永远忙等待下去。这种情况有时被称作优先级反转问题(priority inversion problem)。

现在来考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是sleep和wakeup。sleep是一个将引起调用进程阻塞的系统调用，即被挂起，直到另外一个进程将其唤醒。wakeup调用有一个参数，即要被唤醒的进程。另一种方法是让sleep和wakeup各有一个参数，即有一个用于匹配sleep和wakeup的内存地址。

#### 1. 生产者一消费者问题

作为使用这些原语的一个例子，我们考虑生产者一消费者（producer-consumer）问题，也称作有界缓冲区（bounded-buffer）问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是生产者，将信息放入缓冲区；另一个是消费者，从缓冲区中取出信息。（也可以把这个问题一般化为m个生产者和n个消费者问题，但是这里只讨论一个生产者和一个消费者的情况，这样可以简化解决方案。）

问题在于当缓冲区已满，而此时生产者还想向其中放入一个新的数据项的情况。其解决办法是让生产者睡眠，待消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样地，当消费者试图从缓冲区中取数据而发现缓冲区为空时，消费者就睡眠，直到生产者向其中放入一些数据时再将其唤醒。

这个方法听起来很简单，但它包含与前边假脱机目录问题一样的竞争条件。为了跟踪缓冲区中的数据项数，需要一个变量count。如果缓冲区最多存放N个数据项，则生产者代码将首先检查count是否达到N，若是，则生产者睡眠；否则生产者向缓冲区中放入一个数据项并增量count的值。

消费者的代码与此类似：首先测试count是否为O，若是，则睡眠；否则从中取走一个数据项并递减count的值。每个进程同时也检测另一个进程是否应被唤醒，若是则唤醒之。生产者和消费者的代码如图2-27所示。

![image-20240915080017582](现代操作系统_上.assets/image-20240915080017582.png)

